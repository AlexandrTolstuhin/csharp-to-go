# 4.3 –û—á–µ—Ä–µ–¥–∏ —Å–æ–æ–±—â–µ–Ω–∏–π

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

- [–í–≤–µ–¥–µ–Ω–∏–µ](#–≤–≤–µ–¥–µ–Ω–∏–µ)
- [–≠–∫–æ—Å–∏—Å—Ç–µ–º–∞: C# vs Go](#—ç–∫–æ—Å–∏—Å—Ç–µ–º–∞-c-vs-go)
- [Apache Kafka (segmentio/kafka-go)](#apache-kafka-segmentiokafka-go)
  - [–ü–æ—á–µ–º—É kafka-go](#–ø–æ—á–µ–º—É-kafka-go)
  - [–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è](#–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ-–∏-–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è)
  - [Producer: –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π](#producer-–æ—Ç–ø—Ä–∞–≤–∫–∞-—Å–æ–æ–±—â–µ–Ω–∏–π)
  - [Consumer: –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π](#consumer-–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ-—Å–æ–æ–±—â–µ–Ω–∏–π)
  - [Consumer Groups](#consumer-groups)
  - [Production –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è](#production-–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è-kafka)
  - [Error Handling –∏ Dead Letter Topics](#error-handling-–∏-dead-letter-topics)
- [RabbitMQ (amqp091-go)](#rabbitmq-amqp091-go)
  - [–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–∞–Ω–∞–ª–∞–º–∏](#–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ-–∏-—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ-–∫–∞–Ω–∞–ª–∞–º–∏)
  - [Exchanges, Queues, Bindings](#exchanges-queues-bindings)
  - [Publishing: –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∏ –≥–∞—Ä–∞–Ω—Ç–∏–∏](#publishing-–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è-–∏-–≥–∞—Ä–∞–Ω—Ç–∏–∏)
  - [Consuming: prefetch, ack/nack](#consuming-prefetch-acknack)
  - [Connection Recovery –∏ Reconnection](#connection-recovery-–∏-reconnection)
  - [Dead Letter Exchanges (DLX)](#dead-letter-exchanges-dlx)
- [NATS (nats.go)](#nats-natsgo)
  - [Core NATS: Pub/Sub –∏ Request/Reply](#core-nats-pubsub-–∏-requestreply)
  - [JetStream: –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π –æ–±–º–µ–Ω —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏](#jetstream-–ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π-–æ–±–º–µ–Ω-—Å–æ–æ–±—â–µ–Ω–∏—è–º–∏)
  - [Push vs Pull Consumers](#push-vs-pull-consumers)
  - [Key-Value Store –∏ Object Store](#key-value-store-–∏-object-store)
- [Redis Streams](#redis-streams)
  - [–û—Å–Ω–æ–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (XADD, XREAD)](#–æ—Å–Ω–æ–≤–Ω—ã–µ-–æ–ø–µ—Ä–∞—Ü–∏–∏-xadd-xread)
  - [Consumer Groups](#consumer-groups-redis)
  - [Acknowledgment –∏ Claiming](#acknowledgment-–∏-claiming)
  - [–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Redis Streams](#–∫–æ–≥–¥–∞-–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å-redis-streams)
- [–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π](#—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π)
- [–ü–∞—Ç—Ç–µ—Ä–Ω—ã –∏ Best Practices](#–ø–∞—Ç—Ç–µ—Ä–Ω—ã-–∏-best-practices)
  - [–ò–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (Exactly-Once Processing)](#–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å-exactly-once-processing)
  - [Graceful Shutdown](#graceful-shutdown)
  - [Retry —Å Exponential Backoff](#retry-—Å-exponential-backoff)
  - [Dead Letter Queue](#dead-letter-queue)
  - [–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π](#—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è-—Å–æ–æ–±—â–µ–Ω–∏–π)
  - [Outbox Pattern](#outbox-pattern)
  - [Saga Pattern](#saga-pattern)
- [Production Concerns](#production-concerns)
  - [–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å Prometheus](#–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥-—Å-prometheus)
  - [OpenTelemetry Instrumentation](#opentelemetry-instrumentation)
  - [Health Checks](#health-checks)
- [–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã](#–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ-–ø—Ä–∏–º–µ—Ä—ã)
  - [–ü—Ä–∏–º–µ—Ä 1: Event-Driven Order Processing (Kafka)](#–ø—Ä–∏–º–µ—Ä-1-event-driven-order-processing-kafka)
  - [–ü—Ä–∏–º–µ—Ä 2: Task Queue —Å RabbitMQ](#–ø—Ä–∏–º–µ—Ä-2-task-queue-—Å-rabbitmq)
  - [–ü—Ä–∏–º–µ—Ä 3: Real-Time Notifications (NATS)](#–ø—Ä–∏–º–µ—Ä-3-real-time-notifications-nats)
- [–ß–µ–∫-–ª–∏—Å—Ç](#—á–µ–∫-–ª–∏—Å—Ç)

---

## –í–≤–µ–¥–µ–Ω–∏–µ

–í [—Ä–∞–∑–¥–µ–ª–µ 4.2](./02_caching.md) –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–ª–∏ Pub/Sub –≤ Redis –∏ —É–ø–æ–º—è–Ω—É–ª–∏, —á—Ç–æ –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ–π –¥–æ—Å—Ç–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –Ω—É–∂–Ω—ã —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è. –û—á–µ—Ä–µ–¥–∏ —Å–æ–æ–±—â–µ–Ω–∏–π (Message Queues) ‚Äî —ç—Ç–æ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: –æ–Ω–∏ –ø–æ–∑–≤–æ–ª—è—é—Ç —Å–µ—Ä–≤–∏—Å–∞–º –æ–±–º–µ–Ω–∏–≤–∞—Ç—å—Å—è –¥–∞–Ω–Ω—ã–º–∏ –±–µ–∑ –ø—Ä—è–º–æ–π —Å–≤—è–∑–∏, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç—å, –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å –∏ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ —Å–±–æ—è–º.

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: –í .NET –≤—ã –ø—Ä–∏–≤—ã–∫–ª–∏ –∫ **MassTransit** –∏–ª–∏ **NServiceBus** ‚Äî –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–º –∞–±—Å—Ç—Ä–∞–∫—Ü–∏—è–º, –∫–æ—Ç–æ—Ä—ã–µ —Å–∫—Ä—ã–≤–∞—é—Ç –¥–µ—Ç–∞–ª–∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞. –í—ã —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç–µ `IConsumer<T>` –≤ DI, –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç–µ retry policies, saga state machines, –∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ —Å–∞–º —É–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è–º–∏, —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π, dead letter queues –∏ consumer lifecycle. –í Go **–Ω–µ—Ç –∞–Ω–∞–ª–æ–≥–∞ MassTransit**. –í—ã —Ä–∞–±–æ—Ç–∞–µ—Ç–µ —Å –∫–ª–∏–µ–Ω—Ç—Å–∫–∏–º–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏ –Ω–∞–ø—Ä—è–º—É—é ‚Äî —ç—Ç–æ –±–æ–ª—å—à–µ –∫–æ–¥–∞, –Ω–æ –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ –ø–æ–≤–µ–¥–µ–Ω–∏–µ–º. –ì–æ—Ä—É—Ç–∏–Ω—ã –¥–µ–ª–∞—é—Ç consumer concurrency —Ç—Ä–∏–≤–∏–∞–ª—å–Ω—ã–º, –∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Å–∫—Ä—ã—Ç–æ–π ¬´–º–∞–≥–∏–∏¬ª —É–ø—Ä–æ—â–∞–µ—Ç –æ—Ç–ª–∞–¥–∫—É.

### –ß—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—Å—è –≤ –≤–∞—à–µ–º –ø–æ–¥—Ö–æ–¥–µ

**C# —Å MassTransit**:
```csharp
// –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è ‚Äî –∏ –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç ¬´–∏–∑ –∫–æ—Ä–æ–±–∫–∏¬ª
services.AddMassTransit(x =>
{
    x.AddConsumer<OrderCreatedConsumer>();
    x.UsingRabbitMq((context, cfg) =>
    {
        cfg.UseMessageRetry(r => r.Exponential(5, TimeSpan.FromSeconds(1), TimeSpan.FromMinutes(1), TimeSpan.FromSeconds(2)));
        cfg.ConfigureEndpoints(context);
    });
});

// Consumer ‚Äî —á–∏—Å—Ç–∞—è –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞
public class OrderCreatedConsumer : IConsumer<OrderCreated>
{
    public async Task Consume(ConsumeContext<OrderCreated> context)
    {
        // MassTransit —Å–∞–º –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç, —É–ø—Ä–∞–≤–ª—è–µ—Ç retry, dead letter, tracing
        await ProcessOrder(context.Message);
    }
}
```

**Go ‚Äî —è–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è**:
```go
// –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ, consumer loop, retry, DLQ ‚Äî –≤—Å—ë –≤—Ä—É—á–Ω—É—é
reader := kafka.NewReader(kafka.ReaderConfig{
    Brokers: []string{"localhost:9092"},
    Topic:   "orders.created",
    GroupID: "order-processor",
})
defer reader.Close()

for {
    msg, err := reader.ReadMessage(ctx)
    if err != nil {
        break
    }

    if err := processOrder(msg); err != nil {
        // Retry, DLQ ‚Äî —Ä–µ–∞–ª–∏–∑—É–µ–º —Å–∞–º–∏
        handleError(ctx, msg, err)
    }
}
```

---

## –≠–∫–æ—Å–∏—Å—Ç–µ–º–∞: C# vs Go

| –ö–æ–Ω—Ü–µ–ø—Ü–∏—è | C# (.NET) | Go |
|-----------|-----------|-----|
| **–ê–±—Å—Ç—Ä–∞–∫—Ü–∏—è** | MassTransit, NServiceBus | –ù–µ—Ç –∞–Ω–∞–ª–æ–≥–∞ (—è–≤–Ω—ã–π –∫–æ–¥) |
| **Kafka –∫–ª–∏–µ–Ω—Ç** | Confluent.Kafka (—á–µ—Ä–µ–∑ MassTransit) | segmentio/kafka-go, confluent-kafka-go |
| **RabbitMQ –∫–ª–∏–µ–Ω—Ç** | RabbitMQ.Client (—á–µ—Ä–µ–∑ MassTransit) | amqp091-go |
| **NATS –∫–ª–∏–µ–Ω—Ç** | NATS.Client | nats.go |
| **In-process –æ—á–µ—Ä–µ–¥—å** | `System.Threading.Channels` | Go –∫–∞–Ω–∞–ª—ã (–≤—Å—Ç—Ä–æ–µ–Ω—ã –≤ —è–∑—ã–∫) |
| **Consumer –ø–∞—Ç—Ç–µ—Ä–Ω** | `IConsumer<T>`, hosted service | –ì–æ—Ä—É—Ç–∏–Ω–∞ + `for` loop |
| **Retry / DLQ** | –í—Å—Ç—Ä–æ–µ–Ω–æ –≤ MassTransit | –†—É—á–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è |
| **–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è** | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è (System.Text.Json) | –†—É—á–Ω–∞—è (encoding/json, protobuf) |
| **Saga** | MassTransit Saga / Automatonymous | –†—É—á–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è |
| **Health checks** | `IHealthCheck` | –†—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏–ª–∏ alexliesenfeld/health |
| **Tracing** | `UseOpenTelemetry()` –≤ MassTransit | –†—É—á–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞—Ü–∏—è |

### –ö–ª—é—á–µ–≤–æ–µ –æ—Ç–ª–∏—á–∏–µ

–í .NET **—Ñ—Ä–µ–π–º–≤–æ—Ä–∫ —É–ø—Ä–∞–≤–ª—è–µ—Ç –≤—Å–µ–º –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º**: –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ ‚Üí –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è ‚Üí –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∫ consumer ‚Üí retry –ø—Ä–∏ –æ—à–∏–±–∫–µ ‚Üí DLQ –ø—Ä–∏ –∏—Å—á–µ—Ä–ø–∞–Ω–∏–∏ –ø–æ–ø—ã—Ç–æ–∫ ‚Üí –º–µ—Ç—Ä–∏–∫–∏ ‚Üí —Ç—Ä–µ–π—Å–∏–Ω–≥. –í—ã –ø–∏—à–µ—Ç–µ —Ç–æ–ª—å–∫–æ –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É.

–í Go **–≤—ã —É–ø—Ä–∞–≤–ª—è–µ—Ç–µ –∫–∞–∂–¥—ã–º —à–∞–≥–æ–º —è–≤–Ω–æ**: —Å–æ–∑–¥–∞—ë—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ, —á–∏—Ç–∞–µ—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ü–∏–∫–ª–µ, –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç–µ, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç–µ –æ—à–∏–±–∫–∏, —Ä–µ–∞–ª–∏–∑—É–µ—Ç–µ retry –∏ DLQ. –≠—Ç–æ —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –∫–æ–¥–∞, –Ω–æ:

- **–ù–µ—Ç —Å–∫—Ä—ã—Ç–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è** ‚Äî –ª–µ–≥–∫–æ –æ—Ç–ª–∞–∂–∏–≤–∞—Ç—å
- **–ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å** –Ω–∞–¥ concurrency (–≥–æ—Ä—É—Ç–∏–Ω—ã, worker pool)
- **–ü—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å** ‚Äî –Ω–µ—Ç reflection, –Ω–µ—Ç DI overhead
- **–ü—Ä–æ—Å—Ç–æ—Ç–∞** ‚Äî –Ω–µ—Ç —Å–ª–æ–∂–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ü–µ–ø–æ—á–µ–∫

> ‚ö†Ô∏è **–†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: –∏—Å–∫–∞—Ç—å "Go MassTransit" –∏–ª–∏ –ø—ã—Ç–∞—Ç—å—Å—è —Å–æ–∑–¥–∞—Ç—å –∞–Ω–∞–ª–æ–≥–∏—á–Ω—É—é –∞–±—Å—Ç—Ä–∞–∫—Ü–∏—é. –í Go-—Å–æ–æ–±—â–µ—Å—Ç–≤–µ –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞—é—Ç —è–≤–Ω—ã–π –∫–æ–¥ –±–∏–±–ª–∏–æ—Ç–µ—á–Ω—ã–º —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞–º. –ù–∞–ø–∏—à–∏—Ç–µ —Ç–æ–Ω–∫—É—é –æ–±—ë—Ä—Ç–∫—É –¥–ª—è –≤–∞—à–µ–≥–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–ª—É—á–∞—è, –∞ –Ω–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫.

### –í —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ –≤—ã –Ω–∞—É—á–∏—Ç–µ—Å—å

- –†–∞–±–æ—Ç–∞—Ç—å —Å 4 —Å–∏—Å—Ç–µ–º–∞–º–∏ –æ–±–º–µ–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏: **Kafka**, **RabbitMQ**, **NATS**, **Redis Streams**
- –†–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—Ç—å **producer** –∏ **consumer** –¥–ª—è –∫–∞–∂–¥–æ–π —Å–∏—Å—Ç–µ–º—ã
- –ù–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å **production-–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é** (TLS, batching, compression)
- –†–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—Ç—å **retry**, **dead letter queue**, **idempotency**
- –ü—Ä–∏–º–µ–Ω—è—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã: **Outbox**, **Saga**, **Graceful Shutdown**
- –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—á–µ—Ä–µ–¥–∏ —á–µ—Ä–µ–∑ **Prometheus** –∏ **OpenTelemetry**
- –í—ã–±–∏—Ä–∞—Ç—å –ø–æ–¥—Ö–æ–¥—è—â—É—é —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—é –¥–ª—è –≤–∞—à–µ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è

---

## Apache Kafka (segmentio/kafka-go)

Apache Kafka ‚Äî —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–π –ª–æ–≥ —Å–æ–±—ã—Ç–∏–π, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∏ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è. Kafka —Ö—Ä–∞–Ω–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ –¥–∏—Å–∫–µ –∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–µ—Ä–µ—á–∏—Ç—ã–≤–∞—Ç—å –∏—Ö ‚Äî —ç—Ç–æ –¥–µ–ª–∞–µ—Ç –µ–≥–æ –∏–¥–µ–∞–ª—å–Ω—ã–º –¥–ª—è event sourcing, stream processing –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –º–µ–∂–¥—É –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞–º–∏.

### –ü–æ—á–µ–º—É kafka-go

–í Go-—ç–∫–æ—Å–∏—Å—Ç–µ–º–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç —Ç—Ä–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö Kafka-–∫–ª–∏–µ–Ω—Ç–∞:

| –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ | CGo | API —Å—Ç–∏–ª—å | –°—Ç–∞—Ç—É—Å | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |
|------------|-----|-----------|--------|-------------------|
| **segmentio/kafka-go** | –ù–µ—Ç (pure Go) | –ò–¥–∏–æ–º–∞—Ç–∏—á–Ω—ã–π Go | –ê–∫—Ç–∏–≤–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ | –û—Å–Ω–æ–≤–Ω–æ–π –≤—ã–±–æ—Ä –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –ø—Ä–æ–µ–∫—Ç–æ–≤ |
| **confluent-kafka-go** | –î–∞ (librdkafka) | –û–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ C | –ê–∫—Ç–∏–≤–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ | –ù—É–∂–Ω—ã exactly-once —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å |
| **Shopify/sarama** | –ù–µ—Ç (pure Go) | –ù–∏–∑–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π | IBM –ø–µ—Ä–µ–¥–∞–ª–∞ Shopify, –º–µ–Ω–µ–µ –∞–∫—Ç–∏–≤–Ω–∞—è | Legacy –ø—Ä–æ–µ–∫—Ç—ã |

> üí° **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `segmentio/kafka-go` –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∏–µ–Ω—Ç. –û–Ω –Ω–µ —Ç—Ä–µ–±—É–µ—Ç CGo (–ø—Ä–æ—â–µ –∫—Ä–æ—Å—Å-–∫–æ–º–ø–∏–ª—è—Ü–∏—è –∏ Docker), –∏–º–µ–µ—Ç –ø–æ–Ω—è—Ç–Ω—ã–π API –∏ –∞–∫—Ç–∏–≤–Ω–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. `confluent-kafka-go` –æ–ø—Ä–∞–≤–¥–∞–Ω —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–∞–º –Ω—É–∂–Ω—ã exactly-once —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ Kafka –∏–ª–∏ –≤—ã —É–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ librdkafka –≤ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–µ.

**C# –∞–Ω–∞–ª–æ–≥–∏—è**: –í C# —Å—Ç–∞–Ω–¥–∞—Ä—Ç ‚Äî `Confluent.Kafka`, –∫–æ—Ç–æ—Ä—ã–π —Ç–æ–∂–µ –æ–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ librdkafka. –†–∞–∑–Ω–∏—Ü–∞ –≤ —Ç–æ–º, —á—Ç–æ –≤ Go –µ—Å—Ç—å pure-Go –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ (kafka-go), –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–æ—â–µ –≤ –¥–µ–ø–ª–æ–µ.

–£—Å—Ç–∞–Ω–æ–≤–∫–∞:

```bash
go get github.com/segmentio/kafka-go
```

### –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

kafka-go –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–≤–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–∏–ø–∞: `kafka.Writer` –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∏ `kafka.Reader` –¥–ª—è –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç Confluent.Kafka –≤ C#, –∑–¥–µ—Å—å –Ω–µ—Ç –µ–¥–∏–Ω–æ–≥–æ ¬´–∫–ª–∏–µ–Ω—Ç–∞¬ª ‚Äî producer –∏ consumer –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã.

**C#** (Confluent.Kafka):
```csharp
// Producer
var config = new ProducerConfig
{
    BootstrapServers = "localhost:9092",
    Acks = Acks.All,
    EnableIdempotence = true
};
using var producer = new ProducerBuilder<string, string>(config).Build();

// Consumer
var consumerConfig = new ConsumerConfig
{
    BootstrapServers = "localhost:9092",
    GroupId = "my-group",
    AutoOffsetReset = AutoOffsetReset.Earliest
};
using var consumer = new ConsumerBuilder<string, string>(consumerConfig).Build();
```

**Go** (kafka-go):
```go
package main

import (
    "context"
    "log"
    "time"

    "github.com/segmentio/kafka-go"
)

func main() {
    // Writer (producer) ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è–º–∏
    writer := &kafka.Writer{
        Addr:         kafka.TCP("localhost:9092"),
        Topic:        "orders",
        Balancer:     &kafka.LeastBytes{}, // –°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤—ã–±–æ—Ä–∞ –ø–∞—Ä—Ç–∏—Ü–∏–∏
        BatchTimeout: 10 * time.Millisecond,
        RequiredAcks: kafka.RequireAll, // –ê–Ω–∞–ª–æ–≥ Acks.All –≤ C#
    }
    defer writer.Close()

    // Reader (consumer) ‚Äî –ø—Ä–∏–≤—è–∑–∞–Ω –∫ —Ç–æ–ø–∏–∫—É –∏ –≥—Ä—É–ø–ø–µ
    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers:        []string{"localhost:9092"},
        Topic:          "orders",
        GroupID:        "order-processor",
        MinBytes:       1,              // –ú–∏–Ω–∏–º—É–º 1 –±–∞–π—Ç –¥–ª—è fetch
        MaxBytes:       10e6,           // –ú–∞–∫—Å–∏–º—É–º 10 MB
        CommitInterval: time.Second,    // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–º–º–∏—Ç –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É
        StartOffset:    kafka.FirstOffset, // –ê–Ω–∞–ª–æ–≥ AutoOffsetReset.Earliest
    })
    defer reader.Close()

    log.Println("Kafka writer –∏ reader —Å–æ–∑–¥–∞–Ω—ã")
}
```

> üí° **–û—Ç–ª–∏—á–∏–µ –æ—Ç C#**: –í Confluent.Kafka –≤—ã —Å–æ–∑–¥–∞—ë—Ç–µ `ProducerBuilder` –∏ `ConsumerBuilder` —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π —á–µ—Ä–µ–∑ —Å–ª–æ–≤–∞—Ä—å —Å—Ç—Ä–æ–∫. –í kafka-go –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ‚Äî —Ç–∏–ø–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ–º –≤ IDE.

### Producer: –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π

#### –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞

```go
// –û—Ç–ø—Ä–∞–≤–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –æ–∂–∏–¥–∞–Ω–∏–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
func sendOrder(ctx context.Context, w *kafka.Writer, order Order) error {
    data, err := json.Marshal(order)
    if err != nil {
        return fmt.Errorf("—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–∫–∞–∑–∞: %w", err)
    }

    err = w.WriteMessages(ctx, kafka.Message{
        Key:   []byte(order.ID),     // –ö–ª—é—á –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–∞—Ä—Ç–∏—Ü–∏—é
        Value: data,
        Headers: []kafka.Header{
            {Key: "content-type", Value: []byte("application/json")},
            {Key: "source", Value: []byte("order-service")},
        },
    })
    if err != nil {
        return fmt.Errorf("–æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ Kafka: %w", err)
    }

    return nil
}
```

#### –ë–∞—Ç—á–µ–≤–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞

```go
// WriteMessages –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ—Ç–ø—Ä–∞–≤–∫—É –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∑–∞ —Ä–∞–∑
func sendOrders(ctx context.Context, w *kafka.Writer, orders []Order) error {
    messages := make([]kafka.Message, 0, len(orders))

    for _, order := range orders {
        data, err := json.Marshal(order)
        if err != nil {
            return fmt.Errorf("—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–∫–∞–∑–∞ %s: %w", order.ID, err)
        }
        messages = append(messages, kafka.Message{
            Key:   []byte(order.ID),
            Value: data,
        })
    }

    // kafka-go –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –±–∞—Ç—á–∏
    // –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏—Ö —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ
    return w.WriteMessages(ctx, messages...)
}
```

#### –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è

```go
// Round-Robin ‚Äî —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
writer := &kafka.Writer{
    Addr:     kafka.TCP("localhost:9092"),
    Topic:    "events",
    Balancer: &kafka.RoundRobin{},
}

// –ü–æ –∫–ª—é—á—É ‚Äî —Å–æ–æ–±—â–µ–Ω–∏—è —Å –æ–¥–Ω–∏–º –∫–ª—é—á–æ–º –ø–æ–ø–∞–¥–∞—é—Ç –≤ –æ–¥–Ω—É –ø–∞—Ä—Ç–∏—Ü–∏—é
// (–≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –ø–æ—Ä—è–¥–æ–∫ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∫–ª—é—á–∞)
writer = &kafka.Writer{
    Addr:     kafka.TCP("localhost:9092"),
    Topic:    "events",
    Balancer: &kafka.Hash{}, // Murmur2 —Ö—ç—à –ø–æ –∫–ª—é—á—É
}

// Least Bytes ‚Äî –≤ –ø–∞—Ä—Ç–∏—Ü–∏—é —Å –Ω–∞–∏–º–µ–Ω—å—à–∏–º –æ–±—ä—ë–º–æ–º –¥–∞–Ω–Ω—ã—Ö
writer = &kafka.Writer{
    Addr:     kafka.TCP("localhost:9092"),
    Topic:    "events",
    Balancer: &kafka.LeastBytes{},
}

// –ö–∞—Å—Ç–æ–º–Ω—ã–π –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤—â–∏–∫
type RegionBalancer struct{}

func (b *RegionBalancer) Balance(msg kafka.Message, partitions ...int) int {
    // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞—Ä—Ç–∏—Ü–∏—é –ø–æ —Ä–µ–≥–∏–æ–Ω—É –∏–∑ headers
    for _, h := range msg.Headers {
        if h.Key == "region" {
            switch string(h.Value) {
            case "eu":
                return partitions[0]
            case "us":
                return partitions[1 % len(partitions)]
            }
        }
    }
    return partitions[0]
}
```

> ‚ö†Ô∏è **–í–∞–∂–Ω–æ**: –ï—Å–ª–∏ –≤–∞–º –Ω—É–∂–µ–Ω —Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä—è–¥–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –æ–¥–Ω–æ–π —Å—É—â–Ω–æ—Å—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤—Å–µ —Å–æ–±—ã—Ç–∏—è –æ–¥–Ω–æ–≥–æ –∑–∞–∫–∞–∑–∞), –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `Hash` –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤—â–∏–∫ –∏ –∑–∞–¥–∞–≤–∞–π—Ç–µ `Key` = ID —Å—É—â–Ω–æ—Å—Ç–∏. –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –æ–¥–Ω–∏–º –∫–ª—é—á–æ–º –ø–æ–ø–∞–¥—É—Ç –≤ –æ–¥–Ω—É –ø–∞—Ä—Ç–∏—Ü–∏—é.

#### –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π producer —á–µ—Ä–µ–∑ –≥–æ—Ä—É—Ç–∏–Ω—ã

```go
// –ü–∞—Ç—Ç–µ—Ä–Ω: –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ –∫–∞–Ω–∞–ª + –≥–æ—Ä—É—Ç–∏–Ω–∞-writer
type AsyncProducer struct {
    writer *kafka.Writer
    ch     chan kafka.Message
    wg     sync.WaitGroup
}

func NewAsyncProducer(brokers []string, topic string, bufferSize int) *AsyncProducer {
    p := &AsyncProducer{
        writer: &kafka.Writer{
            Addr:         kafka.TCP(brokers...),
            Topic:        topic,
            Balancer:     &kafka.Hash{},
            BatchTimeout: 50 * time.Millisecond,
            RequiredAcks: kafka.RequireAll,
        },
        ch: make(chan kafka.Message, bufferSize),
    }

    p.wg.Add(1)
    go p.run()

    return p
}

func (p *AsyncProducer) run() {
    defer p.wg.Done()

    batch := make([]kafka.Message, 0, 100)
    ticker := time.NewTicker(100 * time.Millisecond)
    defer ticker.Stop()

    for {
        select {
        case msg, ok := <-p.ch:
            if !ok {
                // –ö–∞–Ω–∞–ª –∑–∞–∫—Ä—ã—Ç ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è
                if len(batch) > 0 {
                    p.flush(batch)
                }
                return
            }
            batch = append(batch, msg)
            if len(batch) >= 100 {
                p.flush(batch)
                batch = batch[:0]
            }

        case <-ticker.C:
            if len(batch) > 0 {
                p.flush(batch)
                batch = batch[:0]
            }
        }
    }
}

func (p *AsyncProducer) flush(batch []kafka.Message) {
    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
    defer cancel()

    if err := p.writer.WriteMessages(ctx, batch...); err != nil {
        log.Printf("–æ—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –±–∞—Ç—á–∞ (%d —Å–æ–æ–±—â–µ–Ω–∏–π): %v", len(batch), err)
    }
}

// Send ‚Äî –Ω–µ–±–ª–æ–∫–∏—Ä—É—é—â–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ (–±–ª–æ–∫–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±—É—Ñ–µ—Ä –ø–æ–ª–æ–Ω)
func (p *AsyncProducer) Send(msg kafka.Message) {
    p.ch <- msg
}

// Close ‚Äî –¥–æ–∂–∏–¥–∞–µ—Ç—Å—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
func (p *AsyncProducer) Close() {
    close(p.ch)
    p.wg.Wait()
    p.writer.Close()
}
```

**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å C#**:

| –ê—Å–ø–µ–∫—Ç | C# (Confluent.Kafka) | Go (kafka-go) |
|--------|----------------------|---------------|
| **Sync –æ—Ç–ø—Ä–∞–≤–∫–∞** | `ProduceAsync()` + `await` | `WriteMessages()` |
| **Async –æ—Ç–ø—Ä–∞–≤–∫–∞** | `Produce()` + callback | –ö–∞–Ω–∞–ª + –≥–æ—Ä—É—Ç–∏–Ω–∞ |
| **–ë–∞—Ç—á–∏–Ω–≥** | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π (linger.ms) | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π (BatchTimeout) |
| **–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ** | `DeliveryResult` | –û—à–∏–±–∫–∞ –æ—Ç `WriteMessages` |
| **–ö–ª—é—á** | `Message<TKey, TValue>.Key` | `kafka.Message.Key` ([]byte) |
| **Headers** | `Headers` –∫–æ–ª–ª–µ–∫—Ü–∏—è | `[]kafka.Header` |

### Consumer: –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π

#### –ë–∞–∑–æ–≤—ã–π consumer

```go
func consumeOrders(ctx context.Context) error {
    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers:  []string{"localhost:9092"},
        Topic:    "orders",
        GroupID:  "order-processor",
        MinBytes: 1,
        MaxBytes: 10e6,
    })
    defer reader.Close()

    for {
        // ReadMessage –±–ª–æ–∫–∏—Ä—É–µ—Ç –¥–æ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è –∏–ª–∏ –æ—Ç–º–µ–Ω—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        msg, err := reader.ReadMessage(ctx)
        if err != nil {
            if errors.Is(err, context.Canceled) {
                return nil // –®—Ç–∞—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
            }
            return fmt.Errorf("—á—Ç–µ–Ω–∏–µ –∏–∑ Kafka: %w", err)
        }

        var order Order
        if err := json.Unmarshal(msg.Value, &order); err != nil {
            log.Printf("–Ω–µ–≤–∞–ª–∏–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (offset=%d): %v", msg.Offset, err)
            continue // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ ‚Äî –æ–Ω–∏ –Ω–µ –±—É–¥—É—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
        }

        if err := processOrder(ctx, order); err != nil {
            log.Printf("–æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–∫–∞–∑–∞ %s: %v", order.ID, err)
            // –ü—Ä–∏ –æ—à–∏–±–∫–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ ‚Äî —Å–æ–æ–±—â–µ–Ω–∏–µ —É–∂–µ –ø—Ä–æ—á–∏—Ç–∞–Ω–æ
            // –ù—É–∂–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: retry, DLQ –∏–ª–∏ –ø—Ä–æ–ø—É—Å–∫
        }

        log.Printf("–æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞–∫–∞–∑ %s (partition=%d, offset=%d)",
            order.ID, msg.Partition, msg.Offset)
    }
}
```

#### Manual commit vs Auto commit

```go
// Auto commit (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) ‚Äî ReadMessage –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫–æ–º–º–∏—Ç–∏—Ç offset
reader := kafka.NewReader(kafka.ReaderConfig{
    Brokers:        []string{"localhost:9092"},
    Topic:          "orders",
    GroupID:        "order-processor",
    CommitInterval: time.Second, // –ö–æ–º–º–∏—Ç –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É
})

// Manual commit ‚Äî –¥–ª—è at-least-once –≥–∞—Ä–∞–Ω—Ç–∏–π
reader = kafka.NewReader(kafka.ReaderConfig{
    Brokers: []string{"localhost:9092"},
    Topic:   "orders",
    GroupID: "order-processor",
    // CommitInterval: 0 ‚Äî –Ω–µ –∑–∞–¥–∞—ë–º, –∫–æ–º–º–∏—Ç–∏–º –≤—Ä—É—á–Ω—É—é
})

for {
    // FetchMessage –ù–ï –∫–æ–º–º–∏—Ç–∏—Ç offset (–≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç ReadMessage)
    msg, err := reader.FetchMessage(ctx)
    if err != nil {
        break
    }

    // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    if err := processOrder(ctx, msg); err != nil {
        log.Printf("–æ—à–∏–±–∫–∞: %v", err)
        continue // –ù–µ –∫–æ–º–º–∏—Ç–∏–º ‚Äî –ø—Ä–∏ —Ä–µ—Å—Ç–∞—Ä—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ
    }

    // –ö–æ–º–º–∏—Ç–∏–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if err := reader.CommitMessages(ctx, msg); err != nil {
        log.Printf("–æ—à–∏–±–∫–∞ –∫–æ–º–º–∏—Ç–∞ offset: %v", err)
    }
}
```

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: –í Confluent.Kafka –≤—ã —É–ø—Ä–∞–≤–ª—è–µ—Ç–µ offset —á–µ—Ä–µ–∑ `consumer.Commit()` –∏–ª–∏ `EnableAutoCommit`. –í kafka-go —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É `ReadMessage` (auto commit) –∏ `FetchMessage` (manual commit) –¥–µ–ª–∞–µ—Ç –≤—ã–±–æ—Ä —è–≤–Ω—ã–º.

> ‚ö†Ô∏è **At-least-once**: –ü—Ä–∏ manual commit —Å–æ–æ–±—â–µ–Ω–∏–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ (crash –º–µ–∂–¥—É –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∏ –∫–æ–º–º–∏—Ç–æ–º). –†–µ–∞–ª–∏–∑—É–π—Ç–µ **–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å** –≤ consumer ‚Äî —Å–º. —Ä–∞–∑–¥–µ–ª [–ü–∞—Ç—Ç–µ—Ä–Ω—ã](#–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å-exactly-once-processing).

#### –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å worker pool

```go
// –ü–∞—Ç—Ç–µ—Ä–Ω: reader —á–∏—Ç–∞–µ—Ç –∏–∑ Kafka, workers –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
func consumeWithWorkers(ctx context.Context, reader *kafka.Reader, workers int) error {
    // –ö–∞–Ω–∞–ª –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –≤–æ—Ä–∫–µ—Ä–∞–º
    jobs := make(chan kafka.Message, workers*2)

    var wg sync.WaitGroup

    // –ó–∞–ø—É—Å–∫–∞–µ–º worker pool
    for i := 0; i < workers; i++ {
        wg.Add(1)
        go func(workerID int) {
            defer wg.Done()
            for msg := range jobs {
                if err := processMessage(ctx, msg); err != nil {
                    log.Printf("[worker %d] –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ offset=%d: %v",
                        workerID, msg.Offset, err)
                    continue
                }
                // –ö–æ–º–º–∏—Ç–∏–º offset –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                if err := reader.CommitMessages(ctx, msg); err != nil {
                    log.Printf("[worker %d] –æ—à–∏–±–∫–∞ –∫–æ–º–º–∏—Ç–∞: %v", workerID, err)
                }
            }
        }(i)
    }

    // –ß–∏—Ç–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –ø–µ—Ä–µ–¥–∞—ë–º –≤–æ—Ä–∫–µ—Ä–∞–º
    for {
        msg, err := reader.FetchMessage(ctx)
        if err != nil {
            if errors.Is(err, context.Canceled) {
                break
            }
            return fmt.Errorf("—á—Ç–µ–Ω–∏–µ: %w", err)
        }
        jobs <- msg
    }

    close(jobs)
    wg.Wait()
    return nil
}
```

> ‚ö†Ô∏è **–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –ø–æ—Ä—è–¥–∫–µ**: –ü—Ä–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ—Ä—è–¥–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π **–Ω–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç—Å—è**. –ï—Å–ª–∏ –ø–æ—Ä—è–¥–æ–∫ –≤–∞–∂–µ–Ω, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–π—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–π –ø–∞—Ä—Ç–∏—Ü–∏–∏. –í–∞—Ä–∏–∞–Ω—Ç ‚Äî —Å–æ–∑–¥–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π worker –Ω–∞ –∫–∞–∂–¥—É—é –ø–∞—Ä—Ç–∏—Ü–∏—é.

### Consumer Groups

Consumer groups –ø–æ–∑–≤–æ–ª—è—é—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É: Kafka —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–∞—Ä—Ç–∏—Ü–∏–∏ –º–µ–∂–¥—É —É—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏ –≥—Ä—É–ø–ø—ã. –ö–∞–∂–¥–∞—è –ø–∞—Ä—Ç–∏—Ü–∏—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è —Ä–æ–≤–Ω–æ –æ–¥–Ω–∏–º consumer –≤ –≥—Ä—É–ø–ø–µ.

```go
// –ù–µ—Å–∫–æ–ª—å–∫–æ –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤ —Å –æ–¥–Ω–∏–º GroupID –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–µ–ª—è—Ç –ø–∞—Ä—Ç–∏—Ü–∏–∏
func startConsumer(ctx context.Context, brokers []string, groupID string) {
    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers: brokers,
        Topic:   "events",
        GroupID: groupID,          // –í—Å–µ –∏–Ω—Å—Ç–∞–Ω—Å—ã —Å –æ–¥–Ω–∏–º GroupID = –æ–¥–Ω–∞ –≥—Ä—É–ø–ø–∞

        // –°—Ç—Ä–∞—Ç–µ–≥–∏—è –Ω–∞—á–∞–ª–∞ —á—Ç–µ–Ω–∏—è –¥–ª—è –Ω–æ–≤—ã—Ö –≥—Ä—É–ø–ø
        StartOffset: kafka.FirstOffset, // –ß–∏—Ç–∞—Ç—å —Å –Ω–∞—á–∞–ª–∞ (–∞–Ω–∞–ª–æ–≥ Earliest)
        // StartOffset: kafka.LastOffset, // –¢–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ (–∞–Ω–∞–ª–æ–≥ Latest)

        // Rebalance strategy
        GroupBalancers: []kafka.GroupBalancer{
            kafka.RangeGroupBalancer{},      // –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
            kafka.RoundRobinGroupBalancer{}, // –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        },

        // Heartbeat ‚Äî –∫–∞–∫ —á–∞—Å—Ç–æ consumer —Å–æ–æ–±—â–∞–µ—Ç, —á—Ç–æ –∂–∏–≤
        HeartbeatInterval: 3 * time.Second,
        // –¢–∞–π–º–∞—É—Ç —Å–µ—Å—Å–∏–∏ ‚Äî –µ—Å–ª–∏ –Ω–µ—Ç heartbeat, consumer —Å—á–∏—Ç–∞–µ—Ç—Å—è –º—ë—Ä—Ç–≤—ã–º
        SessionTimeout: 30 * time.Second,
        // –¢–∞–π–º–∞—É—Ç rebalance ‚Äî —Å–∫–æ–ª—å–∫–æ –∂–¥–∞—Ç—å –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –≤—Å–µ—Ö consumers
        RebalanceTimeout: 60 * time.Second,
    })
    defer reader.Close()

    log.Printf("consumer %s –∑–∞–ø—É—â–µ–Ω (–≥—Ä—É–ø–ø–∞: %s)", reader.Config().GroupID, groupID)

    for {
        msg, err := reader.FetchMessage(ctx)
        if err != nil {
            if errors.Is(err, context.Canceled) {
                return
            }
            log.Printf("–æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è: %v", err)
            continue
        }

        log.Printf("partition=%d offset=%d key=%s",
            msg.Partition, msg.Offset, string(msg.Key))

        if err := reader.CommitMessages(ctx, msg); err != nil {
            log.Printf("–æ—à–∏–±–∫–∞ –∫–æ–º–º–∏—Ç–∞: %v", err)
        }
    }
}
```

**–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ó–∞–ø—É—Å—Ç–∏—Ç–µ N –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤ —Å –æ–¥–Ω–∏–º `GroupID`, –∏ Kafka –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç –ø–∞—Ä—Ç–∏—Ü–∏–∏. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º = –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä—Ç–∏—Ü–∏–π –≤ —Ç–æ–ø–∏–∫–µ.

### Production –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Kafka

#### Production Writer (Producer)

```go
func newProductionWriter(brokers []string, topic string) *kafka.Writer {
    return &kafka.Writer{
        Addr:  kafka.TCP(brokers...),
        Topic: topic,

        // –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ ‚Äî –ø–æ –∫–ª—é—á—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞
        Balancer: &kafka.Hash{},

        // –ë–∞—Ç—á–∏–Ω–≥ ‚Äî –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π
        BatchSize:    100,                   // –î–æ 100 —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –±–∞—Ç—á–µ
        BatchBytes:   1048576,               // –î–æ 1 MB –≤ –±–∞—Ç—á–µ
        BatchTimeout: 10 * time.Millisecond, // –ú–∞–∫—Å–∏–º—É–º 10ms –æ–∂–∏–¥–∞–Ω–∏—è

        // –ù–∞–¥—ë–∂–Ω–æ—Å—Ç—å
        RequiredAcks: kafka.RequireAll,  // –í—Å–µ ISR —Ä–µ–ø–ª–∏–∫–∏ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª–∏
        MaxAttempts:  10,                // Retry –ø—Ä–∏ transient –æ—à–∏–±–∫–∞—Ö
        WriteTimeout: 10 * time.Second,
        ReadTimeout:  10 * time.Second,

        // –°–∂–∞—Ç–∏–µ ‚Äî —É–º–µ–Ω—å—à–∞–µ—Ç —Ç—Ä–∞—Ñ–∏–∫ –∏ –¥–∏—Å–∫–æ–≤–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ
        Compression: kafka.Zstd, // –õ—É—á—à–µ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å–∂–∞—Ç–∏–µ/—Å–∫–æ—Ä–æ—Å—Ç—å

        // –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        Logger:      kafka.LoggerFunc(log.Printf),
        ErrorLogger: kafka.LoggerFunc(log.Printf),

        // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–æ–ø–∏–∫–∞ (–æ—Ç–∫–ª—é—á–∏—Ç—å –≤ production!)
        AllowAutoTopicCreation: false,
    }
}
```

#### Production Reader (Consumer)

```go
func newProductionReader(brokers []string, topic, groupID string) *kafka.Reader {
    return kafka.NewReader(kafka.ReaderConfig{
        Brokers: brokers,
        Topic:   topic,
        GroupID: groupID,

        // –†–∞–∑–º–µ—Ä fetch
        MinBytes: 1,          // –ù–µ –∂–¥–∞—Ç—å –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è
        MaxBytes: 10 << 20,   // 10 MB –º–∞–∫—Å–∏–º—É–º –∑–∞ fetch

        // Offset management
        StartOffset:    kafka.LastOffset,  // –ù–æ–≤—ã–µ –≥—Ä—É–ø–ø—ã —á–∏—Ç–∞—é—Ç —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ
        CommitInterval: 0,                 // Manual commit

        // –¢–∞–π–º–∞—É—Ç—ã
        MaxWait:           500 * time.Millisecond,
        HeartbeatInterval: 3 * time.Second,
        SessionTimeout:    30 * time.Second,
        RebalanceTimeout:  60 * time.Second,

        // Retry
        RetentionTime: 7 * 24 * time.Hour, // –•—Ä–∞–Ω–∏—Ç—å offset 7 –¥–Ω–µ–π

        // –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        Logger:      kafka.LoggerFunc(log.Printf),
        ErrorLogger: kafka.LoggerFunc(log.Printf),
    })
}
```

#### TLS –∏ SASL –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è

```go
import (
    "crypto/tls"
    "crypto/x509"
    "os"

    "github.com/segmentio/kafka-go"
    "github.com/segmentio/kafka-go/sasl/scram"
)

func newTLSWriter(brokers []string, topic string) (*kafka.Writer, error) {
    // –ó–∞–≥—Ä—É–∂–∞–µ–º CA —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç
    caCert, err := os.ReadFile("/etc/kafka/ca.crt")
    if err != nil {
        return nil, fmt.Errorf("—á—Ç–µ–Ω–∏–µ CA —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞: %w", err)
    }
    caCertPool := x509.NewCertPool()
    caCertPool.AppendCertsFromPEM(caCert)

    // SASL/SCRAM –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
    mechanism, err := scram.Mechanism(scram.SHA512,
        os.Getenv("KAFKA_USERNAME"),
        os.Getenv("KAFKA_PASSWORD"),
    )
    if err != nil {
        return nil, fmt.Errorf("SASL –º–µ—Ö–∞–Ω–∏–∑–º: %w", err)
    }

    // Dialer —Å TLS –∏ SASL
    dialer := &kafka.Dialer{
        SASLMechanism: mechanism,
        TLS: &tls.Config{
            RootCAs: caCertPool,
        },
    }

    transport := &kafka.Transport{
        TLS:  dialer.TLS,
        SASL: mechanism,
    }

    return &kafka.Writer{
        Addr:      kafka.TCP(brokers...),
        Topic:     topic,
        Transport: transport,
    }, nil
}
```

### Error Handling –∏ Dead Letter Topics

–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç MassTransit, –≥–¥–µ `_error` –∏ `_skipped` –æ—á–µ—Ä–µ–¥–∏ —Å–æ–∑–¥–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –≤ Go –≤—ã —Ä–µ–∞–ª–∏–∑—É–µ—Ç–µ Dead Letter Topic (DLT) –≤—Ä—É—á–Ω—É—é.

#### –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ—à–∏–±–æ–∫

```go
// Transient –æ—à–∏–±–∫–∏ ‚Äî –≤—Ä–µ–º–µ–Ω–Ω—ã–µ, –∏–º–µ–µ—Ç —Å–º—ã—Å–ª retry
// Permanent –æ—à–∏–±–∫–∏ ‚Äî –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ –ø–æ–º–æ–∂–µ—Ç

type permanentError struct {
    err error
}

func (e *permanentError) Error() string { return e.err.Error() }
func (e *permanentError) Unwrap() error { return e.err }

func isPermanent(err error) bool {
    var pe *permanentError
    return errors.As(err, &pe)
}

// –ü—Ä–∏–º–µ—Ä—ã:
// - JSON unmarshal error ‚Üí permanent (–¥–∞–Ω–Ω—ã–µ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã)
// - Database timeout ‚Üí transient (–ø–æ–≤—Ç–æ—Ä–∏—Ç—å)
// - Business rule violation ‚Üí permanent
// - Network error ‚Üí transient
```

#### Dead Letter Topic —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è

```go
type ConsumerWithDLT struct {
    reader    *kafka.Reader
    dlWriter  *kafka.Writer // Writer –¥–ª—è Dead Letter Topic
    maxRetry  int
}

func NewConsumerWithDLT(brokers []string, topic, groupID string, maxRetry int) *ConsumerWithDLT {
    return &ConsumerWithDLT{
        reader: kafka.NewReader(kafka.ReaderConfig{
            Brokers: brokers,
            Topic:   topic,
            GroupID: groupID,
        }),
        dlWriter: &kafka.Writer{
            Addr:  kafka.TCP(brokers...),
            Topic: topic + ".dlq", // –ö–æ–Ω–≤–µ–Ω—Ü–∏—è: <topic>.dlq
        },
        maxRetry: maxRetry,
    }
}

func (c *ConsumerWithDLT) Run(ctx context.Context) error {
    defer c.reader.Close()
    defer c.dlWriter.Close()

    for {
        msg, err := c.reader.FetchMessage(ctx)
        if err != nil {
            if errors.Is(err, context.Canceled) {
                return nil
            }
            return fmt.Errorf("fetch: %w", err)
        }

        if err := c.processWithRetry(ctx, msg); err != nil {
            // –í—Å–µ retry –∏—Å—á–µ—Ä–ø–∞–Ω—ã –∏–ª–∏ permanent error ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ DLT
            if dlErr := c.sendToDLT(ctx, msg, err); dlErr != nil {
                log.Printf("–ö–†–ò–¢–ò–ß–ù–û: –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ DLT: %v", dlErr)
                // –ù–µ –∫–æ–º–º–∏—Ç–∏–º ‚Äî —Å–æ–æ–±—â–µ–Ω–∏–µ –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ
                continue
            }
            log.Printf("—Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ DLT (offset=%d): %v", msg.Offset, err)
        }

        // –ö–æ–º–º–∏—Ç–∏–º offset (—É—Å–ø–µ—Ö –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ DLT)
        if err := c.reader.CommitMessages(ctx, msg); err != nil {
            log.Printf("–æ—à–∏–±–∫–∞ –∫–æ–º–º–∏—Ç–∞: %v", err)
        }
    }
}

func (c *ConsumerWithDLT) processWithRetry(ctx context.Context, msg kafka.Message) error {
    var lastErr error

    for attempt := 0; attempt <= c.maxRetry; attempt++ {
        err := processMessage(ctx, msg)
        if err == nil {
            return nil
        }

        // Permanent error ‚Äî –Ω–µ retry
        if isPermanent(err) {
            return err
        }

        lastErr = err
        if attempt < c.maxRetry {
            // Exponential backoff: 100ms, 200ms, 400ms, 800ms, ...
            backoff := time.Duration(100<<uint(attempt)) * time.Millisecond
            log.Printf("retry %d/%d —á–µ—Ä–µ–∑ %v: %v", attempt+1, c.maxRetry, backoff, err)

            select {
            case <-time.After(backoff):
            case <-ctx.Done():
                return ctx.Err()
            }
        }
    }

    return fmt.Errorf("–∏—Å—á–µ—Ä–ø–∞–Ω—ã retry (%d –ø–æ–ø—ã—Ç–æ–∫): %w", c.maxRetry, lastErr)
}

func (c *ConsumerWithDLT) sendToDLT(ctx context.Context, original kafka.Message, processingErr error) error {
    // –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ—à–∏–±–∫–∏ –≤ headers
    headers := make([]kafka.Header, len(original.Headers))
    copy(headers, original.Headers)

    headers = append(headers,
        kafka.Header{Key: "dlq-error", Value: []byte(processingErr.Error())},
        kafka.Header{Key: "dlq-original-topic", Value: []byte(original.Topic)},
        kafka.Header{Key: "dlq-original-partition", Value: []byte(fmt.Sprintf("%d", original.Partition))},
        kafka.Header{Key: "dlq-original-offset", Value: []byte(fmt.Sprintf("%d", original.Offset))},
        kafka.Header{Key: "dlq-timestamp", Value: []byte(time.Now().UTC().Format(time.RFC3339))},
    )

    return c.dlWriter.WriteMessages(ctx, kafka.Message{
        Key:     original.Key,
        Value:   original.Value,
        Headers: headers,
    })
}
```

**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å C# MassTransit**:

| –ê—Å–ø–µ–∫—Ç | C# MassTransit | Go (—Ä—É—á–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è) |
|--------|----------------|----------------------|
| **DLQ —Å–æ–∑–¥–∞–Ω–∏–µ** | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (`_error` queue) | –í—Ä—É—á–Ω—É—é (—Å–æ–∑–¥–∞—Ç—å —Ç–æ–ø–∏–∫, –Ω–∞–ø–∏—Å–∞—Ç—å –ª–æ–≥–∏–∫—É) |
| **Retry** | `UseMessageRetry(r => r.Exponential(...))` | –¶–∏–∫–ª —Å backoff |
| **Error context** | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (exception details) | Headers —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –æ—à–∏–±–∫–∏ |
| **Reprocessing** | MassTransit Retry/Redelivery | –ß–∏—Ç–∞–µ–º –∏–∑ DLT –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ |
| **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è** | Fluent API | –Ø–≤–Ω—ã–π –∫–æ–¥ |

> üí° **–°–æ–≤–µ—Ç**: –°–æ–∑–¥–∞–π—Ç–µ —É—Ç–∏–ª–∏—Ç—É –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ DLT ‚Äî Prometheus –º–µ—Ç—Ä–∏–∫—É `dlq_messages_total` –∏ alert, –∫–æ–≥–¥–∞ DLT –Ω–∞—á–∏–Ω–∞–µ—Ç —Ä–∞—Å—Ç–∏.

---

## RabbitMQ (amqp091-go)

RabbitMQ ‚Äî –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –±—Ä–æ–∫–µ—Ä —Å–æ–æ–±—â–µ–Ω–∏–π, —Ä–µ–∞–ª–∏–∑—É—é—â–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª AMQP 0.9.1. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç Kafka (–ª–æ–≥ —Å–æ–±—ã—Ç–∏–π), RabbitMQ ‚Äî —ç—Ç–æ **–æ—á–µ—Ä–µ–¥—å**: —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –æ–¥–Ω–æ–º—É consumer –∏ —É–¥–∞–ª—è–µ—Ç—Å—è –ø–æ—Å–ª–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è. RabbitMQ –æ—Ç–ª–∏—á–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è task queues, RPC –∏ —Å–ª–æ–∂–Ω–æ–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏.

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: RabbitMQ ‚Äî —Å–∞–º—ã–π –ø–æ–ø—É–ª—è—Ä–Ω—ã–π –±—Ä–æ–∫–µ—Ä –≤ .NET —ç–∫–æ—Å–∏—Å—Ç–µ–º–µ. –í—ã –Ω–∞–≤–µ—Ä–Ω—è–∫–∞ —Ä–∞–±–æ—Ç–∞–ª–∏ —Å –Ω–∏–º —á–µ—Ä–µ–∑ MassTransit, –∫–æ—Ç–æ—Ä—ã–π —Å–∫—Ä—ã–≤–∞–µ—Ç AMQP-–¥–µ—Ç–∞–ª–∏ (exchanges, bindings, channels). –í Go –≤—ã —Ä–∞–±–æ—Ç–∞–µ—Ç–µ —Å AMQP –Ω–∞–ø—Ä—è–º—É—é ‚Äî —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –≤—ã –¥–æ–ª–∂–Ω—ã –ø–æ–Ω–∏–º–∞—Ç—å, –∫–∞–∫ —É—Å—Ç—Ä–æ–µ–Ω—ã exchanges –∏ bindings.

–£—Å—Ç–∞–Ω–æ–≤–∫–∞:

```bash
go get github.com/rabbitmq/amqp091-go
```

### –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–∞–Ω–∞–ª–∞–º–∏

#### –ë–∞–∑–æ–≤–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ

```go
import amqp "github.com/rabbitmq/amqp091-go"

func connectRabbitMQ(url string) (*amqp.Connection, *amqp.Channel, error) {
    // –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ RabbitMQ
    conn, err := amqp.Dial(url)
    if err != nil {
        return nil, nil, fmt.Errorf("–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ RabbitMQ: %w", err)
    }

    // –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞ ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π –æ–±—ä–µ–∫—Ç –¥–ª—è –æ–ø–µ—Ä–∞—Ü–∏–π
    ch, err := conn.Channel()
    if err != nil {
        conn.Close()
        return nil, nil, fmt.Errorf("—Å–æ–∑–¥–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞: %w", err)
    }

    return conn, ch, nil
}

func main() {
    conn, ch, err := connectRabbitMQ("amqp://guest:guest@localhost:5672/")
    if err != nil {
        log.Fatal(err)
    }
    defer conn.Close()
    defer ch.Close()

    log.Println("–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ RabbitMQ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
}
```

**C#** (RabbitMQ.Client):
```csharp
var factory = new ConnectionFactory
{
    HostName = "localhost",
    UserName = "guest",
    Password = "guest"
};
await using var connection = await factory.CreateConnectionAsync();
await using var channel = await connection.CreateChannelAsync();
```

> ‚ö†Ô∏è **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ**: –ö–∞–Ω–∞–ª—ã (`amqp.Channel`) **–ù–ï goroutine-safe**! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–¥–∏–Ω –∫–∞–Ω–∞–ª –Ω–∞ –≥–æ—Ä—É—Ç–∏–Ω—É. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏—è (`amqp.Connection`) ‚Äî –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω—ã. –í C# `IChannel` —Ç–∞–∫–∂–µ –Ω–µ thread-safe, –Ω–æ MassTransit —Å–∫—Ä—ã–≤–∞–µ—Ç —ç—Ç–æ –∑–∞ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–µ–π.

#### –ü—É–ª –∫–∞–Ω–∞–ª–æ–≤

```go
// ChannelPool ‚Äî –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–∞–Ω–∞–ª–∞–º–∏ –¥–ª—è concurrent –¥–æ—Å—Ç—É–ø–∞
type ChannelPool struct {
    conn *amqp.Connection
    pool chan *amqp.Channel
}

func NewChannelPool(conn *amqp.Connection, size int) (*ChannelPool, error) {
    pool := make(chan *amqp.Channel, size)

    for i := 0; i < size; i++ {
        ch, err := conn.Channel()
        if err != nil {
            return nil, fmt.Errorf("—Å–æ–∑–¥–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞ %d: %w", i, err)
        }
        pool <- ch
    }

    return &ChannelPool{conn: conn, pool: pool}, nil
}

// Get ‚Äî –ø–æ–ª—É—á–∏—Ç—å –∫–∞–Ω–∞–ª –∏–∑ –ø—É–ª–∞ (–±–ª–æ–∫–∏—Ä—É–µ—Ç, –µ—Å–ª–∏ –ø—É–ª –ø—É—Å—Ç)
func (p *ChannelPool) Get() *amqp.Channel {
    return <-p.pool
}

// Put ‚Äî –≤–µ—Ä–Ω—É—Ç—å –∫–∞–Ω–∞–ª –≤ –ø—É–ª
func (p *ChannelPool) Put(ch *amqp.Channel) {
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–∞–Ω–∞–ª –µ—â—ë –∂–∏–≤
    if ch.IsClosed() {
        newCh, err := p.conn.Channel()
        if err != nil {
            log.Printf("–æ—à–∏–±–∫–∞ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è –∫–∞–Ω–∞–ª–∞: %v", err)
            return
        }
        ch = newCh
    }
    p.pool <- ch
}

// WithChannel ‚Äî –≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏—é —Å –∫–∞–Ω–∞–ª–æ–º –∏–∑ –ø—É–ª–∞
func (p *ChannelPool) WithChannel(fn func(*amqp.Channel) error) error {
    ch := p.Get()
    defer p.Put(ch)
    return fn(ch)
}

func (p *ChannelPool) Close() {
    close(p.pool)
    for ch := range p.pool {
        ch.Close()
    }
}
```

### Exchanges, Queues, Bindings

RabbitMQ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å exchange ‚Üí binding ‚Üí queue. –°–æ–æ–±—â–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –≤ exchange, –∫–æ—Ç–æ—Ä—ã–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∏—Ä—É–µ—Ç –∏—Ö –≤ –æ—á–µ—Ä–µ–¥–∏ —á–µ—Ä–µ–∑ bindings.

#### –¢–∏–ø—ã exchange

| –¢–∏–ø | –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è | –ê–Ω–∞–ª–æ–≥ –≤ C# MassTransit | –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è |
|-----|--------------|-------------------------|---------------------|
| **direct** | –ü–æ —Ç–æ—á–Ω–æ–º—É routing key | Endpoint name | –¢–æ—á–µ—á–Ω–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞ |
| **fanout** | –í–æ –≤—Å–µ –ø—Ä–∏–≤—è–∑–∞–Ω–Ω—ã–µ –æ—á–µ—Ä–µ–¥–∏ | `Publish<T>()` (–≤—Å–µ consumers) | Broadcast, notifications |
| **topic** | –ü–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É routing key | `Publish<T>()` —Å —Ñ–∏–ª—å—Ç—Ä–æ–º | –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ —É—Ä–æ–≤–Ω—è–º |
| **headers** | –ü–æ headers —Å–æ–æ–±—â–µ–Ω–∏—è | –†–µ–¥–∫–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è | –°–ª–æ–∂–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è |

```go
func setupTopology(ch *amqp.Channel) error {
    // –û–±—ä—è–≤–ª—è–µ–º exchange
    err := ch.ExchangeDeclare(
        "orders",  // –ò–º—è
        "topic",   // –¢–∏–ø
        true,      // Durable ‚Äî –ø–µ—Ä–µ–∂–∏–≤—ë—Ç —Ä–µ—Å—Ç–∞—Ä—Ç RabbitMQ
        false,     // Auto-delete ‚Äî –Ω–µ —É–¥–∞–ª—è—Ç—å –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ bindings
        false,     // Internal ‚Äî –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è publish
        false,     // No-wait ‚Äî –∂–¥–∞—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞
        nil,       // Arguments
    )
    if err != nil {
        return fmt.Errorf("exchange declare: %w", err)
    }

    // –û–±—ä—è–≤–ª—è–µ–º –æ—á–µ—Ä–µ–¥—å
    q, err := ch.QueueDeclare(
        "order-processor", // –ò–º—è –æ—á–µ—Ä–µ–¥–∏
        true,              // Durable
        false,             // Auto-delete
        false,             // Exclusive (—Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ)
        false,             // No-wait
        amqp.Table{
            // Dead letter exchange –¥–ª—è –æ—Ç–∫–ª–æ–Ω—ë–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
            "x-dead-letter-exchange":    "orders.dlx",
            "x-dead-letter-routing-key": "dead",
            // –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—á–µ—Ä–µ–¥–∏ (overflow ‚Üí DLX)
            "x-max-length": int32(100000),
            // TTL —Å–æ–æ–±—â–µ–Ω–∏–π ‚Äî 24 —á–∞—Å–∞
            "x-message-ttl": int32(86400000),
        },
    )
    if err != nil {
        return fmt.Errorf("queue declare: %w", err)
    }

    // –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –æ—á–µ—Ä–µ–¥—å –∫ exchange —Å routing key –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º
    err = ch.QueueBind(
        q.Name,            // –û—á–µ—Ä–µ–¥—å
        "order.created",   // Routing key (–ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è topic exchange)
        "orders",          // Exchange
        false,             // No-wait
        nil,               // Arguments
    )
    if err != nil {
        return fmt.Errorf("queue bind: %w", err)
    }

    // –î–ª—è topic exchange: –ø—Ä–∏–≤—è–∑–∫–∞ —Å wildcard
    // "order.*" ‚Äî order.created, order.updated, order.deleted
    // "order.#" ‚Äî order.created, order.payment.completed
    err = ch.QueueBind(q.Name, "order.*", "orders", false, nil)

    log.Printf("—Ç–æ–ø–æ–ª–æ–≥–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞: exchange=%s, queue=%s", "orders", q.Name)
    return nil
}
```

### Publishing: –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∏ –≥–∞—Ä–∞–Ω—Ç–∏–∏

#### –ë–∞–∑–æ–≤–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è

```go
func publishOrder(ctx context.Context, ch *amqp.Channel, order Order) error {
    body, err := json.Marshal(order)
    if err != nil {
        return fmt.Errorf("—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è: %w", err)
    }

    return ch.PublishWithContext(ctx,
        "orders",        // Exchange
        "order.created", // Routing key
        false,           // Mandatory ‚Äî –≤–µ—Ä–Ω—É—Ç—å, –µ—Å–ª–∏ –Ω–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–µ–π –æ—á–µ—Ä–µ–¥–∏
        false,           // Immediate (deprecated –≤ RabbitMQ 3.x)
        amqp.Publishing{
            ContentType:  "application/json",
            DeliveryMode: amqp.Persistent, // –°–æ–æ–±—â–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –Ω–∞ –¥–∏—Å–∫
            MessageId:    uuid.NewString(), // –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
            Timestamp:    time.Now(),
            Type:         "OrderCreated",
            Body:         body,
        },
    )
}
```

#### Publisher Confirms

```go
// Publisher confirms ‚Äî RabbitMQ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç, —á—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∞–Ω–æ
func publishWithConfirm(ctx context.Context, ch *amqp.Channel, order Order) error {
    // –í–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º confirm
    if err := ch.Confirm(false); err != nil {
        return fmt.Errorf("–≤–∫–ª—é—á–µ–Ω–∏–µ confirm mode: %w", err)
    }

    // –ö–∞–Ω–∞–ª –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π
    confirms := ch.NotifyPublish(make(chan amqp.Confirmation, 1))

    body, err := json.Marshal(order)
    if err != nil {
        return fmt.Errorf("—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è: %w", err)
    }

    err = ch.PublishWithContext(ctx,
        "orders",
        "order.created",
        true, // Mandatory ‚Äî –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ—Å—Ç–∞–≤–∏—Ç—å
        false,
        amqp.Publishing{
            ContentType:  "application/json",
            DeliveryMode: amqp.Persistent,
            MessageId:    uuid.NewString(),
            Body:         body,
        },
    )
    if err != nil {
        return fmt.Errorf("publish: %w", err)
    }

    // –ñ–¥—ë–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –æ—Ç RabbitMQ
    select {
    case confirm := <-confirms:
        if !confirm.Ack {
            return fmt.Errorf("—Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ (nack)")
        }
        return nil
    case <-ctx.Done():
        return ctx.Err()
    case <-time.After(5 * time.Second):
        return fmt.Errorf("—Ç–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è")
    }
}
```

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: –í RabbitMQ.Client —ç—Ç–æ `channel.WaitForConfirmsAsync()`. MassTransit –≤–∫–ª—é—á–∞–µ—Ç publisher confirms –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏. –í Go ‚Äî —è–≤–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —á–µ—Ä–µ–∑ `ch.Confirm()`.

### Consuming: prefetch, ack/nack

```go
func consumeOrders(ctx context.Context, ch *amqp.Channel) error {
    // Prefetch ‚Äî –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ unacked —Å–æ–æ–±—â–µ–Ω–∏–π
    // –≠—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è backpressure –∏ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    err := ch.Qos(
        10,    // Prefetch count ‚Äî –º–∞–∫—Å–∏–º—É–º 10 unacked –Ω–∞ consumer
        0,     // Prefetch size ‚Äî 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ —Ä–∞–∑–º–µ—Ä—É
        false, // Global ‚Äî false = per consumer, true = per channel
    )
    if err != nil {
        return fmt.Errorf("–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ QoS: %w", err)
    }

    // –ù–∞—á–∏–Ω–∞–µ–º –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ
    deliveries, err := ch.Consume(
        "order-processor", // –û—á–µ—Ä–µ–¥—å
        "worker-1",        // Consumer tag (—É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä)
        false,             // Auto-ack: false = manual ack
        false,             // Exclusive
        false,             // No-local
        false,             // No-wait
        nil,               // Arguments
    )
    if err != nil {
        return fmt.Errorf("consume: %w", err)
    }

    for {
        select {
        case d, ok := <-deliveries:
            if !ok {
                return fmt.Errorf("–∫–∞–Ω–∞–ª deliveries –∑–∞–∫—Ä—ã—Ç")
            }

            var order Order
            if err := json.Unmarshal(d.Body, &order); err != nil {
                // –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ‚Äî reject –±–µ–∑ requeue (–ø–æ–π–¥—É—Ç –≤ DLX)
                log.Printf("–Ω–µ–≤–∞–ª–∏–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: %v", err)
                d.Reject(false) // false = –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –≤ –æ—á–µ—Ä–µ–¥—å
                continue
            }

            if err := processOrder(ctx, order); err != nil {
                // –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ ‚Äî nack —Å requeue –¥–ª—è retry
                log.Printf("–æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: %v", err)
                d.Nack(false, true) // multiple=false, requeue=true
                continue
            }

            // –£—Å–ø–µ—à–Ω–æ ‚Äî ack
            d.Ack(false) // multiple=false (–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ–º —Ç–æ–ª—å–∫–æ —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ)

        case <-ctx.Done():
            return nil
        }
    }
}
```

#### Worker Pool –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏

```go
func consumeWithWorkerPool(ctx context.Context, ch *amqp.Channel, workers int) error {
    // Prefetch = 2x workers ‚Äî –≤—Å–µ–≥–¥–∞ –µ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if err := ch.Qos(workers*2, 0, false); err != nil {
        return fmt.Errorf("QoS: %w", err)
    }

    deliveries, err := ch.Consume("order-processor", "", false, false, false, false, nil)
    if err != nil {
        return fmt.Errorf("consume: %w", err)
    }

    var wg sync.WaitGroup
    // –ó–∞–ø—É—Å–∫–∞–µ–º workers –≥–æ—Ä—É—Ç–∏–Ω, –∫–∞–∂–¥–∞—è —á–∏—Ç–∞–µ—Ç –∏–∑ –æ–¥–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞ deliveries
    for i := 0; i < workers; i++ {
        wg.Add(1)
        go func(workerID int) {
            defer wg.Done()
            for {
                select {
                case d, ok := <-deliveries:
                    if !ok {
                        return
                    }
                    if err := processDelivery(ctx, d); err != nil {
                        log.Printf("[worker %d] –æ—à–∏–±–∫–∞: %v", workerID, err)
                        d.Nack(false, true)
                    } else {
                        d.Ack(false)
                    }
                case <-ctx.Done():
                    return
                }
            }
        }(i)
    }

    wg.Wait()
    return nil
}
```

> üí° **–ü–æ–¥—Å–∫–∞–∑–∫–∞ –ø–æ prefetch**: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π—Ç–µ `prefetch = 2 * workers`. –≠—Ç–æ –æ–±–µ—Å–ø–µ—á–∏—Ç, —á—Ç–æ –∫–∞–∂–¥—ã–π worker –≤—Å–µ–≥–¥–∞ –∏–º–µ–µ—Ç —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏, –º–∏–Ω–∏–º–∏–∑–∏—Ä—É—è –ø—Ä–æ—Å—Ç–æ–π.

**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ ack/nack —Å C#**:

| –î–µ–π—Å—Ç–≤–∏–µ | C# (RabbitMQ.Client) | Go (amqp091-go) |
|----------|---------------------|-----------------|
| **–ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å** | `channel.BasicAckAsync(tag, false)` | `d.Ack(false)` |
| **–û—Ç–∫–ª–æ–Ω–∏—Ç—å + requeue** | `channel.BasicNackAsync(tag, false, true)` | `d.Nack(false, true)` |
| **–û—Ç–∫–ª–æ–Ω–∏—Ç—å –±–µ–∑ requeue** | `channel.BasicRejectAsync(tag, false)` | `d.Reject(false)` |
| **Auto ack** | `autoAck: true` –≤ `BasicConsumeAsync` | `autoAck: true` –≤ `Consume` |

### Connection Recovery –∏ Reconnection

–≠—Ç–æ **—Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π** production-–∞—Å–ø–µ–∫—Ç RabbitMQ –≤ Go. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç C#, –≥–¥–µ `RabbitMQ.Client` –∏–º–µ–µ—Ç `AutomaticRecoveryEnabled = true`, –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ `amqp091-go` **–Ω–µ —Ä–µ–∞–ª–∏–∑—É–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ**.

> ‚ö†Ô∏è **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –æ—Ç–ª–∏—á–∏–µ –æ—Ç C#**: –í .NET –≤—ã —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç–µ `factory.AutomaticRecoveryEnabled = true` –∏ –∑–∞–±—ã–≤–∞–µ—Ç–µ. –í Go –≤—ã **–æ–±—è–∑–∞–Ω—ã** —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å reconnection —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ. –ë–µ–∑ —ç—Ç–æ–≥–æ –ª—é–±–æ–π —Å–µ—Ç–µ–≤–æ–π —Å–±–æ–π —É–±—å—ë—Ç –≤–∞—à —Å–µ—Ä–≤–∏—Å.

```go
// RabbitMQClient ‚Äî –æ–±—ë—Ä—Ç–∫–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º
type RabbitMQClient struct {
    url        string
    conn       *amqp.Connection
    ch         *amqp.Channel
    mu         sync.RWMutex
    done       chan struct{}
    notifyClose chan *amqp.Error
}

func NewRabbitMQClient(url string) (*RabbitMQClient, error) {
    client := &RabbitMQClient{
        url:  url,
        done: make(chan struct{}),
    }

    if err := client.connect(); err != nil {
        return nil, err
    }

    go client.reconnectLoop()

    return client, nil
}

func (c *RabbitMQClient) connect() error {
    conn, err := amqp.Dial(c.url)
    if err != nil {
        return fmt.Errorf("dial: %w", err)
    }

    ch, err := conn.Channel()
    if err != nil {
        conn.Close()
        return fmt.Errorf("channel: %w", err)
    }

    c.mu.Lock()
    c.conn = conn
    c.ch = ch
    c.notifyClose = conn.NotifyClose(make(chan *amqp.Error, 1))
    c.mu.Unlock()

    log.Println("–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ RabbitMQ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
    return nil
}

func (c *RabbitMQClient) reconnectLoop() {
    for {
        select {
        case <-c.done:
            return
        case amqpErr, ok := <-c.notifyClose:
            if !ok {
                return // –®—Ç–∞—Ç–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ
            }
            log.Printf("—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å RabbitMQ –ø–æ—Ç–µ—Ä—è–Ω–æ: %v", amqpErr)

            // Exponential backoff —Å jitter
            for attempt := 0; ; attempt++ {
                backoff := time.Duration(math.Min(
                    float64(time.Second)*math.Pow(2, float64(attempt)),
                    float64(30*time.Second),
                ))
                // –î–æ–±–∞–≤–ª—è–µ–º jitter ¬±25%
                jitter := time.Duration(rand.Int63n(int64(backoff) / 2))
                backoff = backoff + jitter

                log.Printf("–ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ RabbitMQ —á–µ—Ä–µ–∑ %v (–ø–æ–ø—ã—Ç–∫–∞ %d)...", backoff, attempt+1)

                select {
                case <-time.After(backoff):
                case <-c.done:
                    return
                }

                if err := c.connect(); err != nil {
                    log.Printf("–æ—à–∏–±–∫–∞ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: %v", err)
                    continue
                }

                log.Println("–ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ RabbitMQ —É—Å–ø–µ—à–Ω–æ")
                break
            }
        }
    }
}

// Channel ‚Äî –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π –∫–∞–Ω–∞–ª (–ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ)
func (c *RabbitMQClient) Channel() *amqp.Channel {
    c.mu.RLock()
    defer c.mu.RUnlock()
    return c.ch
}

// Publish ‚Äî –ø—É–±–ª–∏–∫–∞—Ü–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º retry –ø—Ä–∏ –ø–æ—Ç–µ—Ä–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
func (c *RabbitMQClient) Publish(ctx context.Context, exchange, routingKey string, msg amqp.Publishing) error {
    for attempt := 0; attempt < 3; attempt++ {
        ch := c.Channel()
        if ch == nil {
            time.Sleep(time.Second)
            continue
        }

        err := ch.PublishWithContext(ctx, exchange, routingKey, false, false, msg)
        if err == nil {
            return nil
        }

        // –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ —Å–≤—è–∑–∞–Ω–∞ —Å –∑–∞–∫—Ä—ã—Ç—ã–º –∫–∞–Ω–∞–ª–æ–º, –∂–¥—ë–º reconnect
        if errors.Is(err, amqp.ErrClosed) {
            log.Printf("–∫–∞–Ω–∞–ª –∑–∞–∫—Ä—ã—Ç, –æ–∂–∏–¥–∞–µ–º –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è...")
            time.Sleep(time.Second * time.Duration(attempt+1))
            continue
        }

        return err
    }

    return fmt.Errorf("publish –Ω–µ —É–¥–∞–ª—Å—è –ø–æ—Å–ª–µ 3 –ø–æ–ø—ã—Ç–æ–∫")
}

func (c *RabbitMQClient) Close() {
    close(c.done)
    c.mu.Lock()
    defer c.mu.Unlock()
    if c.ch != nil {
        c.ch.Close()
    }
    if c.conn != nil {
        c.conn.Close()
    }
}
```

### Dead Letter Exchanges (DLX)

DLX ‚Äî –º–µ—Ö–∞–Ω–∏–∑–º RabbitMQ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —É–¥–∞–ª–æ—Å—å –¥–æ—Å—Ç–∞–≤–∏—Ç—å: –æ—Ç–∫–ª–æ–Ω—ë–Ω–Ω—ã–µ (`reject`/`nack` –±–µ–∑ requeue), expired (TTL) –∏–ª–∏ overflow (–æ—á–µ—Ä–µ–¥—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞).

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     publish     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     binding     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Producer ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ Exchange ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ   Queue    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                               ‚îÇ
                                                          reject/nack
                                                          TTL expired
                                                          overflow
                                                               ‚îÇ
                                                               ‚ñº
                                                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                         ‚îÇ   DLX    ‚îÇ ‚îÄ‚îÄ‚Üí ‚îÇ DLQ      ‚îÇ
                                                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ DLX

```go
func setupDLX(ch *amqp.Channel) error {
    // 1. –°–æ–∑–¥–∞—ë–º Dead Letter Exchange
    err := ch.ExchangeDeclare("orders.dlx", "direct", true, false, false, false, nil)
    if err != nil {
        return fmt.Errorf("DLX exchange: %w", err)
    }

    // 2. –°–æ–∑–¥–∞—ë–º Dead Letter Queue
    _, err = ch.QueueDeclare("orders.dlq", true, false, false, false, nil)
    if err != nil {
        return fmt.Errorf("DLQ queue: %w", err)
    }

    // 3. –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º DLQ –∫ DLX
    err = ch.QueueBind("orders.dlq", "dead", "orders.dlx", false, nil)
    if err != nil {
        return fmt.Errorf("DLQ bind: %w", err)
    }

    // 4. –û—Å–Ω–æ–≤–Ω–∞—è –æ—á–µ—Ä–µ–¥—å —Å —É–∫–∞–∑–∞–Ω–∏–µ–º DLX
    _, err = ch.QueueDeclare(
        "order-processor",
        true, false, false, false,
        amqp.Table{
            "x-dead-letter-exchange":    "orders.dlx",
            "x-dead-letter-routing-key": "dead",
        },
    )
    if err != nil {
        return fmt.Errorf("main queue: %w", err)
    }

    return nil
}
```

#### Retry —á–µ—Ä–µ–∑ —Ü–µ–ø–æ—á–∫—É DLX + TTL

```go
// –ü–∞—Ç—Ç–µ—Ä–Ω: retry —á–µ—Ä–µ–∑ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –æ—á–µ—Ä–µ–¥–∏ —Å TTL
// –°–æ–æ–±—â–µ–Ω–∏–µ ‚Üí retry-queue (TTL=5s) ‚Üí expire ‚Üí DLX ‚Üí –æ—Å–Ω–æ–≤–Ω–∞—è –æ—á–µ—Ä–µ–¥—å
func setupRetryTopology(ch *amqp.Channel) error {
    // –û—Å–Ω–æ–≤–Ω–æ–π exchange
    ch.ExchangeDeclare("orders", "direct", true, false, false, false, nil)
    // Retry exchange
    ch.ExchangeDeclare("orders.retry", "direct", true, false, false, false, nil)
    // DLX –¥–ª—è –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç–∫–∞–∑–æ–≤
    ch.ExchangeDeclare("orders.dlx", "direct", true, false, false, false, nil)

    // Retry –æ—á–µ—Ä–µ–¥—å —Å TTL ‚Äî —Å–æ–æ–±—â–µ–Ω–∏—è ¬´–æ—Ç–ª—ë–∂–∏–≤–∞—é—Ç—Å—è¬ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç—Å—è
    ch.QueueDeclare("orders.retry.5s", true, false, false, false, amqp.Table{
        "x-dead-letter-exchange":    "orders",      // –ü–æ—Å–ª–µ TTL ‚Üí –æ–±—Ä–∞—Ç–Ω–æ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π exchange
        "x-dead-letter-routing-key": "process",
        "x-message-ttl":             int32(5000),   // 5 —Å–µ–∫—É–Ω–¥
    })
    ch.QueueBind("orders.retry.5s", "retry", "orders.retry", false, nil)

    ch.QueueDeclare("orders.retry.30s", true, false, false, false, amqp.Table{
        "x-dead-letter-exchange":    "orders",
        "x-dead-letter-routing-key": "process",
        "x-message-ttl":             int32(30000), // 30 —Å–µ–∫—É–Ω–¥
    })
    ch.QueueBind("orders.retry.30s", "retry-slow", "orders.retry", false, nil)

    // –û—Å–Ω–æ–≤–Ω–∞—è –æ—á–µ—Ä–µ–¥—å
    ch.QueueDeclare("order-processor", true, false, false, false, amqp.Table{
        "x-dead-letter-exchange":    "orders.dlx",
        "x-dead-letter-routing-key": "dead",
    })
    ch.QueueBind("order-processor", "process", "orders", false, nil)

    // DLQ
    ch.QueueDeclare("orders.dlq", true, false, false, false, nil)
    ch.QueueBind("orders.dlq", "dead", "orders.dlx", false, nil)

    return nil
}

// –ü—Ä–∏ –æ—à–∏–±–∫–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ retry queue
func retryMessage(ch *amqp.Channel, d amqp.Delivery, attempt int) error {
    routingKey := "retry"
    if attempt > 3 {
        routingKey = "retry-slow" // –ü–æ—Å–ª–µ 3 –ø–æ–ø—ã—Ç–æ–∫ ‚Äî –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω–∞—è –ø–∞—É–∑–∞
    }

    return ch.PublishWithContext(context.Background(),
        "orders.retry",
        routingKey,
        false, false,
        amqp.Publishing{
            ContentType: d.ContentType,
            Body:        d.Body,
            Headers: amqp.Table{
                "x-retry-count": int32(attempt),
                "x-first-failure": func() interface{} {
                    if v, ok := d.Headers["x-first-failure"]; ok {
                        return v
                    }
                    return time.Now().UTC().Format(time.RFC3339)
                }(),
            },
        },
    )
}
```

**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ DLX —Å C# MassTransit**:

| –ê—Å–ø–µ–∫—Ç | C# MassTransit | Go (amqp091-go) |
|--------|----------------|-----------------|
| **–°–æ–∑–¥–∞–Ω–∏–µ DLQ** | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ | –†—É—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–æ–ø–æ–ª–æ–≥–∏–∏ |
| **Retry** | `UseMessageRetry`, `UseDelayedRedelivery` | DLX + TTL —Ü–µ–ø–æ—á–∫–∏ –∏–ª–∏ —Ä—É—á–Ω–æ–π retry |
| **Error metadata** | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (exception stack trace) | Headers —Å —Ä—É—á–Ω—ã–º –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º |
| **Reprocessing** | Move message –∏–∑ error queue | –ß–∏—Ç–∞–µ–º –∏–∑ DLQ, –ø—É–±–ª–∏–∫—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ |
| **Delayed retry** | `UseDelayedExchangeMessageScheduler` | TTL –æ—á–µ—Ä–µ–¥–∏ —Å DLX routing |

---

## NATS (nats.go)

NATS ‚Äî –ª–µ–≥–∫–æ–≤–µ—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±–º–µ–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –ø—Ä–æ—Å—Ç–æ—Ç—É –∏ –Ω–∏–∑–∫—É—é latency. NATS –∑–∞—Ä–æ–¥–∏–ª—Å—è –≤ Cloud Foundry –∏ —Å—Ç–∞–ª –¥–µ-—Ñ–∞–∫—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–º –¥–ª—è –º–µ–∂—Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –æ–±—â–µ–Ω–∏—è –≤ Go-–º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞—Ö. NATS –∏–º–µ–µ—Ç –¥–≤–∞ —Ä–µ–∂–∏–º–∞: **Core NATS** (fire-and-forget, –∫–∞–∫ Redis Pub/Sub) –∏ **JetStream** (–ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π –æ–±–º–µ–Ω, –∞–Ω–∞–ª–æ–≥ Kafka).

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: NATS –º–µ–Ω–µ–µ –ø–æ–ø—É–ª—è—Ä–µ–Ω –≤ .NET-–º–∏—Ä–µ (—Ö–æ—Ç—è `NATS.Client` —Å—É—â–µ—Å—Ç–≤—É–µ—Ç), –Ω–æ –æ—á–µ–Ω—å —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω –≤ Go-—ç–∫–æ—Å–∏—Å—Ç–µ–º–µ. –ï—Å–ª–∏ Kafka ‚Äî —ç—Ç–æ ¬´—Ç—è–∂—ë–ª–∞—è –∞—Ä—Ç–∏–ª–ª–µ—Ä–∏—è¬ª –¥–ª—è event streaming, –∞ RabbitMQ ‚Äî ¬´—Ä–∞–±–æ—á–∞—è –ª–æ—à–∞–¥–∫–∞¬ª –¥–ª—è task queues, —Ç–æ NATS ‚Äî ¬´—Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–π –±–æ–ª–∏–¥¬ª –¥–ª—è low-latency –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ –º–µ–∂–¥—É —Å–µ—Ä–≤–∏—Å–∞–º–∏.

–£—Å—Ç–∞–Ω–æ–≤–∫–∞:

```bash
go get github.com/nats-io/nats.go
```

### Core NATS: Pub/Sub –∏ Request/Reply

Core NATS ‚Äî —ç—Ç–æ at-most-once delivery: –µ—Å–ª–∏ subscriber –Ω–µ –ø–æ–¥–∫–ª—é—á—ë–Ω –≤ –º–æ–º–µ–Ω—Ç –æ—Ç–ø—Ä–∞–≤–∫–∏, —Å–æ–æ–±—â–µ–Ω–∏–µ —Ç–µ—Ä—è–µ—Ç—Å—è (–∫–∞–∫ Redis Pub/Sub).

#### Pub/Sub

```go
import "github.com/nats-io/nats.go"

func coreNATSExample() error {
    // –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
    nc, err := nats.Connect(
        "nats://localhost:4222",
        nats.Name("order-service"),           // –ò–º—è –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        nats.ReconnectWait(2*time.Second),    // –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è–º–∏
        nats.MaxReconnects(60),               // –ú–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫
        nats.ReconnectHandler(func(nc *nats.Conn) {
            log.Printf("–ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ NATS: %s", nc.ConnectedUrl())
        }),
        nats.DisconnectErrHandler(func(nc *nats.Conn, err error) {
            log.Printf("–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –æ—Ç NATS: %v", err)
        }),
    )
    if err != nil {
        return fmt.Errorf("–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ NATS: %w", err)
    }
    defer nc.Close()

    // –ü–æ–¥–ø–∏—Å–∫–∞ ‚Äî –ø–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —á–µ—Ä–µ–∑ callback
    sub, err := nc.Subscribe("orders.created", func(msg *nats.Msg) {
        log.Printf("–ø–æ–ª—É—á–µ–Ω –∑–∞–∫–∞–∑: %s", string(msg.Data))

        var order Order
        if err := json.Unmarshal(msg.Data, &order); err != nil {
            log.Printf("–Ω–µ–≤–∞–ª–∏–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: %v", err)
            return
        }

        processOrder(context.Background(), order)
    })
    if err != nil {
        return fmt.Errorf("–ø–æ–¥–ø–∏—Å–∫–∞: %w", err)
    }
    defer sub.Unsubscribe()

    // –ü—É–±–ª–∏–∫–∞—Ü–∏—è
    order := Order{ID: "123", Total: 99.99}
    data, _ := json.Marshal(order)
    if err := nc.Publish("orders.created", data); err != nil {
        return fmt.Errorf("–ø—É–±–ª–∏–∫–∞—Ü–∏—è: %w", err)
    }

    // Wildcard –ø–æ–¥–ø–∏—Å–∫–∏
    // "orders.*" ‚Äî orders.created, orders.updated (–æ–¥–∏–Ω —É—Ä–æ–≤–µ–Ω—å)
    // "orders.>" ‚Äî orders.created, orders.payment.completed (–≤—Å–µ —É—Ä–æ–≤–Ω–∏)
    nc.Subscribe("orders.*", func(msg *nats.Msg) {
        log.Printf("—Å–æ–±—ã—Ç–∏–µ –∑–∞–∫–∞–∑–∞ [%s]: %s", msg.Subject, string(msg.Data))
    })

    return nil
}
```

#### Queue Groups (–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –Ω–∞–≥—Ä—É–∑–∫–∏)

```go
// Queue groups ‚Äî NATS —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –º–µ–∂–¥—É –ø–æ–¥–ø–∏—Å—á–∏–∫–∞–º–∏ –≤ –≥—Ä—É–ø–ø–µ
// –ö–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è —Ä–æ–≤–Ω–æ –æ–¥–Ω–æ–º—É –ø–æ–¥–ø–∏—Å—á–∏–∫—É –≤ –≥—Ä—É–ø–ø–µ
func startWorker(nc *nats.Conn, workerID int) (*nats.Subscription, error) {
    return nc.QueueSubscribe(
        "tasks.process",    // Subject
        "task-workers",     // Queue group name
        func(msg *nats.Msg) {
            log.Printf("[worker %d] –æ–±—Ä–∞–±–æ—Ç–∫–∞: %s", workerID, string(msg.Data))
            // –í—Å–µ –≤–æ—Ä–∫–µ—Ä—ã –≤ –≥—Ä—É–ø–ø–µ "task-workers" –¥–µ–ª—è—Ç –Ω–∞–≥—Ä—É–∑–∫—É
        },
    )
}

// –ó–∞–ø—É—Å–∫–∞–µ–º 3 –≤–æ—Ä–∫–µ—Ä–∞ ‚Äî NATS —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –º–µ–∂–¥—É –Ω–∏–º–∏
func main() {
    nc, _ := nats.Connect("nats://localhost:4222")
    for i := 0; i < 3; i++ {
        startWorker(nc, i)
    }
    select {} // –ë–ª–æ–∫–∏—Ä—É–µ–º main
}
```

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: Queue groups ‚Äî –∞–Ω–∞–ª–æ–≥ competing consumers –≤ RabbitMQ –∏ consumer groups –≤ Kafka. –í MassTransit —ç—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–Ω—Å—Ç–∞–Ω—Å–∞—Ö –æ–¥–Ω–æ–≥–æ consumer.

#### Request/Reply (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π RPC)

```go
// –°–µ—Ä–≤–µ—Ä ‚Äî –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—á–∞–µ—Ç
func startRPCServer(nc *nats.Conn) (*nats.Subscription, error) {
    return nc.Subscribe("users.get", func(msg *nats.Msg) {
        var req GetUserRequest
        if err := json.Unmarshal(msg.Data, &req); err != nil {
            msg.Respond([]byte(`{"error":"invalid request"}`))
            return
        }

        user := User{ID: req.ID, Name: "John"}
        data, _ := json.Marshal(user)
        msg.Respond(data) // –û—Ç–≤–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –Ω–∞ msg.Reply
    })
}

// –ö–ª–∏–µ–Ω—Ç ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∏ –∂–¥—ë—Ç –æ—Ç–≤–µ—Ç
func getUser(nc *nats.Conn, userID string) (*User, error) {
    req := GetUserRequest{ID: userID}
    data, _ := json.Marshal(req)

    // Request –±–ª–æ–∫–∏—Ä—É–µ—Ç –¥–æ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –∏–ª–∏ —Ç–∞–π–º–∞—É—Ç–∞
    msg, err := nc.Request("users.get", data, 5*time.Second)
    if err != nil {
        return nil, fmt.Errorf("RPC –∑–∞–ø—Ä–æ—Å: %w", err)
    }

    var user User
    if err := json.Unmarshal(msg.Data, &user); err != nil {
        return nil, fmt.Errorf("–¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞: %w", err)
    }

    return &user, nil
}
```

### JetStream: –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π –æ–±–º–µ–Ω —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏

JetStream ‚Äî –Ω–∞–¥—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞–¥ Core NATS, –¥–æ–±–∞–≤–ª—è—é—â–∞—è –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å, at-least-once/exactly-once delivery –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–µ—Ä–µ—á–∏—Ç—ã–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è. JetStream ‚Äî —ç—Ç–æ –æ—Ç–≤–µ—Ç NATS –Ω–∞ Kafka.

```go
import (
    "github.com/nats-io/nats.go"
    "github.com/nats-io/nats.go/jetstream"
)

func jetStreamExample() error {
    nc, err := nats.Connect("nats://localhost:4222")
    if err != nil {
        return err
    }
    defer nc.Close()

    // –°–æ–∑–¥–∞—ë–º JetStream context
    js, err := jetstream.New(nc)
    if err != nil {
        return fmt.Errorf("JetStream: %w", err)
    }

    ctx := context.Background()

    // –°–æ–∑–¥–∞—ë–º –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ–º stream ‚Äî —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å–æ–æ–±—â–µ–Ω–∏–π
    stream, err := js.CreateOrUpdateStream(ctx, jetstream.StreamConfig{
        Name:     "ORDERS",
        Subjects: []string{"orders.>"},  // –í—Å–µ subjects, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å "orders."

        // –•—Ä–∞–Ω–µ–Ω–∏–µ
        Storage:   jetstream.FileStorage,  // –ù–∞ –¥–∏—Å–∫–µ (–∏–ª–∏ MemoryStorage)
        Retention: jetstream.LimitsPolicy, // –•—Ä–∞–Ω–∏—Ç—å –¥–æ –ª–∏–º–∏—Ç–æ–≤

        // –õ–∏–º–∏—Ç—ã
        MaxMsgs:    1000000,              // –ú–∞–∫—Å–∏–º—É–º —Å–æ–æ–±—â–µ–Ω–∏–π
        MaxBytes:   1 << 30,              // –ú–∞–∫—Å–∏–º—É–º 1 GB
        MaxAge:     7 * 24 * time.Hour,   // –ú–∞–∫—Å–∏–º—É–º 7 –¥–Ω–µ–π

        // –†–µ–ø–ª–∏–∫–∞—Ü–∏—è
        Replicas: 3,                      // 3 —Ä–µ–ø–ª–∏–∫–∏ –¥–ª—è HA

        // –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
        DuplicateWindow: 2 * time.Minute, // –û–∫–Ω–æ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –ø–æ Nats-Msg-Id
    })
    if err != nil {
        return fmt.Errorf("—Å–æ–∑–¥–∞–Ω–∏–µ stream: %w", err)
    }
    log.Printf("stream —Å–æ–∑–¥–∞–Ω: %s", stream.CachedInfo().Config.Name)

    // –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ JetStream ‚Äî —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º –∑–∞–ø–∏—Å–∏
    ack, err := js.Publish(ctx, "orders.created", []byte(`{"id":"123","total":99.99}`),
        jetstream.WithMsgID("order-123"), // ID –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
    )
    if err != nil {
        return fmt.Errorf("publish: %w", err)
    }
    log.Printf("–æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ: stream=%s seq=%d", ack.Stream, ack.Sequence)

    return nil
}
```

#### Consumer: –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ JetStream

```go
func consumeJetStream(ctx context.Context, js jetstream.JetStream) error {
    // –°–æ–∑–¥–∞—ë–º durable consumer ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ–∑–∏—Ü–∏—é –º–µ–∂–¥—É –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–º–∏
    consumer, err := js.CreateOrUpdateConsumer(ctx, "ORDERS", jetstream.ConsumerConfig{
        Name:          "order-processor",
        Durable:       "order-processor",
        FilterSubject: "orders.created",

        // Delivery policy ‚Äî –æ—Ç–∫—É–¥–∞ –Ω–∞—á–∞—Ç—å
        DeliverPolicy: jetstream.DeliverAllPolicy, // –° —Å–∞–º–æ–≥–æ –Ω–∞—á–∞–ª–∞
        // DeliverPolicy: jetstream.DeliverNewPolicy, // –¢–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ

        // Ack policy
        AckPolicy: jetstream.AckExplicitPolicy, // –†—É—á–Ω–æ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
        AckWait:   30 * time.Second,             // –¢–∞–π–º–∞—É—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è

        // Retry ‚Äî –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ ack, —Å–æ–æ–±—â–µ–Ω–∏–µ –±—É–¥–µ—Ç –ø–æ–≤—Ç–æ—Ä–Ω–æ –¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ
        MaxDeliver: 5, // –ú–∞–∫—Å–∏–º—É–º 5 –ø–æ–ø—ã—Ç–æ–∫ –¥–æ—Å—Ç–∞–≤–∫–∏

        // Backoff –¥–ª—è retry
        BackOff: []time.Duration{
            5 * time.Second,
            15 * time.Second,
            30 * time.Second,
            60 * time.Second,
        },
    })
    if err != nil {
        return fmt.Errorf("—Å–æ–∑–¥–∞–Ω–∏–µ consumer: %w", err)
    }

    // –ü–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π
    iter, err := consumer.Messages()
    if err != nil {
        return fmt.Errorf("messages: %w", err)
    }
    defer iter.Stop()

    for {
        msg, err := iter.Next()
        if err != nil {
            if errors.Is(err, jetstream.ErrMsgIteratorClosed) {
                return nil
            }
            return fmt.Errorf("next: %w", err)
        }

        var order Order
        if err := json.Unmarshal(msg.Data(), &order); err != nil {
            log.Printf("–Ω–µ–≤–∞–ª–∏–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: %v", err)
            // Term ‚Äî –Ω–∞–≤—Å–µ–≥–¥–∞ –æ—Ç–∫–ª–æ–Ω–∏—Ç—å (–Ω–µ retry)
            msg.Term()
            continue
        }

        if err := processOrder(ctx, order); err != nil {
            log.Printf("–æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: %v", err)
            // Nak ‚Äî –∑–∞–ø—Ä–æ—Å–∏—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω—É—é –¥–æ—Å—Ç–∞–≤–∫—É (—Å backoff –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏)
            msg.Nak()
            continue
        }

        // Ack ‚Äî —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ
        msg.Ack()
        log.Printf("–æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞–∫–∞–∑ %s (seq=%d)", order.ID, msg.Headers().Get("Nats-Sequence"))
    }
}
```

### Push vs Pull Consumers

| –ê—Å–ø–µ–∫—Ç | Push Consumer | Pull Consumer |
|--------|--------------|---------------|
| **–î–æ—Å—Ç–∞–≤–∫–∞** | NATS –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è consumer | Consumer –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è |
| **Backpressure** | –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ `MaxAckPending` | –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å —á–µ—Ä–µ–∑ `Fetch(batch)` |
| **–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ** | –ß–µ—Ä–µ–∑ queue groups | –ß–µ—Ä–µ–∑ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ |
| **–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å** | –ü—Ä–æ—Å—Ç—ã–µ —Å–ª—É—á–∞–∏, —Ä–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è | –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞, –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–≥—Ä—É–∑–∫–∏ |

```go
// Pull consumer ‚Äî —è–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å –±–∞—Ç—á–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
func pullConsumer(ctx context.Context, js jetstream.JetStream) error {
    consumer, err := js.CreateOrUpdateConsumer(ctx, "ORDERS", jetstream.ConsumerConfig{
        Name:    "batch-processor",
        Durable: "batch-processor",
    })
    if err != nil {
        return err
    }

    for {
        // Fetch ‚Äî –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–æ 10 —Å–æ–æ–±—â–µ–Ω–∏–π, –∂–¥—ë–º –¥–æ 5 —Å–µ–∫—É–Ω–¥
        batch, err := consumer.Fetch(10, jetstream.FetchMaxWait(5*time.Second))
        if err != nil {
            if errors.Is(err, context.Canceled) {
                return nil
            }
            log.Printf("fetch –æ—à–∏–±–∫–∞: %v", err)
            continue
        }

        for msg := range batch.Messages() {
            if err := processMessage(ctx, msg); err != nil {
                msg.Nak()
            } else {
                msg.Ack()
            }
        }

        if batch.Error() != nil {
            log.Printf("batch error: %v", batch.Error())
        }
    }
}
```

### Key-Value Store –∏ Object Store

JetStream –≤–∫–ª—é—á–∞–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ Key-Value —Ö—Ä–∞–Ω–∏–ª–∏—â–µ ‚Äî –ª—ë–≥–∫–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ Redis –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤.

```go
func kvExample(ctx context.Context, js jetstream.JetStream) error {
    // –°–æ–∑–¥–∞—ë–º KV bucket
    kv, err := js.CreateOrUpdateKeyValue(ctx, jetstream.KeyValueConfig{
        Bucket:  "sessions",
        TTL:     30 * time.Minute,  // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ
        History: 5,                  // –•—Ä–∞–Ω–∏—Ç—å 5 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –≤–µ—Ä—Å–∏–π
    })
    if err != nil {
        return fmt.Errorf("KV bucket: %w", err)
    }

    // Put
    _, err = kv.Put(ctx, "user:123", []byte(`{"token":"abc","role":"admin"}`))
    if err != nil {
        return fmt.Errorf("put: %w", err)
    }

    // Get
    entry, err := kv.Get(ctx, "user:123")
    if err != nil {
        if errors.Is(err, jetstream.ErrKeyNotFound) {
            log.Println("–∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return nil
        }
        return fmt.Errorf("get: %w", err)
    }
    log.Printf("–∑–Ω–∞—á–µ–Ω–∏–µ: %s (revision=%d)", string(entry.Value()), entry.Revision())

    // Watch ‚Äî –ø–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è (–∞–Ω–∞–ª–æ–≥ Redis SUBSCRIBE, –Ω–æ –¥–ª—è KV)
    watcher, err := kv.Watch(ctx, "user.*")
    if err != nil {
        return err
    }
    defer watcher.Stop()

    go func() {
        for entry := range watcher.Updates() {
            if entry == nil {
                continue // –ù–∞—á–∞–ª—å–Ω—ã–π nil –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ watcher
            }
            log.Printf("–∏–∑–º–µ–Ω–µ–Ω–∏–µ: key=%s op=%s", entry.Key(), entry.Operation())
        }
    }()

    // Delete
    err = kv.Delete(ctx, "user:123")
    return err
}
```

> üí° **NATS KV vs Redis**: NATS KV —É–¥–æ–±–µ–Ω, –µ—Å–ª–∏ —É –≤–∞—Å —É–∂–µ –µ—Å—Ç—å NATS –∏ –Ω—É–∂–µ–Ω –ø—Ä–æ—Å—Ç–æ–π key-value –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã. –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ (sorted sets, Lua —Å–∫—Ä–∏–ø—Ç—ã, Pub/Sub —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏) Redis –æ—Å—Ç–∞—ë—Ç—Å—è –ª—É—á—à–∏–º –≤—ã–±–æ—Ä–æ–º.

---

## Redis Streams

Redis Streams ‚Äî –≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –≤ Redis —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è persistent messaging. –ï—Å–ª–∏ –≤—ã —É–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ Redis (—Å–º. [—Ä–∞–∑–¥–µ–ª 4.2](./02_caching.md)), Redis Streams –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–æ–±–∞–≤–∏—Ç—å –æ—á–µ—Ä–µ–¥—å —Å–æ–æ–±—â–µ–Ω–∏–π –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã.

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: Redis Streams –¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ `StackExchange.Redis` (`StreamAdd`, `StreamRead`), –Ω–æ —Ä–µ–¥–∫–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ .NET ‚Äî –æ–±—ã—á–Ω–æ –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞—é—Ç MassTransit —Å RabbitMQ. –í Go Redis Streams –ø–æ–ø—É–ª—è—Ä–Ω–µ–µ, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ –ø—Ä–æ–µ–∫—Ç–∞—Ö, –≥–¥–µ Redis —É–∂–µ –µ—Å—Ç—å –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è.

### –û—Å–Ω–æ–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (XADD, XREAD)

```go
import "github.com/redis/go-redis/v9"

func redisStreamsBasic(ctx context.Context, rdb *redis.Client) error {
    // XADD ‚Äî –¥–æ–±–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ stream
    id, err := rdb.XAdd(ctx, &redis.XAddArgs{
        Stream: "events",
        ID:     "*", // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π ID (timestamp-sequence)
        Values: map[string]interface{}{
            "type":    "order.created",
            "payload": `{"id":"123","total":99.99}`,
            "source":  "order-service",
        },
    }).Result()
    if err != nil {
        return fmt.Errorf("XADD: %w", err)
    }
    log.Printf("–¥–æ–±–∞–≤–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ: %s", id) // 1706000000000-0

    // –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ stream
    rdb.XAdd(ctx, &redis.XAddArgs{
        Stream: "events",
        MaxLen: 100000,   // –ú–∞–∫—Å–∏–º—É–º 100k –∑–∞–ø–∏—Å–µ–π
        Approx: true,     // –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ (—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ)
        ID:     "*",
        Values: map[string]interface{}{"type": "test"},
    })

    // XREAD ‚Äî —á—Ç–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π (–±–ª–æ–∫–∏—Ä—É—é—â–µ–µ)
    streams, err := rdb.XRead(ctx, &redis.XReadArgs{
        Streams: []string{"events", "0"}, // stream name, start ID
        Count:   10,                       // –ú–∞–∫—Å–∏–º—É–º 10 —Å–æ–æ–±—â–µ–Ω–∏–π
        Block:   5 * time.Second,          // –ë–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –¥–æ 5 —Å–µ–∫—É–Ω–¥
    }).Result()
    if err != nil {
        if err == redis.Nil {
            log.Println("–Ω–µ—Ç –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π")
            return nil
        }
        return fmt.Errorf("XREAD: %w", err)
    }

    for _, stream := range streams {
        for _, msg := range stream.Messages {
            log.Printf("ID=%s type=%s payload=%s",
                msg.ID, msg.Values["type"], msg.Values["payload"])
        }
    }

    return nil
}
```

### Consumer Groups (Redis)

Consumer groups –≤ Redis Streams —Ä–∞–±–æ—Ç–∞—é—Ç –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ Kafka consumer groups: –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –æ–¥–Ω–æ–º—É consumer –≤ –≥—Ä—É–ø–ø–µ.

```go
func redisStreamsConsumerGroup(ctx context.Context, rdb *redis.Client) error {
    stream := "events"
    group := "event-processors"
    consumer := "worker-1"

    // –°–æ–∑–¥–∞—ë–º consumer group ($ = —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, 0 = —Å –Ω–∞—á–∞–ª–∞)
    err := rdb.XGroupCreateMkStream(ctx, stream, group, "$").Err()
    if err != nil && !strings.Contains(err.Error(), "BUSYGROUP") {
        return fmt.Errorf("—Å–æ–∑–¥–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã: %w", err)
    }

    for {
        // XREADGROUP ‚Äî —á–∏—Ç–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –Ω–∞—à–µ–≥–æ consumer
        streams, err := rdb.XReadGroup(ctx, &redis.XReadGroupArgs{
            Group:    group,
            Consumer: consumer,
            Streams:  []string{stream, ">"},  // ">" = —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ
            Count:    10,
            Block:    5 * time.Second,
        }).Result()
        if err != nil {
            if err == redis.Nil {
                continue // –ù–µ—Ç –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
            }
            if errors.Is(err, context.Canceled) {
                return nil
            }
            log.Printf("XREADGROUP –æ—à–∏–±–∫–∞: %v", err)
            time.Sleep(time.Second)
            continue
        }

        for _, stream := range streams {
            for _, msg := range stream.Messages {
                // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
                if err := processEvent(ctx, msg); err != nil {
                    log.Printf("–æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ %s: %v", msg.ID, err)
                    continue // –ù–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ–º ‚Äî —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è pending
                }

                // XACK ‚Äî –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                rdb.XAck(ctx, stream.Stream, group, msg.ID)
            }
        }
    }
}
```

### Acknowledgment –∏ Claiming

```go
// –û–±—Ä–∞–±–æ—Ç–∫–∞ ¬´–∑–∞—Å—Ç—Ä—è–≤—à–∏—Ö¬ª —Å–æ–æ–±—â–µ–Ω–∏–π ‚Äî –µ—Å–ª–∏ consumer —É–ø–∞–ª,
// –¥—Ä—É–≥–æ–π consumer –º–æ–∂–µ—Ç –∑–∞–±—Ä–∞—Ç—å –µ–≥–æ pending —Å–æ–æ–±—â–µ–Ω–∏—è
func claimStaleMessages(ctx context.Context, rdb *redis.Client,
    stream, group, consumer string) error {

    // XPENDING ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º pending —Å–æ–æ–±—â–µ–Ω–∏—è
    pending, err := rdb.XPendingExt(ctx, &redis.XPendingExtArgs{
        Stream: stream,
        Group:  group,
        Start:  "-",
        End:    "+",
        Count:  100,
    }).Result()
    if err != nil {
        return fmt.Errorf("XPENDING: %w", err)
    }

    var staleIDs []string
    for _, p := range pending {
        // –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ –±–æ–ª–µ–µ 5 –º–∏–Ω—É—Ç ‚Äî –∑–∞–±–∏—Ä–∞–µ–º
        if p.Idle > 5*time.Minute {
            staleIDs = append(staleIDs, p.ID)
            log.Printf("—Å—Ç–∞–≥–Ω–∏—Ä—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: ID=%s consumer=%s idle=%v retries=%d",
                p.ID, p.Consumer, p.Idle, p.RetryCount)
        }
    }

    if len(staleIDs) == 0 {
        return nil
    }

    // XCLAIM ‚Äî –∑–∞–±–∏—Ä–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å–µ–±–µ
    messages, err := rdb.XClaim(ctx, &redis.XClaimArgs{
        Stream:   stream,
        Group:    group,
        Consumer: consumer,
        MinIdle:  5 * time.Minute,
        Messages: staleIDs,
    }).Result()
    if err != nil {
        return fmt.Errorf("XCLAIM: %w", err)
    }

    for _, msg := range messages {
        if err := processEvent(ctx, msg); err != nil {
            log.Printf("–æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ claimed %s: %v", msg.ID, err)
            continue
        }
        rdb.XAck(ctx, stream, group, msg.ID)
    }

    log.Printf("–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ %d —Å—Ç–∞–≥–Ω–∏—Ä—É—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π", len(messages))
    return nil
}

// XAUTOCLAIM (Redis 6.2+) ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–±–∏—Ä–∞–µ—Ç stale —Å–æ–æ–±—â–µ–Ω–∏—è
func autoClaimMessages(ctx context.Context, rdb *redis.Client,
    stream, group, consumer string) error {

    messages, _, err := rdb.XAutoClaim(ctx, &redis.XAutoClaimArgs{
        Stream:   stream,
        Group:    group,
        Consumer: consumer,
        MinIdle:  5 * time.Minute,
        Start:    "0-0",
        Count:    50,
    }).Result()
    if err != nil {
        return fmt.Errorf("XAUTOCLAIM: %w", err)
    }

    for _, msg := range messages {
        if err := processEvent(ctx, msg); err != nil {
            log.Printf("–æ—à–∏–±–∫–∞: %v", err)
            continue
        }
        rdb.XAck(ctx, stream, group, msg.ID)
    }

    return nil
}
```

### –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Redis Streams

| –ö—Ä–∏—Ç–µ—Ä–∏–π | Redis Streams | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è |
|----------|--------------|--------------|
| Redis —É–∂–µ –µ—Å—Ç—å –≤ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–µ | ‚úÖ | –û—Ç–ª–∏—á–Ω—ã–π –≤—ã–±–æ—Ä ‚Äî –Ω–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ |
| –ù—É–∂–Ω–∞ –≤—ã—Å–æ–∫–∞—è –ø—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å (>100k msg/sec) | ‚ùå | –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Kafka |
| –ù—É–∂–Ω–∞ —Å–ª–æ–∂–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è | ‚ùå | –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ RabbitMQ |
| –ù—É–∂–Ω–æ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π | ‚ùå | –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Kafka |
| –ù—É–∂–Ω–∞ –ø—Ä–æ—Å—Ç–∞—è –æ—á–µ—Ä–µ–¥—å –∑–∞–¥–∞—á | ‚úÖ | Redis Streams + consumer groups |
| –ù—É–∂–µ–Ω lightweight event bus | ‚úÖ | –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö —Å–∏—Å—Ç–µ–º |

> üí° **–°–æ–≤–µ—Ç**: Redis Streams ‚Äî –æ—Ç–ª–∏—á–Ω—ã–π –≤—ã–±–æ—Ä –¥–ª—è MVP –∏ –Ω–µ–±–æ–ª—å—à–∏—Ö —Å–∏—Å—Ç–µ–º. –ö–æ–≥–¥–∞ –Ω–∞–≥—Ä—É–∑–∫–∞ –≤—ã—Ä–∞—Å—Ç–µ—Ç, –≤—ã —Å–º–æ–∂–µ—Ç–µ –º–∏–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ Kafka –∏–ª–∏ RabbitMQ, —Å–æ—Ö—Ä–∞–Ω–∏–≤ —Ç—É –∂–µ —Å–µ–º–∞–Ω—Ç–∏–∫—É consumer groups.

---

## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π

### –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞

| –ê—Å–ø–µ–∫—Ç | Kafka | RabbitMQ | NATS | Redis Streams |
|--------|-------|----------|------|---------------|
| **–ú–æ–¥–µ–ª—å** | –†–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–π –ª–æ–≥ | –û—á–µ—Ä–µ–¥—å —Å–æ–æ–±—â–µ–Ω–∏–π | Subject-based messaging | Append-only stream |
| **–ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å** | –î–∞ (–¥–∏—Å–∫, retention) | –î–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) | JetStream (–¥–∞) | –î–∞ (AOF/RDB) |
| **–ü–æ—Ä—è–¥–æ–∫** | –ü–æ –ø–∞—Ä—Ç–∏—Ü–∏–∏ | –ü–æ –æ—á–µ—Ä–µ–¥–∏ | –ü–æ subject | –ü–æ stream |
| **Consumer groups** | –î–∞ | Competing consumers | Queue groups / JetStream | –î–∞ (XREADGROUP) |
| **–ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å** | –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è (–º–ª–Ω/—Å–µ–∫) | –°—Ä–µ–¥–Ω—è—è (–¥–µ—Å—è—Ç–∫–∏ —Ç—ã—Å/—Å–µ–∫) | –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è | –°—Ä–µ–¥–Ω–µ-–≤—ã—Å–æ–∫–∞—è |
| **Latency** | –°—Ä–µ–¥–Ω—è—è (–±–∞—Ç—á–∏–Ω–≥) | –ù–∏–∑–∫–∞—è | –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è (< 1 –º—Å) | –ù–∏–∑–∫–∞—è |
| **Replay** | –î–∞ (offset) | –ù–µ—Ç | JetStream (–¥–∞) | –î–∞ (–ø–æ ID) |
| **–ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è** | Topic / partition | Exchanges (–≥–∏–±–∫–∞—è) | Subject hierarchy | –ù–µ—Ç |
| **–ü—Ä–æ—Ç–æ–∫–æ–ª** | Custom TCP | AMQP 0.9.1 | Custom TCP | RESP (Redis) |
| **–°–ª–æ–∂–Ω–æ—Å—Ç—å ops** | –í—ã—Å–æ–∫–∞—è (ZooKeeper/KRaft) | –°—Ä–µ–¥–Ω—è—è | –ù–∏–∑–∫–∞—è | –ù–∏–∑–∫–∞—è (–µ—Å–ª–∏ Redis –µ—Å—Ç—å) |
| **Go –±–∏–±–ª–∏–æ—Ç–µ–∫–∞** | segmentio/kafka-go | amqp091-go | nats.go | go-redis |
| **C# –±–∏–±–ª–∏–æ—Ç–µ–∫–∞** | Confluent.Kafka | RabbitMQ.Client | NATS.Client | StackExchange.Redis |
| **MassTransit** | –î–∞ (Rider) | –î–∞ (–æ—Å–Ω–æ–≤–Ω–æ–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç) | –ù–µ—Ç | –ù–µ—Ç |

### –ë–ª–æ–∫-—Å—Ö–µ–º–∞ –≤—ã–±–æ—Ä–∞

```
–ù—É–∂–Ω–∞ –ª–∏ –ø–æ—Å—Ç–æ—è–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å —Å–æ–±—ã—Ç–∏–π (event log)?
‚îú‚îÄ‚îÄ –î–∞ ‚Üí Kafka
‚îÇ   ‚îî‚îÄ‚îÄ Event sourcing, CQRS, stream processing, audit log
‚îÇ
‚îî‚îÄ‚îÄ –ù–µ—Ç ‚Üí –ù—É–∂–Ω–∞ —Å–ª–æ–∂–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è?
    ‚îú‚îÄ‚îÄ –î–∞ ‚Üí RabbitMQ
    ‚îÇ   ‚îî‚îÄ‚îÄ Topic routing, priority queues, delayed messages, DLX
    ‚îÇ
    ‚îî‚îÄ‚îÄ –ù–µ—Ç ‚Üí –ù—É–∂–Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è latency?
        ‚îú‚îÄ‚îÄ –î–∞ ‚Üí NATS
        ‚îÇ   ‚îî‚îÄ‚îÄ –ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã, request/reply, real-time
        ‚îÇ
        ‚îî‚îÄ‚îÄ –ù–µ—Ç ‚Üí Redis —É–∂–µ –≤ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–µ?
            ‚îú‚îÄ‚îÄ –î–∞ ‚Üí Redis Streams
            ‚îÇ   ‚îî‚îÄ‚îÄ –ü—Ä–æ—Å—Ç—ã–µ –æ—á–µ—Ä–µ–¥–∏, event bus –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö —Å–∏—Å—Ç–µ–º
            ‚îÇ
            ‚îî‚îÄ‚îÄ –ù–µ—Ç ‚Üí RabbitMQ (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä)
```

---

## –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∏ Best Practices

### –ò–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (Exactly-Once Processing)

At-least-once delivery –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ **–ø–æ–≤—Ç–æ—Ä–Ω–æ** (crash –º–µ–∂–¥—É –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∏ ack). –ò–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ –ø—Ä–∏–≤–µ–¥—ë—Ç –∫ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—é –¥–∞–Ω–Ω—ã—Ö.

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: MassTransit –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç `InMemoryOutbox` –∏ message deduplication. –í Go –≤—ã —Ä–µ–∞–ª–∏–∑—É–µ—Ç–µ –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ ‚Äî –æ–±—ã—á–Ω–æ —á–µ—Ä–µ–∑ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.

```go
// –ò–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ PostgreSQL ‚Äî INSERT ... ON CONFLICT DO NOTHING
type IdempotencyChecker struct {
    db *pgxpool.Pool
}

func NewIdempotencyChecker(db *pgxpool.Pool) *IdempotencyChecker {
    return &IdempotencyChecker{db: db}
}

// Process ‚Äî –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
func (c *IdempotencyChecker) Process(ctx context.Context, messageID string,
    handler func(ctx context.Context) error) error {

    // –ù–∞—á–∏–Ω–∞–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é
    tx, err := c.db.Begin(ctx)
    if err != nil {
        return fmt.Errorf("begin tx: %w", err)
    }
    defer tx.Rollback(ctx)

    // –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–ø–∏—Å–∞—Ç—å ID —Å–æ–æ–±—â–µ–Ω–∏—è ‚Äî –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
    var inserted bool
    err = tx.QueryRow(ctx,
        `INSERT INTO processed_messages (message_id, processed_at)
         VALUES ($1, NOW())
         ON CONFLICT (message_id) DO NOTHING
         RETURNING true`,
        messageID,
    ).Scan(&inserted)

    if err != nil {
        if errors.Is(err, pgx.ErrNoRows) {
            // –°–æ–æ–±—â–µ–Ω–∏–µ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            log.Printf("—Å–æ–æ–±—â–µ–Ω–∏–µ %s —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º", messageID)
            return nil
        }
        return fmt.Errorf("idempotency check: %w", err)
    }

    // –í—ã–ø–æ–ª–Ω—è–µ–º –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É –≤ —Ç–æ–π –∂–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
    if err := handler(ctx); err != nil {
        return err // Rollback ‚Äî ID —É–¥–∞–ª–∏—Ç—Å—è, –º–æ–∂–Ω–æ retry
    }

    return tx.Commit(ctx)
}

// SQL –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã:
// CREATE TABLE processed_messages (
//     message_id TEXT PRIMARY KEY,
//     processed_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
// );
// CREATE INDEX idx_processed_messages_at ON processed_messages(processed_at);
// -- –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π: DELETE FROM processed_messages WHERE processed_at < NOW() - INTERVAL '7 days';
```

### Graceful Shutdown

```go
// –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω graceful shutdown –¥–ª—è consumer-—Å–µ—Ä–≤–∏—Å–æ–≤
func runConsumer(ctx context.Context) error {
    // –ü–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã
    ctx, stop := signal.NotifyContext(ctx, syscall.SIGINT, syscall.SIGTERM)
    defer stop()

    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers: []string{"localhost:9092"},
        Topic:   "events",
        GroupID: "processor",
    })

    var wg sync.WaitGroup

    // Worker pool
    jobs := make(chan kafka.Message, 10)

    for i := 0; i < 5; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            for msg := range jobs {
                processMessage(ctx, msg)
                reader.CommitMessages(ctx, msg)
            }
        }(i)
    }

    // –ß–∏—Ç–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
    go func() {
        for {
            msg, err := reader.FetchMessage(ctx)
            if err != nil {
                if errors.Is(err, context.Canceled) {
                    return
                }
                log.Printf("fetch error: %v", err)
                continue
            }
            jobs <- msg
        }
    }()

    // –ñ–¥—ë–º —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    <-ctx.Done()
    log.Println("–ø–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è...")

    // 1. –ü—Ä–µ–∫—Ä–∞—â–∞–µ–º —á—Ç–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    close(jobs)

    // 2. –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    wg.Wait()

    // 3. –ó–∞–∫—Ä—ã–≤–∞–µ–º reader (–æ—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞—Ä—Ç–∏—Ü–∏–∏)
    reader.Close()

    log.Println("graceful shutdown –∑–∞–≤–µ—Ä—à—ë–Ω")
    return nil
}
```

**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å C#**:

| –ê—Å–ø–µ–∫—Ç | C# (.NET) | Go |
|--------|-----------|-----|
| **–°–∏–≥–Ω–∞–ª** | `IHostApplicationLifetime`, `CancellationToken` | `signal.NotifyContext`, `context.Context` |
| **Lifecycle** | `BackgroundService.StopAsync()` | –†—É—á–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è |
| **In-flight** | MassTransit –∂–¥—ë—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è consumers | `sync.WaitGroup` |
| **Timeout** | `HostOptions.ShutdownTimeout` (30s) | –†—É—á–Ω–æ–π `context.WithTimeout` |

### Retry —Å Exponential Backoff

```go
// –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è retry —Å exponential backoff –∏ jitter
func retryWithBackoff(ctx context.Context, maxRetries int,
    fn func(ctx context.Context) error) error {

    var lastErr error

    for attempt := 0; attempt <= maxRetries; attempt++ {
        err := fn(ctx)
        if err == nil {
            return nil
        }

        // Permanent error ‚Äî –Ω–µ retry
        if isPermanent(err) {
            return err
        }

        lastErr = err

        if attempt < maxRetries {
            // Backoff: 100ms * 2^attempt, –º–∞–∫—Å–∏–º—É–º 30 —Å–µ–∫—É–Ω–¥
            base := float64(100*time.Millisecond) * math.Pow(2, float64(attempt))
            maxBackoff := float64(30 * time.Second)
            backoff := time.Duration(math.Min(base, maxBackoff))

            // Jitter: ¬±25%
            jitter := time.Duration(rand.Int63n(int64(backoff) / 2))
            backoff = backoff/2 + jitter

            select {
            case <-time.After(backoff):
            case <-ctx.Done():
                return ctx.Err()
            }
        }
    }

    return fmt.Errorf("–∏—Å—á–µ—Ä–ø–∞–Ω–æ %d –ø–æ–ø—ã—Ç–æ–∫: %w", maxRetries, lastErr)
}
```

### Dead Letter Queue

–û–±—â–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω DLQ, –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–π –æ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –±—Ä–æ–∫–µ—Ä–∞:

```go
// DeadLetterSender ‚Äî –∞–±—Å—Ç—Ä–∞–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ DLQ
type DeadLetterSender interface {
    SendToDLQ(ctx context.Context, originalMsg []byte, err error, metadata map[string]string) error
}

// KafkaDLQ ‚Äî —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è Kafka
type KafkaDLQ struct {
    writer *kafka.Writer
}

func (d *KafkaDLQ) SendToDLQ(ctx context.Context, originalMsg []byte,
    processingErr error, metadata map[string]string) error {

    headers := []kafka.Header{
        {Key: "dlq-error", Value: []byte(processingErr.Error())},
        {Key: "dlq-timestamp", Value: []byte(time.Now().UTC().Format(time.RFC3339))},
    }
    for k, v := range metadata {
        headers = append(headers, kafka.Header{Key: k, Value: []byte(v)})
    }

    return d.writer.WriteMessages(ctx, kafka.Message{
        Value:   originalMsg,
        Headers: headers,
    })
}
```

### –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π

| –§–æ—Ä–º–∞—Ç | –†–∞–∑–º–µ—Ä | –°–∫–æ—Ä–æ—Å—Ç—å | Schema | –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |
|--------|--------|----------|--------|-----------------|-------------------|
| **JSON** | –ë–æ–ª—å—à–æ–π | –°—Ä–µ–¥–Ω—è—è | –ù–µ—Ç | –î–∞ | MVP, –æ—Ç–ª–∞–¥–∫–∞, –≤–Ω–µ—à–Ω–∏–µ API |
| **Protobuf** | –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π | –í—ã—Å–æ–∫–∞—è | –î–∞ (.proto) | –ù–µ—Ç | –í—ã—Å–æ–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞, –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã |
| **Avro** | –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π | –í—ã—Å–æ–∫–∞—è | –î–∞ (Schema Registry) | –ù–µ—Ç | Kafka + schema evolution |
| **MessagePack** | –°—Ä–µ–¥–Ω–∏–π | –í—ã—Å–æ–∫–∞—è | –ù–µ—Ç | –ù–µ—Ç | –ö–æ–º–ø—Ä–æ–º–∏—Å—Å JSON/binary |

```go
// JSON ‚Äî –ø—Ä–æ—Å—Ç–æ –∏ —É–¥–æ–±–Ω–æ
data, _ := json.Marshal(order)
writer.WriteMessages(ctx, kafka.Message{
    Value: data,
    Headers: []kafka.Header{
        {Key: "content-type", Value: []byte("application/json")},
    },
})

// Protobuf ‚Äî –∫–æ–º–ø–∞–∫—Ç–Ω–æ –∏ –±—ã—Å—Ç—Ä–æ
// (—Ç—Ä–µ–±—É–µ—Ç—Å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥ –∏–∑ .proto —Ñ–∞–π–ª–∞)
data, _ := proto.Marshal(orderProto)
writer.WriteMessages(ctx, kafka.Message{
    Value: data,
    Headers: []kafka.Header{
        {Key: "content-type", Value: []byte("application/protobuf")},
        {Key: "proto-type", Value: []byte("orders.v1.OrderCreated")},
    },
})
```

> üí° **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –ù–∞—á–∏–Ω–∞–π—Ç–µ —Å JSON ‚Äî –ø—Ä–æ—â–µ –æ—Ç–ª–∞–∂–∏–≤–∞—Ç—å –∏ –Ω–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç codegen. –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –Ω–∞ Protobuf, –∫–æ–≥–¥–∞ —Ä–∞–∑–º–µ—Ä —Å–æ–æ–±—â–µ–Ω–∏–π –∏–ª–∏ —Å–∫–æ—Ä–æ—Å—Ç—å —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è —É–∑–∫–∏–º –º–µ—Å—Ç–æ–º, –∏–ª–∏ –∫–æ–≥–¥–∞ –∫–æ–º–∞–Ω–¥–∞ —Ä–∞—Å—Ç—ë—Ç –∏ –Ω—É–∂–Ω–∞ —Å—Ç—Ä–æ–≥–∞—è —Ç–∏–ø–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ `.proto` —Ñ–∞–π–ª—ã.

### Outbox Pattern

–ü—Ä–æ–±–ª–µ–º–∞ **dual write**: –Ω—É–∂–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å –≤ –±–∞–∑—É –ò –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ. –ï—Å–ª–∏ crash –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –º–µ–∂–¥—É –¥–≤—É–º—è –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏, –¥–∞–Ω–Ω—ã–µ —Ä–∞—Å—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É—é—Ç—Å—è.

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: MassTransit –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç `AddEntityFrameworkOutbox<TDbContext>()` ‚Äî outbox –≤—Å—Ç—Ä–æ–µ–Ω –≤ EF Core —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏. –í Go —ç—Ç–æ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω —Ä–µ–∞–ª–∏–∑—É–µ—Ç—Å—è –≤—Ä—É—á–Ω—É—é.

```go
// Outbox Pattern: –∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Å–æ–±—ã—Ç–∏–µ –≤ —Ç—É –∂–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é, —á—Ç–æ –∏ –±–∏–∑–Ω–µ—Å-–¥–∞–Ω–Ω—ã–µ

// SQL: CREATE TABLE outbox (
//     id BIGSERIAL PRIMARY KEY,
//     topic TEXT NOT NULL,
//     key TEXT,
//     payload BYTEA NOT NULL,
//     headers JSONB DEFAULT '{}',
//     created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
//     published_at TIMESTAMPTZ
// );
// CREATE INDEX idx_outbox_unpublished ON outbox(created_at) WHERE published_at IS NULL;

type OutboxWriter struct {
    db *pgxpool.Pool
}

// SaveWithEvent ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º –±–∏–∑–Ω–µ—Å-–¥–∞–Ω–Ω—ã–µ –∏ —Å–æ–±—ã—Ç–∏–µ –≤ –æ–¥–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
func (o *OutboxWriter) SaveWithEvent(ctx context.Context,
    businessFn func(tx pgx.Tx) error,
    topic, key string, payload []byte) error {

    tx, err := o.db.Begin(ctx)
    if err != nil {
        return fmt.Errorf("begin: %w", err)
    }
    defer tx.Rollback(ctx)

    // 1. –ë–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞
    if err := businessFn(tx); err != nil {
        return err
    }

    // 2. –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å–æ–±—ã—Ç–∏–µ –≤ outbox (—Ç–∞ –∂–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è!)
    _, err = tx.Exec(ctx,
        `INSERT INTO outbox (topic, key, payload) VALUES ($1, $2, $3)`,
        topic, key, payload,
    )
    if err != nil {
        return fmt.Errorf("outbox insert: %w", err)
    }

    return tx.Commit(ctx)
}

// OutboxRelay ‚Äî –≥–æ—Ä—É—Ç–∏–Ω–∞, –∫–æ—Ç–æ—Ä–∞—è —á–∏—Ç–∞–µ—Ç –∏–∑ outbox –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ –±—Ä–æ–∫–µ—Ä
type OutboxRelay struct {
    db     *pgxpool.Pool
    writer *kafka.Writer
}

func (r *OutboxRelay) Run(ctx context.Context) error {
    ticker := time.NewTicker(500 * time.Millisecond) // Polling –∫–∞–∂–¥—ã–µ 500ms
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return nil
        case <-ticker.C:
            if err := r.publishBatch(ctx); err != nil {
                log.Printf("outbox relay –æ—à–∏–±–∫–∞: %v", err)
            }
        }
    }
}

func (r *OutboxRelay) publishBatch(ctx context.Context) error {
    tx, err := r.db.Begin(ctx)
    if err != nil {
        return err
    }
    defer tx.Rollback(ctx)

    // –ß–∏—Ç–∞–µ–º –Ω–µ–æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è (—Å –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π FOR UPDATE SKIP LOCKED)
    rows, err := tx.Query(ctx,
        `SELECT id, topic, key, payload
         FROM outbox
         WHERE published_at IS NULL
         ORDER BY created_at
         LIMIT 100
         FOR UPDATE SKIP LOCKED`)
    if err != nil {
        return err
    }
    defer rows.Close()

    var ids []int64
    var messages []kafka.Message

    for rows.Next() {
        var id int64
        var topic, key string
        var payload []byte
        if err := rows.Scan(&id, &topic, &key, &payload); err != nil {
            return err
        }
        ids = append(ids, id)
        messages = append(messages, kafka.Message{
            Topic: topic,
            Key:   []byte(key),
            Value: payload,
        })
    }

    if len(messages) == 0 {
        return nil
    }

    // –ü—É–±–ª–∏–∫—É–µ–º –≤ Kafka
    if err := r.writer.WriteMessages(ctx, messages...); err != nil {
        return fmt.Errorf("publish: %w", err)
    }

    // –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ
    _, err = tx.Exec(ctx,
        `UPDATE outbox SET published_at = NOW() WHERE id = ANY($1)`,
        ids,
    )
    if err != nil {
        return fmt.Errorf("update outbox: %w", err)
    }

    log.Printf("outbox: –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ %d —Å–æ–±—ã—Ç–∏–π", len(messages))
    return tx.Commit(ctx)
}
```

### Saga Pattern

Saga ‚Äî –ø–∞—Ç—Ç–µ—Ä–Ω —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–º–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏ —á–µ—Ä–µ–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π —Å –∫–æ–º–ø–µ–Ω—Å–∏—Ä—É—é—â–∏–º–∏ –¥–µ–π—Å—Ç–≤–∏—è–º–∏.

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: MassTransit –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç `MassTransitStateMachine<T>` (Automatonymous) ‚Äî –¥–µ–∫–ª–∞—Ä–∞—Ç–∏–≤–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ saga —á–µ—Ä–µ–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ —Å–æ–±—ã—Ç–∏—è. –í Go saga —Ä–µ–∞–ª–∏–∑—É–µ—Ç—Å—è –≤—Ä—É—á–Ω—É—é ‚Äî –æ–±—ã—á–Ω–æ —á–µ—Ä–µ–∑ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –∏–ª–∏ —Ö–æ—Ä–µ–æ–≥—Ä–∞—Ñ–∏—é.

**–î–≤–∞ –ø–æ–¥—Ö–æ–¥–∞**:

| –ü–æ–¥—Ö–æ–¥ | –û–ø–∏—Å–∞–Ω–∏–µ | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |
|--------|----------|-------------------|
| **–•–æ—Ä–µ–æ–≥—Ä–∞—Ñ–∏—è** | –ö–∞–∂–¥—ã–π —Å–µ—Ä–≤–∏—Å —Å–ª—É—à–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è –∏ —Ä–µ–∞–≥–∏—Ä—É–µ—Ç | –ü—Ä–æ—Å—Ç—ã–µ —Å–∞–≥–∏ (2-3 —à–∞–≥–∞) |
| **–û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è** | –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä —É–ø—Ä–∞–≤–ª—è–µ—Ç —à–∞–≥–∞–º–∏ | –°–ª–æ–∂–Ω—ã–µ —Å–∞–≥–∏ (4+ —à–∞–≥–æ–≤) |

```go
// –ü—Ä–∏–º–µ—Ä —Ö–æ—Ä–µ–æ–≥—Ä–∞—Ñ–∏–∏: Order ‚Üí Payment ‚Üí Notification
//
// order-service:  OrderCreated  ‚Üí (Kafka) ‚Üí payment-service
// payment-service: PaymentCompleted ‚Üí (Kafka) ‚Üí notification-service
// payment-service: PaymentFailed ‚Üí (Kafka) ‚Üí order-service (–∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è)

// –û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è ‚Äî —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä
type SagaStep struct {
    Name       string
    Execute    func(ctx context.Context, data any) error
    Compensate func(ctx context.Context, data any) error // –û—Ç–∫–∞—Ç
}

type SagaOrchestrator struct {
    steps []SagaStep
}

func (s *SagaOrchestrator) Run(ctx context.Context, data any) error {
    var completedSteps []int

    for i, step := range s.steps {
        log.Printf("saga: –≤—ã–ø–æ–ª–Ω—è—é —à–∞–≥ %d (%s)", i, step.Name)

        if err := step.Execute(ctx, data); err != nil {
            log.Printf("saga: —à–∞–≥ %d (%s) failed: %v", i, step.Name, err)

            // –ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è ‚Äî –æ—Ç–∫–∞—Ç—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ —à–∞–≥–∏ –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
            for j := len(completedSteps) - 1; j >= 0; j-- {
                stepIdx := completedSteps[j]
                compStep := s.steps[stepIdx]
                if compStep.Compensate != nil {
                    log.Printf("saga: –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è —à–∞–≥–∞ %d (%s)", stepIdx, compStep.Name)
                    if compErr := compStep.Compensate(ctx, data); compErr != nil {
                        log.Printf("saga: –û–®–ò–ë–ö–ê –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏ —à–∞–≥–∞ %d: %v", stepIdx, compErr)
                        // –í production: –∑–∞–ø–∏—Å–∞—Ç—å –≤ outbox –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏
                    }
                }
            }

            return fmt.Errorf("saga failed –Ω–∞ —à–∞–≥–µ %s: %w", step.Name, err)
        }

        completedSteps = append(completedSteps, i)
    }

    log.Println("saga: –≤—Å–µ —à–∞–≥–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
    return nil
}
```

> –î–µ—Ç–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è saga —Å persistence –∏ recovery –±—É–¥–µ—Ç —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∞ –≤ [–ß–∞—Å—Ç–∏ 5: –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–µ–∫—Ç—ã](../part5-projects/) –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ E-commerce –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã.

---

## Production Concerns

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å Prometheus

```go
import "github.com/prometheus/client_golang/prometheus"

var (
    messagesProcessed = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "messages_processed_total",
            Help: "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π",
        },
        []string{"topic", "status"}, // status: success, error, dlq
    )

    messageProcessingDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "message_processing_duration_seconds",
            Help:    "–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è",
            Buckets: prometheus.DefBuckets,
        },
        []string{"topic"},
    )

    consumerLag = prometheus.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "consumer_lag",
            Help: "–û—Ç—Å—Ç–∞–≤–∞–Ω–∏–µ consumer –æ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è",
        },
        []string{"topic", "partition"},
    )

    dlqMessages = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "dlq_messages_total",
            Help: "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π, –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –≤ DLQ",
        },
        []string{"topic", "error_type"},
    )
)

func init() {
    prometheus.MustRegister(messagesProcessed, messageProcessingDuration, consumerLag, dlqMessages)
}

// –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π consumer
func processWithMetrics(ctx context.Context, topic string, msg []byte,
    handler func(context.Context, []byte) error) error {

    start := time.Now()

    err := handler(ctx, msg)

    duration := time.Since(start).Seconds()
    messageProcessingDuration.WithLabelValues(topic).Observe(duration)

    if err != nil {
        messagesProcessed.WithLabelValues(topic, "error").Inc()
        return err
    }

    messagesProcessed.WithLabelValues(topic, "success").Inc()
    return nil
}
```

#### Kafka Consumer Lag

```go
// –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ consumer lag ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è Kafka
func monitorConsumerLag(ctx context.Context, brokers []string, topic, groupID string) {
    conn, err := kafka.Dial("tcp", brokers[0])
    if err != nil {
        log.Printf("–æ—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: %v", err)
        return
    }
    defer conn.Close()

    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            partitions, err := conn.ReadPartitions(topic)
            if err != nil {
                log.Printf("–æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ø–∞—Ä—Ç–∏—Ü–∏–π: %v", err)
                continue
            }

            for _, p := range partitions {
                // –ü–æ–ª—É—á–∞–µ–º last offset –ø–∞—Ä—Ç–∏—Ü–∏–∏
                pConn, err := kafka.DialLeader(ctx, "tcp", brokers[0], topic, p.ID)
                if err != nil {
                    continue
                }
                lastOffset, _ := pConn.ReadLastOffset()
                pConn.Close()

                // Consumer lag = last offset - committed offset
                // (committed offset –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —á–µ—Ä–µ–∑ admin API)
                consumerLag.WithLabelValues(topic, fmt.Sprintf("%d", p.ID)).Set(
                    float64(lastOffset), // –£–ø—Ä–æ—â—ë–Ω–Ω–æ, –≤ production –Ω—É–∂–µ–Ω committed offset
                )
            }
        }
    }
}
```

### OpenTelemetry Instrumentation

```go
import (
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/propagation"
    "go.opentelemetry.io/otel/trace"
)

var tracer = otel.Tracer("message-queue")

// Producer ‚Äî –∏–Ω–∂–µ–∫—Ç–∏—Ä—É–µ–º trace context –≤ headers —Å–æ–æ–±—â–µ–Ω–∏—è
func publishWithTracing(ctx context.Context, w *kafka.Writer, topic string, payload []byte) error {
    ctx, span := tracer.Start(ctx, "kafka.publish",
        trace.WithAttributes(
            attribute.String("messaging.system", "kafka"),
            attribute.String("messaging.destination", topic),
            attribute.String("messaging.operation", "publish"),
        ),
    )
    defer span.End()

    // –ò–Ω–∂–µ–∫—Ç–∏—Ä—É–µ–º trace context –≤ Kafka headers
    headers := make([]kafka.Header, 0)
    carrier := &KafkaHeaderCarrier{headers: &headers}
    otel.GetTextMapPropagator().Inject(ctx, carrier)

    return w.WriteMessages(ctx, kafka.Message{
        Value:   payload,
        Headers: headers,
    })
}

// Consumer ‚Äî –∏–∑–≤–ª–µ–∫–∞–µ–º trace context –∏–∑ headers
func consumeWithTracing(ctx context.Context, msg kafka.Message,
    handler func(context.Context, kafka.Message) error) error {

    // –ò–∑–≤–ª–µ–∫–∞–µ–º trace context –∏–∑ Kafka headers
    carrier := &KafkaHeaderCarrier{headers: &msg.Headers}
    ctx = otel.GetTextMapPropagator().Extract(ctx, carrier)

    ctx, span := tracer.Start(ctx, "kafka.consume",
        trace.WithAttributes(
            attribute.String("messaging.system", "kafka"),
            attribute.String("messaging.destination", msg.Topic),
            attribute.String("messaging.operation", "receive"),
            attribute.Int64("messaging.kafka.partition", int64(msg.Partition)),
            attribute.Int64("messaging.kafka.offset", msg.Offset),
        ),
    )
    defer span.End()

    err := handler(ctx, msg)
    if err != nil {
        span.RecordError(err)
    }
    return err
}

// KafkaHeaderCarrier ‚Äî –∞–¥–∞–ø—Ç–µ—Ä –¥–ª—è OTel propagation
type KafkaHeaderCarrier struct {
    headers *[]kafka.Header
}

func (c *KafkaHeaderCarrier) Get(key string) string {
    for _, h := range *c.headers {
        if h.Key == key {
            return string(h.Value)
        }
    }
    return ""
}

func (c *KafkaHeaderCarrier) Set(key, value string) {
    *c.headers = append(*c.headers, kafka.Header{
        Key:   key,
        Value: []byte(value),
    })
}

func (c *KafkaHeaderCarrier) Keys() []string {
    keys := make([]string, len(*c.headers))
    for i, h := range *c.headers {
        keys[i] = h.Key
    }
    return keys
}
```

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: –í MassTransit tracing –≤–∫–ª—é—á–∞–µ—Ç—Å—è –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π: `cfg.UseOpenTelemetry()`. –í Go –≤—ã –≤—Ä—É—á–Ω—É—é –∏–Ω–∂–µ–∫—Ç–∏—Ä—É–µ—Ç–µ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç–µ trace context —á–µ—Ä–µ–∑ headers. –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç–æ—Ç –∂–µ ‚Äî —Å–≤—è–∑–∞–Ω–Ω—ã–µ spans –æ—Ç producer –∫ consumer –≤ Jaeger/Tempo.

### Health Checks

```go
// Health check –¥–ª—è message queue consumers
type MQHealthChecker struct {
    kafkaReader  *kafka.Reader
    rabbitClient *RabbitMQClient
    natsConn     *nats.Conn
    redisClient  *redis.Client
}

func (h *MQHealthChecker) CheckKafka(ctx context.Context) error {
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ reader –ø–æ–¥–∫–ª—é—á—ë–Ω –∏ —á–∏—Ç–∞–µ—Ç
    stats := h.kafkaReader.Stats()
    if stats.Dials > 0 && stats.Errors > stats.Dials/2 {
        return fmt.Errorf("kafka: –≤—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –æ—à–∏–±–æ–∫ (%d/%d)", stats.Errors, stats.Dials)
    }
    return nil
}

func (h *MQHealthChecker) CheckRabbitMQ(ctx context.Context) error {
    ch := h.rabbitClient.Channel()
    if ch == nil || ch.IsClosed() {
        return fmt.Errorf("rabbitmq: –∫–∞–Ω–∞–ª –∑–∞–∫—Ä—ã—Ç")
    }
    return nil
}

func (h *MQHealthChecker) CheckNATS(ctx context.Context) error {
    if !h.natsConn.IsConnected() {
        return fmt.Errorf("nats: –Ω–µ –ø–æ–¥–∫–ª—é—á—ë–Ω (status=%v)", h.natsConn.Status())
    }
    return nil
}

func (h *MQHealthChecker) CheckRedisStreams(ctx context.Context) error {
    return h.redisClient.Ping(ctx).Err()
}
```

---

## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã

### –ü—Ä–∏–º–µ—Ä 1: Event-Driven Order Processing (Kafka)

**–ó–∞–¥–∞—á–∞**: –°–µ—Ä–≤–∏—Å –∑–∞–∫–∞–∑–æ–≤ –ø—É–±–ª–∏–∫—É–µ—Ç —Å–æ–±—ã—Ç–∏–µ `OrderCreated` –≤ Kafka. –°–µ—Ä–≤–∏—Å –ø–ª–∞—Ç–µ–∂–µ–π –ø–æ—Ç—Ä–µ–±–ª—è–µ—Ç —Å–æ–±—ã—Ç–∏–µ, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–ø–ª–∞—Ç—É –∏ –ø—É–±–ª–∏–∫—É–µ—Ç `PaymentCompleted`. –†–µ–∞–ª–∏–∑—É–µ–º –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∏ DLT.

**C# —Å MassTransit**:
```csharp
// –í C# ‚Äî –≤—Å—ë –¥–µ–∫–ª–∞—Ä–∞—Ç–∏–≤–Ω–æ:
public class OrderCreatedConsumer : IConsumer<OrderCreated>
{
    public async Task Consume(ConsumeContext<OrderCreated> context)
    {
        await _paymentService.ProcessPayment(context.Message.OrderId);
        await context.Publish(new PaymentCompleted(context.Message.OrderId));
    }
}
// MassTransit –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è, retry, DLQ, tracing
```

**Go ‚Äî –ø–æ–ª–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è**:

```go
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "os/signal"
    "sync"
    "syscall"
    "time"

    "github.com/jackc/pgx/v5/pgxpool"
    "github.com/segmentio/kafka-go"
)

// --- –ú–æ–¥–µ–ª–∏ ---

type OrderCreated struct {
    OrderID    string  `json:"order_id"`
    CustomerID string  `json:"customer_id"`
    Total      float64 `json:"total"`
    Currency   string  `json:"currency"`
    CreatedAt  string  `json:"created_at"`
}

type PaymentCompleted struct {
    OrderID       string  `json:"order_id"`
    TransactionID string  `json:"transaction_id"`
    Amount        float64 `json:"amount"`
    ProcessedAt   string  `json:"processed_at"`
}

// --- Payment Processor ---

type PaymentProcessor struct {
    reader      *kafka.Reader
    writer      *kafka.Writer    // –î–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ PaymentCompleted
    dlqWriter   *kafka.Writer    // Dead Letter Topic
    db          *pgxpool.Pool
    idempotency *IdempotencyChecker
}

func NewPaymentProcessor(brokers []string, db *pgxpool.Pool) *PaymentProcessor {
    return &PaymentProcessor{
        reader: kafka.NewReader(kafka.ReaderConfig{
            Brokers:  brokers,
            Topic:    "orders.created",
            GroupID:  "payment-processor",
            MaxBytes: 10e6,
        }),
        writer: &kafka.Writer{
            Addr:         kafka.TCP(brokers...),
            Topic:        "payments.completed",
            Balancer:     &kafka.Hash{},
            RequiredAcks: kafka.RequireAll,
        },
        dlqWriter: &kafka.Writer{
            Addr:  kafka.TCP(brokers...),
            Topic: "orders.created.dlq",
        },
        db:          db,
        idempotency: NewIdempotencyChecker(db),
    }
}

func (p *PaymentProcessor) Run(ctx context.Context) error {
    defer p.reader.Close()
    defer p.writer.Close()
    defer p.dlqWriter.Close()

    log.Println("payment processor –∑–∞–ø—É—â–µ–Ω")

    for {
        msg, err := p.reader.FetchMessage(ctx)
        if err != nil {
            if ctx.Err() != nil {
                return nil
            }
            log.Printf("fetch –æ—à–∏–±–∫–∞: %v", err)
            continue
        }

        if err := p.handleMessage(ctx, msg); err != nil {
            log.Printf("–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è failed (offset=%d): %v", msg.Offset, err)
        }

        // –ö–æ–º–º–∏—Ç–∏–º offset –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        // (–æ—à–∏–±–∫–∏ —É—à–ª–∏ –≤ DLQ –∏–ª–∏ –±—É–¥—É—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –ø—Ä–∏ retry)
        if err := p.reader.CommitMessages(ctx, msg); err != nil {
            log.Printf("commit –æ—à–∏–±–∫–∞: %v", err)
        }
    }
}

func (p *PaymentProcessor) handleMessage(ctx context.Context, msg kafka.Message) error {
    var event OrderCreated
    if err := json.Unmarshal(msg.Value, &event); err != nil {
        // –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON ‚Äî permanent error, —Å—Ä–∞–∑—É –≤ DLQ
        return p.sendToDLQ(ctx, msg, fmt.Errorf("–Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON: %w", err))
    }

    // –ò–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    messageID := getMessageID(msg)
    err := p.idempotency.Process(ctx, messageID, func(ctx context.Context) error {
        return p.processPayment(ctx, event)
    })

    if err != nil {
        // Retry —Å backoff
        retryErr := retryWithBackoff(ctx, 3, func(ctx context.Context) error {
            return p.idempotency.Process(ctx, messageID, func(ctx context.Context) error {
                return p.processPayment(ctx, event)
            })
        })

        if retryErr != nil {
            return p.sendToDLQ(ctx, msg, retryErr)
        }
    }

    return nil
}

func (p *PaymentProcessor) processPayment(ctx context.Context, event OrderCreated) error {
    // –ë–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–ª–∞—Ç–µ–∂–∞
    log.Printf("–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–ª–∞—Ç–µ–∂–∞ –¥–ª—è –∑–∞–∫–∞–∑–∞ %s: %.2f %s",
        event.OrderID, event.Total, event.Currency)

    // –ü—É–±–ª–∏–∫—É–µ–º —Å–æ–±—ã—Ç–∏–µ PaymentCompleted
    completed := PaymentCompleted{
        OrderID:       event.OrderID,
        TransactionID: fmt.Sprintf("txn_%s_%d", event.OrderID, time.Now().UnixNano()),
        Amount:        event.Total,
        ProcessedAt:   time.Now().UTC().Format(time.RFC3339),
    }

    data, err := json.Marshal(completed)
    if err != nil {
        return fmt.Errorf("—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è PaymentCompleted: %w", err)
    }

    return p.writer.WriteMessages(ctx, kafka.Message{
        Key:   []byte(event.OrderID),
        Value: data,
    })
}

func (p *PaymentProcessor) sendToDLQ(ctx context.Context, msg kafka.Message, processingErr error) error {
    log.Printf("–æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ DLQ (offset=%d): %v", msg.Offset, processingErr)

    headers := append(msg.Headers,
        kafka.Header{Key: "dlq-error", Value: []byte(processingErr.Error())},
        kafka.Header{Key: "dlq-timestamp", Value: []byte(time.Now().UTC().Format(time.RFC3339))},
    )

    return p.dlqWriter.WriteMessages(ctx, kafka.Message{
        Key:     msg.Key,
        Value:   msg.Value,
        Headers: headers,
    })
}

func getMessageID(msg kafka.Message) string {
    for _, h := range msg.Headers {
        if h.Key == "message-id" {
            return string(h.Value)
        }
    }
    return fmt.Sprintf("%s-%d-%d", msg.Topic, msg.Partition, msg.Offset)
}

func main() {
    ctx, stop := signal.NotifyContext(context.Background(), syscall.SIGINT, syscall.SIGTERM)
    defer stop()

    db, _ := pgxpool.New(ctx, "postgres://localhost:5432/payments")
    defer db.Close()

    processor := NewPaymentProcessor([]string{"localhost:9092"}, db)

    if err := processor.Run(ctx); err != nil {
        log.Fatal(err)
    }
}
```

---

### –ü—Ä–∏–º–µ—Ä 2: Task Queue —Å RabbitMQ

**–ó–∞–¥–∞—á–∞**: –§–æ–Ω–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á (–æ—Ç–ø—Ä–∞–≤–∫–∞ email, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–æ–≤). Worker pool —Å prefetch, publisher confirms –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º.

```go
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "os/signal"
    "sync"
    "syscall"
    "time"

    amqp "github.com/rabbitmq/amqp091-go"
)

// --- –ú–æ–¥–µ–ª–∏ ---

type Task struct {
    ID      string          `json:"id"`
    Type    string          `json:"type"`    // "send_email", "generate_report"
    Payload json.RawMessage `json:"payload"`
}

type EmailPayload struct {
    To      string `json:"to"`
    Subject string `json:"subject"`
    Body    string `json:"body"`
}

// --- Task Publisher ---

type TaskPublisher struct {
    client *RabbitMQClient // –û–±—ë—Ä—Ç–∫–∞ —Å reconnection –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ –≤—ã—à–µ
}

func (p *TaskPublisher) PublishTask(ctx context.Context, task Task) error {
    body, err := json.Marshal(task)
    if err != nil {
        return fmt.Errorf("—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è: %w", err)
    }

    return p.client.Publish(ctx, "tasks", task.Type, amqp.Publishing{
        ContentType:  "application/json",
        DeliveryMode: amqp.Persistent,
        MessageId:    task.ID,
        Timestamp:    time.Now(),
        Body:         body,
    })
}

// --- Task Worker ---

type TaskWorker struct {
    url       string
    queueName string
    workers   int
    handlers  map[string]func(context.Context, json.RawMessage) error
}

func NewTaskWorker(url, queueName string, workers int) *TaskWorker {
    return &TaskWorker{
        url:       url,
        queueName: queueName,
        workers:   workers,
        handlers:  make(map[string]func(context.Context, json.RawMessage) error),
    }
}

func (w *TaskWorker) RegisterHandler(taskType string, handler func(context.Context, json.RawMessage) error) {
    w.handlers[taskType] = handler
}

func (w *TaskWorker) Run(ctx context.Context) error {
    for {
        err := w.runOnce(ctx)
        if ctx.Err() != nil {
            return nil // –®—Ç–∞—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
        }

        // –ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        log.Printf("worker –æ—à–∏–±–∫–∞: %v, –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...", err)
        select {
        case <-time.After(5 * time.Second):
        case <-ctx.Done():
            return nil
        }
    }
}

func (w *TaskWorker) runOnce(ctx context.Context) error {
    conn, err := amqp.Dial(w.url)
    if err != nil {
        return fmt.Errorf("dial: %w", err)
    }
    defer conn.Close()

    ch, err := conn.Channel()
    if err != nil {
        return fmt.Errorf("channel: %w", err)
    }
    defer ch.Close()

    // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ç–æ–ø–æ–ª–æ–≥–∏—é
    if err := w.setupTopology(ch); err != nil {
        return err
    }

    // Prefetch = 2 * workers
    if err := ch.Qos(w.workers*2, 0, false); err != nil {
        return fmt.Errorf("qos: %w", err)
    }

    deliveries, err := ch.Consume(w.queueName, "", false, false, false, false, nil)
    if err != nil {
        return fmt.Errorf("consume: %w", err)
    }

    // –°–ª–µ–¥–∏–º –∑–∞ –∑–∞–∫—Ä—ã—Ç–∏–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    connClose := conn.NotifyClose(make(chan *amqp.Error, 1))

    var wg sync.WaitGroup

    for i := 0; i < w.workers; i++ {
        wg.Add(1)
        go func(workerID int) {
            defer wg.Done()
            for {
                select {
                case d, ok := <-deliveries:
                    if !ok {
                        return
                    }
                    w.processDelivery(ctx, workerID, ch, d)

                case <-ctx.Done():
                    return
                }
            }
        }(i)
    }

    // –ñ–¥—ë–º –∑–∞–∫—Ä—ã—Ç–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∏–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    select {
    case amqpErr := <-connClose:
        return fmt.Errorf("—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–∫—Ä—ã—Ç–æ: %v", amqpErr)
    case <-ctx.Done():
        wg.Wait()
        return nil
    }
}

func (w *TaskWorker) setupTopology(ch *amqp.Channel) error {
    // Exchange –¥–ª—è –∑–∞–¥–∞—á
    if err := ch.ExchangeDeclare("tasks", "direct", true, false, false, false, nil); err != nil {
        return err
    }

    // DLX
    if err := ch.ExchangeDeclare("tasks.dlx", "direct", true, false, false, false, nil); err != nil {
        return err
    }

    // –û—Å–Ω–æ–≤–Ω–∞—è –æ—á–µ—Ä–µ–¥—å —Å DLX
    _, err := ch.QueueDeclare(w.queueName, true, false, false, false, amqp.Table{
        "x-dead-letter-exchange":    "tasks.dlx",
        "x-dead-letter-routing-key": "dead",
    })
    if err != nil {
        return err
    }

    // –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –≤—Å–µ —Ç–∏–ø—ã –∑–∞–¥–∞—á
    for taskType := range w.handlers {
        if err := ch.QueueBind(w.queueName, taskType, "tasks", false, nil); err != nil {
            return err
        }
    }

    // DLQ
    ch.QueueDeclare("tasks.dlq", true, false, false, false, nil)
    ch.QueueBind("tasks.dlq", "dead", "tasks.dlx", false, nil)

    return nil
}

func (w *TaskWorker) processDelivery(ctx context.Context, workerID int, ch *amqp.Channel, d amqp.Delivery) {
    var task Task
    if err := json.Unmarshal(d.Body, &task); err != nil {
        log.Printf("[worker %d] –Ω–µ–≤–∞–ª–∏–¥–Ω–∞—è –∑–∞–¥–∞—á–∞: %v", workerID, err)
        d.Reject(false) // –í DLX
        return
    }

    handler, ok := w.handlers[task.Type]
    if !ok {
        log.Printf("[worker %d] –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∑–∞–¥–∞—á–∏: %s", workerID, task.Type)
        d.Reject(false) // –í DLX
        return
    }

    log.Printf("[worker %d] –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ %s (—Ç–∏–ø: %s)", workerID, task.ID, task.Type)

    if err := handler(ctx, task.Payload); err != nil {
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ —á–µ—Ä–µ–∑ x-death header
        retryCount := getRetryCount(d)
        if retryCount >= 3 {
            log.Printf("[worker %d] –∑–∞–¥–∞—á–∞ %s: –∏—Å—á–µ—Ä–ø–∞–Ω—ã –ø–æ–ø—ã—Ç–∫–∏ (%d), –≤ DLQ", workerID, task.ID, retryCount)
            d.Reject(false) // –í DLX ‚Üí DLQ
        } else {
            log.Printf("[worker %d] –∑–∞–¥–∞—á–∞ %s: –æ—à–∏–±–∫–∞ (–ø–æ–ø—ã—Ç–∫–∞ %d): %v", workerID, task.ID, retryCount+1, err)
            d.Nack(false, true) // Requeue –¥–ª—è –ø–æ–≤—Ç–æ—Ä–∞
        }
        return
    }

    d.Ack(false)
    log.Printf("[worker %d] –∑–∞–¥–∞—á–∞ %s –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ", workerID, task.ID)
}

func getRetryCount(d amqp.Delivery) int {
    if d.Headers == nil {
        return 0
    }
    deaths, ok := d.Headers["x-death"].([]interface{})
    if !ok || len(deaths) == 0 {
        return 0
    }
    death, ok := deaths[0].(amqp.Table)
    if !ok {
        return 0
    }
    count, ok := death["count"].(int64)
    if !ok {
        return 0
    }
    return int(count)
}

func main() {
    ctx, stop := signal.NotifyContext(context.Background(), syscall.SIGINT, syscall.SIGTERM)
    defer stop()

    worker := NewTaskWorker("amqp://guest:guest@localhost:5672/", "task-queue", 5)

    // –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    worker.RegisterHandler("send_email", func(ctx context.Context, payload json.RawMessage) error {
        var email EmailPayload
        if err := json.Unmarshal(payload, &email); err != nil {
            return err
        }
        log.Printf("–æ—Ç–ø—Ä–∞–≤–∫–∞ email: to=%s subject=%s", email.To, email.Subject)
        // –ó–¥–µ—Å—å —Ä–µ–∞–ª—å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —á–µ—Ä–µ–∑ SMTP
        return nil
    })

    worker.RegisterHandler("generate_report", func(ctx context.Context, payload json.RawMessage) error {
        log.Println("–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞...")
        time.Sleep(2 * time.Second) // –ò–º–∏—Ç–∞—Ü–∏—è —Ç—è–∂—ë–ª–æ–π —Ä–∞–±–æ—Ç—ã
        return nil
    })

    log.Println("task worker –∑–∞–ø—É—â–µ–Ω (5 –≤–æ—Ä–∫–µ—Ä–æ–≤)")
    if err := worker.Run(ctx); err != nil {
        log.Fatal(err)
    }
}
```

---

### –ü—Ä–∏–º–µ—Ä 3: Real-Time Notifications (NATS)

**–ó–∞–¥–∞—á–∞**: –°–µ—Ä–≤–∏—Å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –ø–æ–ª—É—á–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è —á–µ—Ä–µ–∑ NATS –∏ –ø–µ—Ä–µ—Å—ã–ª–∞–µ—Ç –ø–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã–º –∫–ª–∏–µ–Ω—Ç–∞–º —á–µ—Ä–µ–∑ WebSocket. JetStream –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –Ω–µ —Ç–µ—Ä—è—é—Ç—Å—è.

```go
package main

import (
    "context"
    "encoding/json"
    "log"
    "net/http"
    "os/signal"
    "sync"
    "syscall"
    "time"

    "github.com/gorilla/websocket"
    "github.com/nats-io/nats.go"
    "github.com/nats-io/nats.go/jetstream"
)

// --- –ú–æ–¥–µ–ª–∏ ---

type Notification struct {
    ID        string `json:"id"`
    UserID    string `json:"user_id"`
    Type      string `json:"type"`    // "order_update", "payment", "system"
    Title     string `json:"title"`
    Message   string `json:"message"`
    CreatedAt string `json:"created_at"`
}

// --- WebSocket Hub ---

type Hub struct {
    mu      sync.RWMutex
    clients map[string]map[*websocket.Conn]struct{} // userID ‚Üí connections
}

func NewHub() *Hub {
    return &Hub{
        clients: make(map[string]map[*websocket.Conn]struct{}),
    }
}

func (h *Hub) Register(userID string, conn *websocket.Conn) {
    h.mu.Lock()
    defer h.mu.Unlock()
    if h.clients[userID] == nil {
        h.clients[userID] = make(map[*websocket.Conn]struct{})
    }
    h.clients[userID][conn] = struct{}{}
    log.Printf("WebSocket –ø–æ–¥–∫–ª—é—á—ë–Ω: user=%s (–≤—Å–µ–≥–æ: %d)", userID, len(h.clients[userID]))
}

func (h *Hub) Unregister(userID string, conn *websocket.Conn) {
    h.mu.Lock()
    defer h.mu.Unlock()
    if conns, ok := h.clients[userID]; ok {
        delete(conns, conn)
        if len(conns) == 0 {
            delete(h.clients, userID)
        }
    }
    conn.Close()
}

func (h *Hub) SendToUser(userID string, data []byte) {
    h.mu.RLock()
    defer h.mu.RUnlock()

    conns, ok := h.clients[userID]
    if !ok {
        return
    }

    for conn := range conns {
        if err := conn.WriteMessage(websocket.TextMessage, data); err != nil {
            log.Printf("–æ—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ WebSocket: %v", err)
            go h.Unregister(userID, conn)
        }
    }
}

// --- NATS Consumer ---

type NotificationConsumer struct {
    js  jetstream.JetStream
    hub *Hub
}

func NewNotificationConsumer(nc *nats.Conn, hub *Hub) (*NotificationConsumer, error) {
    js, err := jetstream.New(nc)
    if err != nil {
        return nil, err
    }

    return &NotificationConsumer{js: js, hub: hub}, nil
}

func (c *NotificationConsumer) Setup(ctx context.Context) error {
    // –°–æ–∑–¥–∞—ë–º stream –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
    _, err := c.js.CreateOrUpdateStream(ctx, jetstream.StreamConfig{
        Name:      "NOTIFICATIONS",
        Subjects:  []string{"notifications.>"},
        Storage:   jetstream.FileStorage,
        Retention: jetstream.InterestPolicy, // –£–¥–∞–ª—è—Ç—å –ø–æ—Å–ª–µ –¥–æ—Å—Ç–∞–≤–∫–∏ –≤—Å–µ–º consumers
        MaxAge:    24 * time.Hour,
    })
    return err
}

func (c *NotificationConsumer) Run(ctx context.Context) error {
    // Durable consumer ‚Äî –Ω–µ –ø–æ—Ç–µ—Ä—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –ø—Ä–∏ —Ä–µ—Å—Ç–∞—Ä—Ç–µ
    consumer, err := c.js.CreateOrUpdateConsumer(ctx, "NOTIFICATIONS", jetstream.ConsumerConfig{
        Name:          "ws-gateway",
        Durable:       "ws-gateway",
        DeliverPolicy: jetstream.DeliverNewPolicy,
        AckPolicy:     jetstream.AckExplicitPolicy,
        AckWait:       10 * time.Second,
        MaxDeliver:    3,
    })
    if err != nil {
        return err
    }

    iter, err := consumer.Messages()
    if err != nil {
        return err
    }
    defer iter.Stop()

    for {
        msg, err := iter.Next()
        if err != nil {
            if ctx.Err() != nil {
                return nil
            }
            log.Printf("next –æ—à–∏–±–∫–∞: %v", err)
            continue
        }

        var notif Notification
        if err := json.Unmarshal(msg.Data(), &notif); err != nil {
            log.Printf("–Ω–µ–≤–∞–ª–∏–¥–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ: %v", err)
            msg.Term() // –ù–µ retry ‚Äî –¥–∞–Ω–Ω—ã–µ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã
            continue
        }

        // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ WebSocket
        c.hub.SendToUser(notif.UserID, msg.Data())
        msg.Ack()

        log.Printf("—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ: user=%s type=%s", notif.UserID, notif.Type)
    }
}

// --- HTTP/WebSocket Server ---

var upgrader = websocket.Upgrader{
    CheckOrigin: func(r *http.Request) bool { return true }, // –í production: –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ origin
}

func wsHandler(hub *Hub) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        userID := r.URL.Query().Get("user_id")
        if userID == "" {
            http.Error(w, "user_id –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω", http.StatusBadRequest)
            return
        }

        conn, err := upgrader.Upgrade(w, r, nil)
        if err != nil {
            log.Printf("WebSocket upgrade –æ—à–∏–±–∫–∞: %v", err)
            return
        }

        hub.Register(userID, conn)
        defer hub.Unregister(userID, conn)

        // –ß–∏—Ç–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞ (ping/pong, close)
        for {
            _, _, err := conn.ReadMessage()
            if err != nil {
                break
            }
        }
    }
}

// --- –ü—É–±–ª–∏–∫–∞—Ü–∏—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π (–∏–∑ –¥—Ä—É–≥–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤) ---

func publishNotification(js jetstream.JetStream, notif Notification) error {
    data, err := json.Marshal(notif)
    if err != nil {
        return err
    }

    _, err = js.Publish(context.Background(),
        "notifications."+notif.UserID, // Subject = notifications.<user_id>
        data,
        jetstream.WithMsgID(notif.ID), // –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
    )
    return err
}

func main() {
    ctx, stop := signal.NotifyContext(context.Background(), syscall.SIGINT, syscall.SIGTERM)
    defer stop()

    // –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ NATS
    nc, err := nats.Connect("nats://localhost:4222",
        nats.ReconnectWait(2*time.Second),
        nats.MaxReconnects(-1), // –ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏
    )
    if err != nil {
        log.Fatal(err)
    }
    defer nc.Close()

    hub := NewHub()

    consumer, err := NewNotificationConsumer(nc, hub)
    if err != nil {
        log.Fatal(err)
    }

    if err := consumer.Setup(ctx); err != nil {
        log.Fatal(err)
    }

    // –ó–∞–ø—É—Å–∫–∞–µ–º NATS consumer –≤ –≥–æ—Ä—É—Ç–∏–Ω–µ
    go func() {
        if err := consumer.Run(ctx); err != nil {
            log.Printf("consumer –æ—à–∏–±–∫–∞: %v", err)
        }
    }()

    // HTTP —Å–µ—Ä–≤–µ—Ä
    mux := http.NewServeMux()
    mux.HandleFunc("/ws", wsHandler(hub))

    server := &http.Server{Addr: ":8080", Handler: mux}

    go func() {
        log.Println("WebSocket —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ :8080")
        if err := server.ListenAndServe(); err != http.ErrServerClosed {
            log.Fatal(err)
        }
    }()

    <-ctx.Done()
    server.Shutdown(context.Background())
    log.Println("—Å–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
}
```

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: –≠—Ç–æ—Ç –ø—Ä–∏–º–µ—Ä ‚Äî –∞–Ω–∞–ª–æ–≥ SignalR —Å backplane –Ω–∞ Azure Service Bus. –í C# –≤—ã –±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ `IHubContext<NotificationHub>` –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –∫–ª–∏–µ–Ω—Ç–∞–º. –í Go ‚Äî gorilla/websocket (–∏–ª–∏ nhooyr.io/websocket) + NATS JetStream.

---

## –ß–µ–∫-–ª–∏—Å—Ç

–ü–æ—Å–ª–µ –∏–∑—É—á–µ–Ω–∏—è —ç—Ç–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ –≤—ã –¥–æ–ª–∂–Ω—ã —É–º–µ—Ç—å:

### Kafka
- [ ] –ü–æ–¥–∫–ª—é—á–∏—Ç—å segmentio/kafka-go (Writer/Reader)
- [ ] –û—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è —Å –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø–æ –∫–ª—é—á—É
- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å compression (Zstd/LZ4/Snappy) –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ç—Ä–∞—Ñ–∏–∫–∞
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å consumer group —Å manual commit (FetchMessage + CommitMessages)
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å worker pool –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å TLS/SASL –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Dead Letter Topic —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –æ—à–∏–±–∫–∏

### RabbitMQ
- [ ] –ü–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è —á–µ—Ä–µ–∑ amqp091-go, –ø–æ–Ω–∏–º–∞—Ç—å —Ä–∞–∑–Ω–∏—Ü—É Connection vs Channel
- [ ] –ó–Ω–∞—Ç—å, —á—Ç–æ Channel **–ù–ï** goroutine-safe (–æ–¥–∏–Ω –∫–∞–Ω–∞–ª –Ω–∞ –≥–æ—Ä—É—Ç–∏–Ω—É)
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å exchanges (direct, fanout, topic), queues –∏ bindings
- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å publisher confirms –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–æ—Å—Ç–∞–≤–∫–∏
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å prefetch (Qos) –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è backpressure
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å ack/nack/reject —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å **–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ** (–≤ Go –Ω–µ—Ç AutomaticRecoveryEnabled!)
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å Dead Letter Exchange (DLX) –∏ retry —á–µ—Ä–µ–∑ TTL

### NATS
- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Core NATS –¥–ª—è pub/sub –∏ request/reply
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å queue groups –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –Ω–∞–≥—Ä—É–∑–∫–∏
- [ ] –°–æ–∑–¥–∞—Ç—å JetStream stream —Å retention policy
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å durable consumer (push –∏–ª–∏ pull)
- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Key-Value Store –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤

### Redis Streams
- [ ] –î–æ–±–∞–≤–ª—è—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ XADD (go-redis)
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å consumer group (XGROUP CREATE, XREADGROUP)
- [ ] –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —á–µ—Ä–µ–∑ XACK
- [ ] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å ¬´–∑–∞—Å—Ç—Ä—è–≤—à–∏–µ¬ª —Å–æ–æ–±—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ XCLAIM/XAUTOCLAIM
- [ ] –ü—Ä–∏–Ω–∏–º–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ: Redis Streams vs Kafka vs RabbitMQ vs NATS

### –ü–∞—Ç—Ç–µ—Ä–Ω—ã
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω—ã–π consumer (deduplication —á–µ—Ä–µ–∑ –ë–î)
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å graceful shutdown —Å os.Signal + context + WaitGroup
- [ ] –ü—Ä–∏–º–µ–Ω—è—Ç—å retry —Å exponential backoff –∏ jitter
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Outbox Pattern –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ—Å—Ç–∏ DB + MQ
- [ ] –í—ã–±–∏—Ä–∞—Ç—å —Ñ–æ—Ä–º–∞—Ç —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ (JSON vs Protobuf vs Avro)

### Production
- [ ] –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å consumer lag, message rate, DLQ depth —á–µ—Ä–µ–∑ Prometheus
- [ ] –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å producer/consumer —á–µ—Ä–µ–∑ OpenTelemetry (trace propagation –≤ headers)
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å health checks –¥–ª—è –≤—Å–µ—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –±—Ä–æ–∫–µ—Ä–æ–≤
- [ ] –ü–æ–Ω–∏–º–∞—Ç—å, —á—Ç–æ –≤ Go –Ω–µ—Ç –∞–Ω–∞–ª–æ–≥–∞ MassTransit ‚Äî –≤—Å–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–µ–∞–ª–∏–∑—É—é—Ç—Å—è —è–≤–Ω–æ

---

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

–ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ [4.4 gRPC](./04_grpc.md) ‚Äî Protocol Buffers, Unary –∏ Streaming RPC, Interceptors, gRPC-Gateway.

---

**–í–æ–ø—Ä–æ—Å—ã?** –û—Ç–∫—Ä–æ–π—Ç–µ issue –Ω–∞ [GitHub](https://github.com/AlexandrTolstuhin/csharp-to-go/issues)

[‚Üê –ù–∞–∑–∞–¥: 4.2 –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ](./02_caching.md) | [–í–ø–µ—Ä—ë–¥: 4.4 gRPC ‚Üí](./04_grpc.md)

