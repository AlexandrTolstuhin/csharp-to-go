# 4.1 Production PostgreSQL

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

- [–í–≤–µ–¥–µ–Ω–∏–µ](#–≤–≤–µ–¥–µ–Ω–∏–µ)
- [Advanced pgx Configuration](#advanced-pgx-configuration)
  - [–î–µ—Ç–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è pgxpool](#–¥–µ—Ç–∞–ª—å–Ω–∞—è-–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è-pgxpool)
  - [Custom Types —Å pgtype](#custom-types-—Å-pgtype)
  - [Query Tracing](#query-tracing)
  - [Connection Hooks](#connection-hooks)
- [Production Connection Pooling](#production-connection-pooling)
  - [pgxpool vs PgBouncer](#pgxpool-vs-pgbouncer)
  - [–ù–∞—Å—Ç—Ä–æ–π–∫–∞ PgBouncer](#–Ω–∞—Å—Ç—Ä–æ–π–∫–∞-pgbouncer)
  - [–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—É–ª–∞](#–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥-–ø—É–ª–∞)
  - [Graceful Shutdown](#graceful-shutdown)
  - [Health Checks](#health-checks)
- [–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π sqlc](#–ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π-sqlc)
  - [–°–ª–æ–∂–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã](#—Å–ª–æ–∂–Ω—ã–µ-–∑–∞–ø—Ä–æ—Å—ã)
  - [Dynamic Queries](#dynamic-queries)
  - [–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –≤ sqlc](#—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏-–≤-sqlc)
  - [Batch Operations](#batch-operations-–≤-sqlc)
  - [Custom Types –∏ Overrides](#custom-types-–∏-overrides)
- [Zero-Downtime Migrations](#zero-downtime-migrations)
  - [–û–ø–∞—Å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏](#–æ–ø–∞—Å–Ω—ã–µ-–æ–ø–µ—Ä–∞—Ü–∏–∏)
  - [–ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã](#–±–µ–∑–æ–ø–∞—Å–Ω—ã–µ-–ø–∞—Ç—Ç–µ—Ä–Ω—ã)
  - [Expand/Contract Pattern](#expandcontract-pattern)
  - [Atlas: Declarative Migrations](#atlas-declarative-migrations)
- [Query Performance](#query-performance)
  - [EXPLAIN ANALYZE –∏–∑ Go](#explain-analyze-–∏–∑-go)
  - [–¢–∏–ø—ã –∏–Ω–¥–µ–∫—Å–æ–≤](#—Ç–∏–ø—ã-–∏–Ω–¥–µ–∫—Å–æ–≤)
  - [Query Tuning](#query-tuning)
  - [pg_stat_statements](#pg_stat_statements)
- [High Availability](#high-availability)
  - [Read Replicas](#read-replicas)
  - [Connection String –¥–ª—è HA](#connection-string-–¥–ª—è-ha)
  - [Retry Strategies](#retry-strategies)
  - [Circuit Breaker](#circuit-breaker)
- [Security](#security)
  - [SSL/TLS Connections](#ssltls-connections)
  - [Row-Level Security](#row-level-security)
  - [Secrets Management](#secrets-management)
- [Observability –¥–ª—è PostgreSQL](#observability-–¥–ª—è-postgresql)
  - [–ú–µ—Ç—Ä–∏–∫–∏ pg_stat_*](#–º–µ—Ç—Ä–∏–∫–∏-pg_stat)
  - [Prometheus Integration](#prometheus-integration)
  - [OpenTelemetry Instrumentation](#opentelemetry-instrumentation)
- [–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã](#–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ-–ø—Ä–∏–º–µ—Ä—ã)
  - [–ü—Ä–∏–º–µ—Ä 1: Production-Ready Connection Setup](#–ø—Ä–∏–º–µ—Ä-1-production-ready-connection-setup)
  - [–ü—Ä–∏–º–µ—Ä 2: Zero-Downtime Migration](#–ø—Ä–∏–º–µ—Ä-2-zero-downtime-migration)
  - [–ü—Ä–∏–º–µ—Ä 3: Read Replica Routing](#–ø—Ä–∏–º–µ—Ä-3-read-replica-routing)
- [–ß–µ–∫-–ª–∏—Å—Ç](#—á–µ–∫-–ª–∏—Å—Ç)

---

## –í–≤–µ–¥–µ–Ω–∏–µ

–í [—Ä–∞–∑–¥–µ–ª–µ 3.3](../part3-web-api/03_database.md) –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–ª–∏ –æ—Å–Ω–æ–≤—ã —Ä–∞–±–æ—Ç—ã —Å PostgreSQL –≤ Go: database/sql, pgx, sqlc, –º–∏–≥—Ä–∞—Ü–∏–∏ –∏ Repository pattern. –≠—Ç–æ—Ç —Ä–∞–∑–¥–µ–ª —É–≥–ª—É–±–ª—è–µ—Ç—Å—è –≤ **production-ready –ø–∞—Ç—Ç–µ—Ä–Ω—ã** ‚Äî —Ç–æ, —á—Ç–æ –æ—Ç–ª–∏—á–∞–µ—Ç –ø—Ä–æ—Ç–æ—Ç–∏–ø –æ—Ç —Å–∏—Å—Ç–µ–º—ã, –æ–±—Å–ª—É–∂–∏–≤–∞—é—â–µ–π –º–∏–ª–ª–∏–æ–Ω—ã –∑–∞–ø—Ä–æ—Å–æ–≤.

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: –ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª 3.3 –±—ã–ª –∞–Ω–∞–ª–æ–≥–æ–º "Getting Started with EF Core", —Ç–æ —ç—Ç–æ—Ç —Ä–∞–∑–¥–µ–ª ‚Äî "EF Core in Production". Connection resilience, query optimization, zero-downtime deployments ‚Äî –≤—Å—ë —ç—Ç–æ –∑–¥–µ—Å—å.

### –ß—Ç–æ –æ—Ç–ª–∏—á–∞–µ—Ç production –æ—Ç development

| –ê—Å–ø–µ–∫—Ç | Development | Production |
|--------|-------------|------------|
| **Connection Pool** | 5-10 —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π | 50-200 —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π, –≤–æ–∑–º–æ–∂–Ω–æ PgBouncer |
| **–ú–∏–≥—Ä–∞—Ü–∏–∏** | `DROP TABLE`, `ALTER` –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π | Zero-downtime, backward-compatible |
| **–û—à–∏–±–∫–∏** | –ü–∞–Ω–∏–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ | Graceful degradation, retry, fallback |
| **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** | `log.Println` | Structured logging, metrics, tracing |
| **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å** | `sslmode=disable` | TLS, certificate verification, RLS |
| **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å** | "–†–∞–±–æ—Ç–∞–µ—Ç –∏ –ª–∞–¥–Ω–æ" | EXPLAIN ANALYZE, –∏–Ω–¥–µ–∫—Å—ã, partitioning |

### –ß—Ç–æ –≤—ã —É–∑–Ω–∞–µ—Ç–µ

- –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è pgx –¥–ª—è production
- External connection pooling —Å PgBouncer
- –°–ª–æ–∂–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∏ dynamic queries –≤ sqlc
- Zero-downtime –º–∏–≥—Ä–∞—Ü–∏–∏ –±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
- High Availability: replicas, failover, retry
- Security: TLS, Row-Level Security
- Observability: –º–µ—Ç—Ä–∏–∫–∏, —Ç—Ä–µ–π—Å–∏–Ω–≥, –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

---

## Advanced pgx Configuration

### –î–µ—Ç–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è pgxpool

–í production `pgxpool.New(ctx, connString)` –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ. –ù—É–∂–Ω–∞ –¥–µ—Ç–∞–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞.

```go
package postgres

import (
    "context"
    "fmt"
    "time"

    "github.com/jackc/pgx/v5"
    "github.com/jackc/pgx/v5/pgxpool"
)

type Config struct {
    // Connection
    Host     string
    Port     int
    User     string
    Password string
    Database string
    SSLMode  string

    // Pool
    MaxConns          int32
    MinConns          int32
    MaxConnLifetime   time.Duration
    MaxConnIdleTime   time.Duration
    HealthCheckPeriod time.Duration

    // Timeouts
    ConnectTimeout   time.Duration
    QueryTimeout     time.Duration
    StatementTimeout time.Duration
}

func DefaultConfig() Config {
    return Config{
        // Connection
        Host:    "localhost",
        Port:    5432,
        SSLMode: "prefer",

        // Pool ‚Äî production values
        MaxConns:          50,
        MinConns:          10,
        MaxConnLifetime:   time.Hour,
        MaxConnIdleTime:   30 * time.Minute,
        HealthCheckPeriod: time.Minute,

        // Timeouts
        ConnectTimeout:   10 * time.Second,
        QueryTimeout:     30 * time.Second,
        StatementTimeout: 30 * time.Second,
    }
}

func NewPool(ctx context.Context, cfg Config) (*pgxpool.Pool, error) {
    connString := fmt.Sprintf(
        "postgres://%s:%s@%s:%d/%s?sslmode=%s",
        cfg.User, cfg.Password, cfg.Host, cfg.Port, cfg.Database, cfg.SSLMode,
    )

    poolConfig, err := pgxpool.ParseConfig(connString)
    if err != nil {
        return nil, fmt.Errorf("parse config: %w", err)
    }

    // Pool settings
    poolConfig.MaxConns = cfg.MaxConns
    poolConfig.MinConns = cfg.MinConns
    poolConfig.MaxConnLifetime = cfg.MaxConnLifetime
    poolConfig.MaxConnIdleTime = cfg.MaxConnIdleTime
    poolConfig.HealthCheckPeriod = cfg.HealthCheckPeriod

    // Connection settings
    poolConfig.ConnConfig.ConnectTimeout = cfg.ConnectTimeout

    // Runtime parameters ‚Äî –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    poolConfig.ConnConfig.RuntimeParams = map[string]string{
        "application_name":  "myapp",
        "statement_timeout": fmt.Sprintf("%dms", cfg.StatementTimeout.Milliseconds()),
        "lock_timeout":      "10s",
        "idle_in_transaction_session_timeout": "60s",
    }

    pool, err := pgxpool.NewWithConfig(ctx, poolConfig)
    if err != nil {
        return nil, fmt.Errorf("create pool: %w", err)
    }

    // Verify connection
    if err := pool.Ping(ctx); err != nil {
        pool.Close()
        return nil, fmt.Errorf("ping: %w", err)
    }

    return pool, nil
}
```

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å ADO.NET

| pgx (Go) | ADO.NET/SqlClient (C#) |
|----------|------------------------|
| `MaxConns` | `Max Pool Size` |
| `MinConns` | `Min Pool Size` |
| `MaxConnLifetime` | `Connection Lifetime` |
| `MaxConnIdleTime` | ‚Äî (–Ω–µ—Ç –ø—Ä—è–º–æ–≥–æ –∞–Ω–∞–ª–æ–≥–∞) |
| `HealthCheckPeriod` | ‚Äî (–≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –≤–∞–ª–∏–¥–∞—Ü–∏—è) |
| `RuntimeParams` | `Initial Catalog`, connection string options |
| `ConnectTimeout` | `Connect Timeout` |

> üí° **–ö–ª—é—á–µ–≤–æ–µ –æ—Ç–ª–∏—á–∏–µ**: –í ADO.NET –º–Ω–æ–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–¥–∞—é—Ç—Å—è –≤ connection string. –í pgx ‚Äî –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ —á–µ—Ä–µ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, —á—Ç–æ –¥–∞—ë—Ç –±–æ–ª—å—à–µ –∫–æ–Ω—Ç—Ä–æ–ª—è.

### Runtime Parameters

Runtime Parameters ‚Äî —ç—Ç–æ PostgreSQL session settings, –ø—Ä–∏–º–µ–Ω—è–µ–º—ã–µ –∫ –∫–∞–∂–¥–æ–º—É —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—é:

```go
poolConfig.ConnConfig.RuntimeParams = map[string]string{
    // –ò–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ‚Äî –≤–∏–¥–Ω–æ –≤ pg_stat_activity
    "application_name": "order-service",

    // Timeout –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ (–æ—Ç–º–µ–Ω—è–µ—Ç –¥–æ–ª–≥–∏–µ –∑–∞–ø—Ä–æ—Å—ã)
    "statement_timeout": "30s",

    // Timeout –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
    "lock_timeout": "10s",

    // Timeout –¥–ª—è idle —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
    "idle_in_transaction_session_timeout": "60s",

    // Timezone
    "timezone": "UTC",

    // Search path
    "search_path": "public,extensions",

    // Work memory –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–æ–∫ –∏ —Ö—ç—à-—Ç–∞–±–ª–∏—Ü
    "work_mem": "64MB",
}
```

> ‚ö†Ô∏è **–í–∞–∂–Ω–æ**: `statement_timeout` –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç "—É–±–∏–π—Å—Ç–≤–µ–Ω–Ω—ã—Ö" –∑–∞–ø—Ä–æ—Å–æ–≤. –ë–µ–∑ –Ω–µ–≥–æ –æ–¥–∏–Ω –ø–ª–æ—Ö–æ–π –∑–∞–ø—Ä–æ—Å –º–æ–∂–µ—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–∞–≤—Å–µ–≥–¥–∞.

### Custom Types —Å pgtype

pgx –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–∞–∫–µ—Ç `pgtype` –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å PostgreSQL —Ç–∏–ø–∞–º–∏. –≠—Ç–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ, —á–µ–º `database/sql`, –∫–æ—Ç–æ—Ä—ã–π –≤—Å—ë –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —á–µ—Ä–µ–∑ —Å—Ç—Ä–æ–∫–∏.

```go
import (
    "github.com/jackc/pgx/v5/pgtype"
)

// –ú–æ–¥–µ–ª—å —Å PostgreSQL-specific —Ç–∏–ø–∞–º–∏
type Product struct {
    ID          int64
    Name        string
    Price       pgtype.Numeric     // NUMERIC ‚Äî —Ç–æ—á–Ω—ã–µ –¥–µ–Ω—å–≥–∏
    Tags        []string           // TEXT[] ‚Äî –º–∞—Å—Å–∏–≤
    Metadata    pgtype.JSONBCodec  // JSONB
    ValidFrom   pgtype.Timestamptz // TIMESTAMP WITH TIME ZONE
    ValidTo     pgtype.Timestamptz
    Coordinates pgtype.Point       // POINT ‚Äî –≥–µ–æ–¥–∞–Ω–Ω—ã–µ
}

// –†–∞–±–æ—Ç–∞ —Å Numeric
func CreateProduct(ctx context.Context, pool *pgxpool.Pool) error {
    price := pgtype.Numeric{}
    // –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏—è 99.99
    if err := price.Scan("99.99"); err != nil {
        return err
    }

    _, err := pool.Exec(ctx,
        `INSERT INTO products (name, price) VALUES ($1, $2)`,
        "Widget", price,
    )
    return err
}

// –†–∞–±–æ—Ç–∞ —Å –º–∞—Å—Å–∏–≤–∞–º–∏
func GetProductsByTags(ctx context.Context, pool *pgxpool.Pool, tags []string) ([]Product, error) {
    rows, err := pool.Query(ctx,
        `SELECT id, name, tags FROM products WHERE tags && $1`,
        tags, // pgx –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç []string –≤ TEXT[]
    )
    if err != nil {
        return nil, err
    }
    defer rows.Close()

    var products []Product
    for rows.Next() {
        var p Product
        if err := rows.Scan(&p.ID, &p.Name, &p.Tags); err != nil {
            return nil, err
        }
        products = append(products, p)
    }
    return products, rows.Err()
}
```

### Nullable —Ç–∏–ø—ã –≤ pgx vs C#

| PostgreSQL | pgx (Go) | C# |
|------------|----------|-----|
| `INTEGER NULL` | `pgtype.Int4` –∏–ª–∏ `*int32` | `int?` |
| `TEXT NULL` | `pgtype.Text` –∏–ª–∏ `*string` | `string?` |
| `TIMESTAMP NULL` | `pgtype.Timestamptz` | `DateTime?` |
| `JSONB` | `pgtype.JSONBCodec` –∏–ª–∏ `map[string]any` | `JsonDocument` |
| `UUID` | `pgtype.UUID` –∏–ª–∏ `[16]byte` | `Guid` |
| `NUMERIC` | `pgtype.Numeric` | `decimal` |

```go
// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ pgtype –¥–ª—è nullable
type User struct {
    ID        int64
    Email     string
    Phone     pgtype.Text // NULL-able
    DeletedAt pgtype.Timestamptz
}

func (u *User) GetPhone() string {
    if u.Phone.Valid {
        return u.Phone.String
    }
    return ""
}

func (u *User) IsDeleted() bool {
    return u.DeletedAt.Valid
}
```

### Query Tracing

pgx –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç tracing —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å `pgx.QueryTracer`. –≠—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å OpenTelemetry.

```go
import (
    "context"
    "log/slog"
    "time"

    "github.com/jackc/pgx/v5"
)

// –ü—Ä–æ—Å—Ç–æ–π tracer –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
type LoggingTracer struct {
    logger *slog.Logger
}

func (t *LoggingTracer) TraceQueryStart(
    ctx context.Context,
    conn *pgx.Conn,
    data pgx.TraceQueryStartData,
) context.Context {
    return context.WithValue(ctx, "query_start", time.Now())
}

func (t *LoggingTracer) TraceQueryEnd(
    ctx context.Context,
    conn *pgx.Conn,
    data pgx.TraceQueryEndData,
) {
    start := ctx.Value("query_start").(time.Time)
    duration := time.Since(start)

    // –õ–æ–≥–∏—Ä—É–µ–º –º–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    if duration > 100*time.Millisecond {
        t.logger.Warn("slow query",
            slog.String("sql", data.SQL),
            slog.Duration("duration", duration),
            slog.Int64("rows", data.CommandTag.RowsAffected()),
        )
    } else {
        t.logger.Debug("query executed",
            slog.String("sql", data.SQL),
            slog.Duration("duration", duration),
        )
    }

    // –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏
    if data.Err != nil {
        t.logger.Error("query failed",
            slog.String("sql", data.SQL),
            slog.String("error", data.Err.Error()),
        )
    }
}

// –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ tracer
func NewPoolWithTracing(ctx context.Context, cfg Config, logger *slog.Logger) (*pgxpool.Pool, error) {
    poolConfig, err := pgxpool.ParseConfig(cfg.ConnectionString())
    if err != nil {
        return nil, err
    }

    poolConfig.ConnConfig.Tracer = &LoggingTracer{logger: logger}

    return pgxpool.NewWithConfig(ctx, poolConfig)
}
```

### OpenTelemetry Tracer

–î–ª—è production —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OpenTelemetry:

```go
import (
    "context"

    "github.com/jackc/pgx/v5"
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/codes"
    "go.opentelemetry.io/otel/trace"
)

type OTelTracer struct {
    tracer trace.Tracer
}

func NewOTelTracer() *OTelTracer {
    return &OTelTracer{
        tracer: otel.Tracer("pgx"),
    }
}

func (t *OTelTracer) TraceQueryStart(
    ctx context.Context,
    conn *pgx.Conn,
    data pgx.TraceQueryStartData,
) context.Context {
    ctx, span := t.tracer.Start(ctx, "postgresql.query",
        trace.WithAttributes(
            attribute.String("db.system", "postgresql"),
            attribute.String("db.statement", data.SQL),
            attribute.String("db.name", conn.Config().Database),
        ),
    )
    return ctx
}

func (t *OTelTracer) TraceQueryEnd(
    ctx context.Context,
    conn *pgx.Conn,
    data pgx.TraceQueryEndData,
) {
    span := trace.SpanFromContext(ctx)
    defer span.End()

    span.SetAttributes(
        attribute.Int64("db.rows_affected", data.CommandTag.RowsAffected()),
    )

    if data.Err != nil {
        span.RecordError(data.Err)
        span.SetStatus(codes.Error, data.Err.Error())
    }
}
```

### Connection Hooks

pgx –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç hooks –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–¥–∞ –ø—Ä–∏ —Å–æ–±—ã—Ç–∏—è—Ö –∂–∏–∑–Ω–µ–Ω–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è.

```go
func NewPoolWithHooks(ctx context.Context, cfg Config) (*pgxpool.Pool, error) {
    poolConfig, err := pgxpool.ParseConfig(cfg.ConnectionString())
    if err != nil {
        return nil, err
    }

    // AfterConnect ‚Äî –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    poolConfig.AfterConnect = func(ctx context.Context, conn *pgx.Conn) error {
        // –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
        _, err := conn.Exec(ctx, "CREATE EXTENSION IF NOT EXISTS pg_trgm")
        if err != nil {
            return fmt.Errorf("create extension: %w", err)
        }

        // –£—Å—Ç–∞–Ω–æ–≤–∫–∞ search_path
        _, err = conn.Exec(ctx, "SET search_path TO public, extensions")
        if err != nil {
            return fmt.Errorf("set search_path: %w", err)
        }

        // –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è custom types
        // (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ custom PostgreSQL types)

        slog.Info("connection established",
            slog.String("db", conn.Config().Database),
        )
        return nil
    }

    // BeforeAcquire ‚Äî –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–µ—Ä–µ–¥ –≤—ã–¥–∞—á–µ–π —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∏–∑ –ø—É–ª–∞
    poolConfig.BeforeAcquire = func(ctx context.Context, conn *pgx.Conn) bool {
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∂–∏–≤–æ–µ
        // –í–æ–∑–≤—Ä–∞—â–∞–µ–º false, –µ—Å–ª–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω—É–∂–Ω–æ –∑–∞–∫—Ä—ã—Ç—å
        if conn.IsClosed() {
            return false
        }

        // –ú–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ –≤ broken state
        // –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è

        return true
    }

    // AfterRelease ‚Äî –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ—Å–ª–µ –≤–æ–∑–≤—Ä–∞—Ç–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –≤ –ø—É–ª
    poolConfig.AfterRelease = func(conn *pgx.Conn) bool {
        // –û—á–∏—Å—Ç–∫–∞ session state
        // –í–æ–∑–≤—Ä–∞—â–∞–µ–º false, –µ—Å–ª–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω—É–∂–Ω–æ –∑–∞–∫—Ä—ã—Ç—å

        // –ù–∞–ø—Ä–∏–º–µ—Ä, —Å–±—Ä–∞—Å—ã–≤–∞–µ–º prepared statements
        // (pgx –∫—ç—à–∏—Ä—É–µ—Ç –∏—Ö –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)

        return true
    }

    return pgxpool.NewWithConfig(ctx, poolConfig)
}
```

### Prepared Statement Cache

pgx –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫—ç—à–∏—Ä—É–µ—Ç prepared statements. –≠—Ç–æ –¥–∞—ë—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–∏—Ä–æ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –∑–∞–ø—Ä–æ—Å–æ–≤.

```go
// pgx –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–µ–ª–∞–µ—Ç —ç—Ç–æ:
// 1. –ü–µ—Ä–≤—ã–π –≤—ã–∑–æ–≤ Query("SELECT * FROM users WHERE id = $1", 1)
//    - –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç Parse + Bind + Execute
// 2. –í—Ç–æ—Ä–æ–π –≤—ã–∑–æ–≤ Query("SELECT * FROM users WHERE id = $1", 2)
//    - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π prepared statement
//    - –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ Bind + Execute

// –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫—ç—à–∞
poolConfig.ConnConfig.DefaultQueryExecMode = pgx.QueryExecModeCacheStatement

// –†–µ–∂–∏–º—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤:
// - QueryExecModeSimpleProtocol ‚Äî –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–æ—Ç–æ–∫–æ–ª, –±–µ–∑ prepared statements
// - QueryExecModeExec ‚Äî Extended Query Protocol, –±–µ–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
// - QueryExecModeCacheStatement ‚Äî –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ (default)
// - QueryExecModeCacheDescribe ‚Äî –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Å describe
// - QueryExecModeDescribeExec ‚Äî describe –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º
```

> ‚ö†Ô∏è **PgBouncer –∏ prepared statements**: –í transaction mode PgBouncer –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç prepared statements. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `QueryExecModeSimpleProtocol` –∏–ª–∏ session mode.

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ Hooks —Å C#

| pgx (Go) | ADO.NET (C#) |
|----------|--------------|
| `AfterConnect` | `SqlConnection.StateChange` event + manual setup |
| `BeforeAcquire` | ‚Äî (–Ω–µ—Ç –ø—Ä—è–º–æ–≥–æ –∞–Ω–∞–ª–æ–≥–∞) |
| `AfterRelease` | `SqlConnection.StateChange` + `ClearPool` |
| `QueryTracer` | `SqlClientEventSource` / DiagnosticSource |

```csharp
// C# –∞–Ω–∞–ª–æ–≥ AfterConnect
connection.StateChange += (sender, e) => {
    if (e.CurrentState == ConnectionState.Open) {
        using var cmd = connection.CreateCommand();
        cmd.CommandText = "SET search_path TO public";
        cmd.ExecuteNonQuery();
    }
};
```

```go
// Go ‚Äî —á–∏—â–µ –∏ –¥–µ–∫–ª–∞—Ä–∞—Ç–∏–≤–Ω–µ–µ
poolConfig.AfterConnect = func(ctx context.Context, conn *pgx.Conn) error {
    _, err := conn.Exec(ctx, "SET search_path TO public")
    return err
}
```

---

## Production Connection Pooling

### pgxpool vs PgBouncer

| –ê—Å–ø–µ–∫—Ç | pgxpool (–≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π) | PgBouncer (–≤–Ω–µ—à–Ω–∏–π) |
|--------|---------------------|---------------------|
| **–ü—Ä–æ—Å—Ç–æ—Ç–∞** | –í–∫–ª—é—á—ë–Ω –≤ pgx | –û—Ç–¥–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å |
| **–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ** | Per-application | Shared across apps |
| **–ú–∞–∫—Å. —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π** | –û–≥—Ä–∞–Ω–∏—á–µ–Ω –ø–∞–º—è—Ç—å—é app | –î–µ—Å—è—Ç–∫–∏ —Ç—ã—Å—è—á |
| **Prepared statements** | –ü–æ–ª–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ | –¢–æ–ª—å–∫–æ –≤ session mode |
| **Overhead** | –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π | –ù–µ–±–æ–ª—å—à–æ–π |
| **Failover** | –ù–µ—Ç | –ú–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å |

### –ö–æ–≥–¥–∞ –Ω—É–∂–µ–Ω PgBouncer

```
‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ PgBouncer –µ—Å–ª–∏:
- –ú–Ω–æ–≥–æ —Å–µ—Ä–≤–∏—Å–æ–≤ (>20) –ø–æ–¥–∫–ª—é—á–∞—é—Ç—Å—è –∫ –æ–¥–Ω–æ–π –ë–î
- Serverless/Lambda —Ñ—É–Ω–∫—Ü–∏–∏ (—Ö–æ–ª–æ–¥–Ω—ã–π —Å—Ç–∞—Ä—Ç)
- PostgreSQL –¥–æ—Å—Ç–∏–≥ max_connections
- –ù—É–∂–µ–Ω connection multiplexing

‚ùå –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ pgxpool –µ—Å–ª–∏:
- –û–¥–∏–Ω-–¥–≤–∞ —Å–µ—Ä–≤–∏—Å–∞
- –°—Ç–∞–±–∏–ª—å–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç–µ prepared statements
- –ù–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç–µ max_connections
```

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ PgBouncer

```ini
; /etc/pgbouncer/pgbouncer.ini

[databases]
mydb = host=postgres.internal port=5432 dbname=mydb

[pgbouncer]
listen_addr = 0.0.0.0
listen_port = 6432

; –†–µ–∂–∏–º –ø—É–ª–∞
; session ‚Äî —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–µ—Ä–∂–∏—Ç—Å—è –Ω–∞ –≤—Ä–µ–º—è —Å–µ—Å—Å–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞
; transaction ‚Äî —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—ã–¥–∞—ë—Ç—Å—è –Ω–∞ –≤—Ä–µ–º—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
; statement ‚Äî —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—ã–¥–∞—ë—Ç—Å—è –Ω–∞ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞ (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è!)
pool_mode = transaction

; –†–∞–∑–º–µ—Ä –ø—É–ª–∞
default_pool_size = 50
max_client_conn = 1000
min_pool_size = 10

; Timeouts
server_connect_timeout = 5
server_idle_timeout = 600
query_timeout = 30

; –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
auth_type = md5
auth_file = /etc/pgbouncer/userlist.txt

; –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
log_connections = 1
log_disconnections = 1
log_pooler_errors = 1
```

### Go —Å PgBouncer

```go
func NewPoolWithPgBouncer(ctx context.Context) (*pgxpool.Pool, error) {
    poolConfig, err := pgxpool.ParseConfig(
        "postgres://user:pass@pgbouncer.internal:6432/mydb",
    )
    if err != nil {
        return nil, err
    }

    // ‚ö†Ô∏è –í–ê–ñ–ù–û: –û—Ç–∫–ª—é—á–∞–µ–º prepared statement cache –¥–ª—è transaction mode
    poolConfig.ConnConfig.DefaultQueryExecMode = pgx.QueryExecModeSimpleProtocol

    // –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º ExecSimpleProtocol –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    // poolConfig.ConnConfig.DefaultQueryExecMode = pgx.QueryExecModeExec

    // –ú–µ–Ω—å—à–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π ‚Äî PgBouncer —É–ø—Ä–∞–≤–ª—è–µ—Ç –ø—É–ª–æ–º
    poolConfig.MaxConns = 10
    poolConfig.MinConns = 2

    return pgxpool.NewWithConfig(ctx, poolConfig)
}
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—É–ª–∞

```go
import (
    "context"
    "log/slog"
    "time"

    "github.com/jackc/pgx/v5/pgxpool"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    poolConnsTotal = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "db_pool_connections_total",
            Help: "Total number of connections in the pool",
        },
        []string{"state"}, // acquired, idle, max
    )

    poolWaitDuration = promauto.NewHistogram(
        prometheus.HistogramOpts{
            Name:    "db_pool_wait_duration_seconds",
            Help:    "Time spent waiting for a connection",
            Buckets: prometheus.ExponentialBuckets(0.001, 2, 10),
        },
    )
)

// PoolMonitor –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ —Å–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –ø—É–ª–∞
type PoolMonitor struct {
    pool   *pgxpool.Pool
    logger *slog.Logger
}

func NewPoolMonitor(pool *pgxpool.Pool, logger *slog.Logger) *PoolMonitor {
    return &PoolMonitor{pool: pool, logger: logger}
}

func (m *PoolMonitor) Start(ctx context.Context) {
    ticker := time.NewTicker(10 * time.Second)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            m.collect()
        }
    }
}

func (m *PoolMonitor) collect() {
    stat := m.pool.Stat()

    // Prometheus –º–µ—Ç—Ä–∏–∫–∏
    poolConnsTotal.WithLabelValues("acquired").Set(float64(stat.AcquiredConns()))
    poolConnsTotal.WithLabelValues("idle").Set(float64(stat.IdleConns()))
    poolConnsTotal.WithLabelValues("max").Set(float64(stat.MaxConns()))
    poolConnsTotal.WithLabelValues("total").Set(float64(stat.TotalConns()))

    // –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    m.logger.Debug("pool stats",
        slog.Int32("acquired", stat.AcquiredConns()),
        slog.Int32("idle", stat.IdleConns()),
        slog.Int32("total", stat.TotalConns()),
        slog.Int32("max", stat.MaxConns()),
        slog.Int64("acquire_count", stat.AcquireCount()),
        slog.Duration("acquire_duration", stat.AcquireDuration()),
        slog.Int64("canceled_acquire", stat.CanceledAcquireCount()),
    )

    // –ê–ª–µ—Ä—Ç –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–π —É—Ç–∏–ª–∏–∑–∞—Ü–∏–∏
    utilization := float64(stat.AcquiredConns()) / float64(stat.MaxConns())
    if utilization > 0.8 {
        m.logger.Warn("high pool utilization",
            slog.Float64("utilization", utilization),
        )
    }
}

// Middleware –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è
func (m *PoolMonitor) AcquireWithMetrics(ctx context.Context) (*pgxpool.Conn, error) {
    start := time.Now()
    conn, err := m.pool.Acquire(ctx)
    poolWaitDuration.Observe(time.Since(start).Seconds())
    return conn, err
}
```

### Pool Statistics

pgxpool –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –±–æ–≥–∞—Ç—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É:

```go
stat := pool.Stat()

// –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è
stat.TotalConns()      // –í—Å–µ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
stat.AcquiredConns()   // –ó–∞–Ω—è—Ç—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
stat.IdleConns()       // –°–≤–æ–±–æ–¥–Ω—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
stat.MaxConns()        // –ú–∞–∫—Å–∏–º—É–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π

// –û–ø–µ—Ä–∞—Ü–∏–∏
stat.AcquireCount()        // –°–∫–æ–ª—å–∫–æ —Ä–∞–∑ –∑–∞–ø—Ä–∞—à–∏–≤–∞–ª–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
stat.AcquireDuration()     // –°—É–º–º–∞—Ä–Ω–æ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è
stat.CanceledAcquireCount() // –û—Ç–º–µ–Ω—ë–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
stat.EmptyAcquireCount()   // –ó–∞–ø—Ä–æ—Å—ã, –∫–æ–≥–¥–∞ –ø—É–ª –±—ã–ª –ø—É—Å—Ç

// –°–æ–∑–¥–∞–Ω–∏–µ/–∑–∞–∫—Ä—ã—Ç–∏–µ
stat.NewConnsCount()        // –°–∫–æ–ª—å–∫–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π —Å–æ–∑–¥–∞–Ω–æ
stat.MaxLifetimeDestroyCount() // –ó–∞–∫—Ä—ã—Ç–æ –ø–æ MaxConnLifetime
stat.MaxIdleDestroyCount()    // –ó–∞–∫—Ä—ã—Ç–æ –ø–æ MaxConnIdleTime
```

### Graceful Shutdown

–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π.

```go
package main

import (
    "context"
    "log/slog"
    "os"
    "os/signal"
    "syscall"
    "time"

    "github.com/jackc/pgx/v5/pgxpool"
)

func main() {
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()

    pool, err := NewPool(ctx, DefaultConfig())
    if err != nil {
        slog.Error("failed to create pool", slog.String("error", err.Error()))
        os.Exit(1)
    }

    // –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞...
    server := startServer(pool)

    // –û–∂–∏–¥–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    quit := make(chan os.Signal, 1)
    signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
    <-quit

    slog.Info("shutting down...")

    // 1. –ü—Ä–µ–∫—Ä–∞—â–∞–µ–º –ø—Ä–∏–Ω–∏–º–∞—Ç—å –Ω–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    shutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer shutdownCancel()

    if err := server.Shutdown(shutdownCtx); err != nil {
        slog.Error("server shutdown failed", slog.String("error", err.Error()))
    }

    // 2. –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
    // pool.Close() –∂–¥—ë—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö acquired —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
    pool.Close()

    slog.Info("shutdown complete")
}

// –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: drain connections —Å timeout
func drainPool(pool *pgxpool.Pool, timeout time.Duration) error {
    ctx, cancel := context.WithTimeout(context.Background(), timeout)
    defer cancel()

    // –ñ–¥—ë–º, –ø–æ–∫–∞ –≤—Å–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –æ—Å–≤–æ–±–æ–¥—è—Ç—Å—è
    ticker := time.NewTicker(100 * time.Millisecond)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            pool.Close()
            return ctx.Err()
        case <-ticker.C:
            if pool.Stat().AcquiredConns() == 0 {
                pool.Close()
                return nil
            }
        }
    }
}
```

### Health Checks

```go
import (
    "context"
    "time"

    "github.com/jackc/pgx/v5/pgxpool"
)

type HealthChecker struct {
    pool *pgxpool.Pool
}

func NewHealthChecker(pool *pgxpool.Pool) *HealthChecker {
    return &HealthChecker{pool: pool}
}

// Simple ping check
func (h *HealthChecker) Ping(ctx context.Context) error {
    return h.pool.Ping(ctx)
}

// Detailed health check
func (h *HealthChecker) Check(ctx context.Context) HealthStatus {
    status := HealthStatus{
        Healthy: true,
        Details: make(map[string]any),
    }

    // Pool stats
    stat := h.pool.Stat()
    status.Details["pool"] = map[string]any{
        "total":    stat.TotalConns(),
        "acquired": stat.AcquiredConns(),
        "idle":     stat.IdleConns(),
        "max":      stat.MaxConns(),
    }

    // Check pool utilization
    utilization := float64(stat.AcquiredConns()) / float64(stat.MaxConns())
    if utilization > 0.9 {
        status.Healthy = false
        status.Details["warning"] = "pool near capacity"
    }

    // Try to execute a query
    start := time.Now()
    ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
    defer cancel()

    var result int
    err := h.pool.QueryRow(ctx, "SELECT 1").Scan(&result)
    queryDuration := time.Since(start)

    status.Details["query_latency_ms"] = queryDuration.Milliseconds()

    if err != nil {
        status.Healthy = false
        status.Details["error"] = err.Error()
    }

    // Check for slow queries
    if queryDuration > time.Second {
        status.Details["warning"] = "slow query response"
    }

    return status
}

type HealthStatus struct {
    Healthy bool
    Details map[string]any
}

// HTTP handler –¥–ª—è health check
func (h *HealthChecker) HTTPHandler(w http.ResponseWriter, r *http.Request) {
    status := h.Check(r.Context())

    w.Header().Set("Content-Type", "application/json")
    if !status.Healthy {
        w.WriteHeader(http.StatusServiceUnavailable)
    }

    json.NewEncoder(w).Encode(status)
}
```

### Connection Warming

–ü—Ä–∏ —Å—Ç–∞—Ä—Ç–µ —Å–µ—Ä–≤–∏—Å–∞ –ø–æ–ª–µ–∑–Ω–æ "–ø—Ä–æ–≥—Ä–µ—Ç—å" –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π:

```go
func WarmPool(ctx context.Context, pool *pgxpool.Pool, minConns int) error {
    // –ó–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    conns := make([]*pgxpool.Conn, 0, minConns)

    for i := 0; i < minConns; i++ {
        conn, err := pool.Acquire(ctx)
        if err != nil {
            // –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —É–∂–µ –∑–∞—Ö–≤–∞—á–µ–Ω–Ω—ã–µ
            for _, c := range conns {
                c.Release()
            }
            return fmt.Errorf("warm pool: %w", err)
        }
        conns = append(conns, conn)
    }

    // –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –æ–±—Ä–∞—Ç–Ω–æ –≤ –ø—É–ª
    for _, conn := range conns {
        conn.Release()
    }

    slog.Info("pool warmed", slog.Int("connections", len(conns)))
    return nil
}

// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
func main() {
    pool, _ := NewPool(ctx, cfg)

    // –ü—Ä–æ–≥—Ä–µ–≤–∞–µ–º –ø—É–ª –ø–µ—Ä–µ–¥ –ø—Ä–∏—ë–º–æ–º —Ç—Ä–∞—Ñ–∏–∫–∞
    if err := WarmPool(ctx, pool, 10); err != nil {
        slog.Warn("pool warming failed", slog.String("error", err.Error()))
    }

    // –¢–µ–ø–µ—Ä—å –≥–æ—Ç–æ–≤—ã –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ç—Ä–∞—Ñ–∏–∫
    startServer(pool)
}

---

## –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π sqlc

–í [—Ä–∞–∑–¥–µ–ª–µ 3.3](../part3-web-api/03_database.md) –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–ª–∏ –æ—Å–Ω–æ–≤—ã sqlc. –ó–¥–µ—Å—å ‚Äî –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è production.

### –°–ª–æ–∂–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã

#### CTE (Common Table Expressions)

```sql
-- queries/analytics.sql

-- name: GetUserOrderStats :many
-- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–∫–∞–∑–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å CTE
WITH order_stats AS (
    SELECT
        user_id,
        COUNT(*) as total_orders,
        SUM(total_amount) as total_spent,
        AVG(total_amount) as avg_order_value,
        MAX(created_at) as last_order_at
    FROM orders
    WHERE status = 'completed'
    GROUP BY user_id
),
user_rank AS (
    SELECT
        user_id,
        total_spent,
        RANK() OVER (ORDER BY total_spent DESC) as spending_rank
    FROM order_stats
)
SELECT
    u.id,
    u.email,
    u.name,
    COALESCE(os.total_orders, 0)::int as total_orders,
    COALESCE(os.total_spent, 0)::numeric as total_spent,
    COALESCE(os.avg_order_value, 0)::numeric as avg_order_value,
    os.last_order_at,
    COALESCE(ur.spending_rank, 0)::int as spending_rank
FROM users u
LEFT JOIN order_stats os ON u.id = os.user_id
LEFT JOIN user_rank ur ON u.id = ur.user_id
WHERE u.deleted_at IS NULL
ORDER BY os.total_spent DESC NULLS LAST
LIMIT sqlc.arg(limit_count)::int;
```

#### Window Functions

```sql
-- queries/reports.sql

-- name: GetSalesReport :many
-- –û—Ç—á—ë—Ç —Å –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–º –∏—Ç–æ–≥–æ–º –∏ —Å–∫–æ–ª—å–∑—è—â–∏–º —Å—Ä–µ–¥–Ω–∏–º
SELECT
    date_trunc('day', created_at)::date as order_date,
    COUNT(*) as order_count,
    SUM(total_amount) as daily_revenue,
    -- –ù–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–π –∏—Ç–æ–≥
    SUM(SUM(total_amount)) OVER (
        ORDER BY date_trunc('day', created_at)
    ) as cumulative_revenue,
    -- –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –∑–∞ 7 –¥–Ω–µ–π
    AVG(SUM(total_amount)) OVER (
        ORDER BY date_trunc('day', created_at)
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) as moving_avg_7d
FROM orders
WHERE created_at >= sqlc.arg(start_date)::timestamp
  AND created_at < sqlc.arg(end_date)::timestamp
  AND status = 'completed'
GROUP BY date_trunc('day', created_at)
ORDER BY order_date;

-- name: GetProductRankByCategory :many
-- –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –≤–Ω—É—Ç—Ä–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
SELECT
    p.id,
    p.name,
    p.category_id,
    c.name as category_name,
    p.price,
    p.sales_count,
    ROW_NUMBER() OVER (
        PARTITION BY p.category_id
        ORDER BY p.sales_count DESC
    ) as rank_in_category,
    PERCENT_RANK() OVER (
        PARTITION BY p.category_id
        ORDER BY p.sales_count DESC
    ) as percentile
FROM products p
JOIN categories c ON p.category_id = c.id
WHERE p.active = true;
```

#### Recursive CTE

```sql
-- queries/categories.sql

-- name: GetCategoryTree :many
-- –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ä–µ–≤–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π (–∏–µ—Ä–∞—Ä—Ö–∏—è)
WITH RECURSIVE category_tree AS (
    -- –ë–∞–∑–æ–≤—ã–π —Å–ª—É—á–∞–π: –∫–æ—Ä–Ω–µ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    SELECT
        id,
        name,
        parent_id,
        0 as depth,
        ARRAY[id] as path,
        name as full_path
    FROM categories
    WHERE parent_id IS NULL

    UNION ALL

    -- –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π —Å–ª—É—á–∞–π: –¥–æ—á–µ—Ä–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    SELECT
        c.id,
        c.name,
        c.parent_id,
        ct.depth + 1,
        ct.path || c.id,
        ct.full_path || ' > ' || c.name
    FROM categories c
    JOIN category_tree ct ON c.parent_id = ct.id
)
SELECT
    id,
    name,
    parent_id,
    depth,
    path,
    full_path
FROM category_tree
ORDER BY path;

-- name: GetCategoryDescendants :many
-- –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –ø–æ—Ç–æ–º–∫–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
WITH RECURSIVE descendants AS (
    SELECT id, name, parent_id
    FROM categories
    WHERE id = sqlc.arg(category_id)

    UNION ALL

    SELECT c.id, c.name, c.parent_id
    FROM categories c
    JOIN descendants d ON c.parent_id = d.id
)
SELECT * FROM descendants
WHERE id != sqlc.arg(category_id);
```

### Dynamic Queries

sqlc –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã —á–µ—Ä–µ–∑ `sqlc.narg()` –∏ `sqlc.slice()`.

#### Optional Filters —Å sqlc.narg()

```sql
-- queries/users.sql

-- name: SearchUsers :many
-- –ü–æ–∏—Å–∫ —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
SELECT id, email, name, role, created_at
FROM users
WHERE deleted_at IS NULL
  AND (sqlc.narg(email)::text IS NULL OR email ILIKE sqlc.narg(email))
  AND (sqlc.narg(name)::text IS NULL OR name ILIKE sqlc.narg(name))
  AND (sqlc.narg(role)::text IS NULL OR role = sqlc.narg(role))
  AND (sqlc.narg(created_after)::timestamp IS NULL OR created_at >= sqlc.narg(created_after))
  AND (sqlc.narg(created_before)::timestamp IS NULL OR created_at < sqlc.narg(created_before))
ORDER BY
    CASE WHEN sqlc.narg(sort_by)::text = 'email' THEN email END,
    CASE WHEN sqlc.narg(sort_by)::text = 'name' THEN name END,
    CASE WHEN sqlc.narg(sort_by)::text = 'created_at' OR sqlc.narg(sort_by)::text IS NULL THEN created_at END DESC
LIMIT sqlc.arg(limit_count)
OFFSET sqlc.arg(offset_count);
```

```go
// –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥
type SearchUsersParams struct {
    Email         pgtype.Text      `json:"email"`
    Name          pgtype.Text      `json:"name"`
    Role          pgtype.Text      `json:"role"`
    CreatedAfter  pgtype.Timestamp `json:"created_after"`
    CreatedBefore pgtype.Timestamp `json:"created_before"`
    SortBy        pgtype.Text      `json:"sort_by"`
    LimitCount    int32            `json:"limit_count"`
    OffsetCount   int32            `json:"offset_count"`
}

// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
func (s *UserService) Search(ctx context.Context, filter UserFilter) ([]User, error) {
    params := db.SearchUsersParams{
        LimitCount:  int32(filter.Limit),
        OffsetCount: int32(filter.Offset),
    }

    // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–¥–∞–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
    if filter.Email != "" {
        params.Email = pgtype.Text{String: "%" + filter.Email + "%", Valid: true}
    }
    if filter.Name != "" {
        params.Name = pgtype.Text{String: "%" + filter.Name + "%", Valid: true}
    }
    if filter.Role != "" {
        params.Role = pgtype.Text{String: filter.Role, Valid: true}
    }
    if !filter.CreatedAfter.IsZero() {
        params.CreatedAfter = pgtype.Timestamp{Time: filter.CreatedAfter, Valid: true}
    }

    return s.queries.SearchUsers(ctx, params)
}
```

#### Arrays —Å sqlc.slice()

```sql
-- queries/products.sql

-- name: GetProductsByIDs :many
-- –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –ø–æ —Å–ø–∏—Å–∫—É ID
SELECT * FROM products
WHERE id = ANY(sqlc.slice(ids)::int[])
ORDER BY array_position(sqlc.slice(ids)::int[], id);

-- name: GetProductsByTags :many
-- –ü—Ä–æ–¥—É–∫—Ç—ã —Å –ª—é–±—ã–º –∏–∑ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö —Ç–µ–≥–æ–≤
SELECT DISTINCT p.*
FROM products p
WHERE p.tags && sqlc.slice(tags)::text[]
  AND p.active = true;

-- name: GetProductsWithAllTags :many
-- –ü—Ä–æ–¥—É–∫—Ç—ã —Å–æ –í–°–ï–ú–ò —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ —Ç–µ–≥–∞–º–∏
SELECT * FROM products
WHERE tags @> sqlc.slice(tags)::text[]
  AND active = true;
```

```go
// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
products, err := queries.GetProductsByIDs(ctx, []int32{1, 2, 3, 4, 5})

products, err = queries.GetProductsByTags(ctx, []string{"electronics", "sale"})
```

### –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –≤ sqlc

sqlc –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –º–µ—Ç–æ–¥ `WithTx` –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏.

```go
// –ü–∞—Ç—Ç–µ—Ä–Ω: —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ —Å sqlc
func (s *OrderService) CreateOrder(ctx context.Context, order CreateOrderRequest) (*Order, error) {
    // –ù–∞—á–∏–Ω–∞–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é
    tx, err := s.pool.Begin(ctx)
    if err != nil {
        return nil, fmt.Errorf("begin tx: %w", err)
    }
    defer tx.Rollback(ctx)

    // –°–æ–∑–¥–∞—ë–º queries —Å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–µ–π
    qtx := s.queries.WithTx(tx)

    // 1. –°–æ–∑–¥–∞—ë–º –∑–∞–∫–∞–∑
    dbOrder, err := qtx.CreateOrder(ctx, db.CreateOrderParams{
        UserID:      order.UserID,
        TotalAmount: order.Total,
        Status:      "pending",
    })
    if err != nil {
        return nil, fmt.Errorf("create order: %w", err)
    }

    // 2. –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–∑–∏—Ü–∏–∏ –∑–∞–∫–∞–∑–∞
    for _, item := range order.Items {
        _, err := qtx.CreateOrderItem(ctx, db.CreateOrderItemParams{
            OrderID:   dbOrder.ID,
            ProductID: item.ProductID,
            Quantity:  item.Quantity,
            Price:     item.Price,
        })
        if err != nil {
            return nil, fmt.Errorf("create order item: %w", err)
        }

        // 3. –£–º–µ–Ω—å—à–∞–µ–º –æ—Å—Ç–∞—Ç–∫–∏
        err = qtx.DecrementStock(ctx, db.DecrementStockParams{
            ProductID: item.ProductID,
            Quantity:  item.Quantity,
        })
        if err != nil {
            return nil, fmt.Errorf("decrement stock: %w", err)
        }
    }

    // –ö–æ–º–º–∏—Ç–∏–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é
    if err := tx.Commit(ctx); err != nil {
        return nil, fmt.Errorf("commit: %w", err)
    }

    return mapOrder(dbOrder), nil
}
```

#### Transaction Manager

–î–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ª–æ–≥–∏–∫–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π:

```go
// internal/database/txmanager.go
package database

import (
    "context"
    "fmt"

    "github.com/jackc/pgx/v5"
    "github.com/jackc/pgx/v5/pgxpool"
    "myapp/internal/db"
)

type TxManager struct {
    pool *pgxpool.Pool
}

func NewTxManager(pool *pgxpool.Pool) *TxManager {
    return &TxManager{pool: pool}
}

// TxFunc ‚Äî —Ñ—É–Ω–∫—Ü–∏—è, –≤—ã–ø–æ–ª–Ω—è–µ–º–∞—è –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
type TxFunc func(ctx context.Context, q *db.Queries) error

// WithTx –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
func (m *TxManager) WithTx(ctx context.Context, fn TxFunc) error {
    tx, err := m.pool.Begin(ctx)
    if err != nil {
        return fmt.Errorf("begin: %w", err)
    }
    defer tx.Rollback(ctx)

    q := db.New(tx)
    if err := fn(ctx, q); err != nil {
        return err
    }

    return tx.Commit(ctx)
}

// WithTxResult ‚Äî —Å –≤–æ–∑–≤—Ä–∞—Ç–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
func WithTxResult[T any](
    m *TxManager,
    ctx context.Context,
    fn func(ctx context.Context, q *db.Queries) (T, error),
) (T, error) {
    var result T

    tx, err := m.pool.Begin(ctx)
    if err != nil {
        return result, fmt.Errorf("begin: %w", err)
    }
    defer tx.Rollback(ctx)

    q := db.New(tx)
    result, err = fn(ctx, q)
    if err != nil {
        return result, err
    }

    if err := tx.Commit(ctx); err != nil {
        return result, fmt.Errorf("commit: %w", err)
    }

    return result, nil
}

// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
func (s *OrderService) CreateOrder(ctx context.Context, req CreateOrderRequest) (*Order, error) {
    return WithTxResult(s.txManager, ctx, func(ctx context.Context, q *db.Queries) (*Order, error) {
        order, err := q.CreateOrder(ctx, db.CreateOrderParams{...})
        if err != nil {
            return nil, err
        }
        // ... –æ—Å—Ç–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞
        return mapOrder(order), nil
    })
}
```

### Batch Operations –≤ sqlc

sqlc –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç batch queries —á–µ—Ä–µ–∑ `pgx.Batch`.

```sql
-- queries/users.sql

-- name: CreateUser :one
INSERT INTO users (email, name, role)
VALUES ($1, $2, $3)
RETURNING *;

-- name: CreateUsersBatch :batchone
INSERT INTO users (email, name, role)
VALUES ($1, $2, $3)
RETURNING *;
```

```go
// –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π batch –∫–æ–¥
type CreateUsersBatchParams struct {
    Email string
    Name  string
    Role  string
}

func (q *Queries) CreateUsersBatch(ctx context.Context, arg []CreateUsersBatchParams) *CreateUsersBatchResults {
    batch := &pgx.Batch{}
    for _, a := range arg {
        batch.Queue(createUsersBatch, a.Email, a.Name, a.Role)
    }
    return &CreateUsersBatchResults{br: q.db.SendBatch(ctx, batch), ind: -1}
}

// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
func (s *UserService) BulkCreate(ctx context.Context, users []CreateUserRequest) ([]User, error) {
    params := make([]db.CreateUsersBatchParams, len(users))
    for i, u := range users {
        params[i] = db.CreateUsersBatchParams{
            Email: u.Email,
            Name:  u.Name,
            Role:  u.Role,
        }
    }

    results := s.queries.CreateUsersBatch(ctx, params)
    defer results.Close()

    var created []User
    for results.Next() {
        user, err := results.One()
        if err != nil {
            return nil, fmt.Errorf("batch result: %w", err)
        }
        created = append(created, mapUser(user))
    }

    return created, nil
}
```

### Custom Types –∏ Overrides

sqlc –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è—Ç—å —Ç–∏–ø—ã Go –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫.

```yaml
# sqlc.yaml
version: "2"
sql:
  - engine: "postgresql"
    queries: "queries/"
    schema: "schema/"
    gen:
      go:
        package: "db"
        out: "internal/db"
        sql_package: "pgx/v5"
        emit_json_tags: true
        overrides:
          # UUID ‚Üí google/uuid
          - db_type: "uuid"
            go_type:
              import: "github.com/google/uuid"
              type: "UUID"

          # NUMERIC ‚Üí shopspring/decimal
          - db_type: "numeric"
            go_type:
              import: "github.com/shopspring/decimal"
              type: "Decimal"

          # JSONB ‚Üí custom type
          - column: "users.metadata"
            go_type:
              import: "myapp/internal/types"
              type: "UserMetadata"

          # Custom enum
          - db_type: "pg_catalog.varchar"
            column: "orders.status"
            go_type:
              import: "myapp/internal/types"
              type: "OrderStatus"

          # Nullable override
          - db_type: "text"
            nullable: true
            go_type:
              type: "string"
              pointer: true
```

```go
// internal/types/types.go
package types

import (
    "database/sql/driver"
    "encoding/json"
    "fmt"
)

// UserMetadata ‚Äî —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
type UserMetadata struct {
    Timezone   string            `json:"timezone"`
    Locale     string            `json:"locale"`
    Preferences map[string]any   `json:"preferences"`
}

// Scan —Ä–µ–∞–ª–∏–∑—É–µ—Ç sql.Scanner
func (m *UserMetadata) Scan(src any) error {
    if src == nil {
        return nil
    }

    switch v := src.(type) {
    case []byte:
        return json.Unmarshal(v, m)
    case string:
        return json.Unmarshal([]byte(v), m)
    default:
        return fmt.Errorf("cannot scan %T into UserMetadata", src)
    }
}

// Value —Ä–µ–∞–ª–∏–∑—É–µ—Ç driver.Valuer
func (m UserMetadata) Value() (driver.Value, error) {
    return json.Marshal(m)
}

// OrderStatus ‚Äî enum –¥–ª—è —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–∫–∞–∑–∞
type OrderStatus string

const (
    OrderStatusPending   OrderStatus = "pending"
    OrderStatusPaid      OrderStatus = "paid"
    OrderStatusShipped   OrderStatus = "shipped"
    OrderStatusDelivered OrderStatus = "delivered"
    OrderStatusCancelled OrderStatus = "cancelled"
)

func (s OrderStatus) IsValid() bool {
    switch s {
    case OrderStatusPending, OrderStatusPaid, OrderStatusShipped,
         OrderStatusDelivered, OrderStatusCancelled:
        return true
    }
    return false
}
```

### sqlc.embed –¥–ª—è –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏

```sql
-- queries/orders.sql

-- name: GetOrderWithUser :one
SELECT
    sqlc.embed(orders),
    sqlc.embed(users)
FROM orders
JOIN users ON orders.user_id = users.id
WHERE orders.id = $1;
```

```go
// –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
type GetOrderWithUserRow struct {
    Order Order // –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ Order
    User  User  // –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ User
}

// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
row, err := queries.GetOrderWithUser(ctx, orderID)
fmt.Println(row.Order.ID, row.User.Email)
```

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ sqlc —Å Dapper (C#)

| –ê—Å–ø–µ–∫—Ç | sqlc (Go) | Dapper (C#) |
|--------|-----------|-------------|
| **–í—Ä–µ–º—è –ø—Ä–æ–≤–µ—Ä–∫–∏** | Compile-time | Runtime |
| **SQL** | –í .sql —Ñ–∞–π–ª–∞—Ö | –í —Å—Ç—Ä–æ–∫–∞—Ö C# |
| **Type safety** | –ü–æ–ª–Ω–∞—è | –ß–∞—Å—Ç–∏—á–Ω–∞—è |
| **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è** | –î–∞ (go generate) | –ù–µ—Ç |
| **Dynamic queries** | sqlc.narg, sqlc.slice | –ê–Ω–æ–Ω–∏–º–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã |
| **Transactions** | WithTx | connection.BeginTransaction |
| **Batch** | –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π | –ß–µ—Ä–µ–∑ Dapper Plus |

```csharp
// Dapper ‚Äî runtime SQL, reflection –¥–ª—è –º–∞–ø–ø–∏–Ω–≥–∞
var users = connection.Query<User>(
    "SELECT * FROM users WHERE role = @Role",
    new { Role = "admin" }
);

// –û—à–∏–±–∫–∏ —Ç–∏–ø–æ–≤ ‚Äî —Ç–æ–ª—å–∫–æ –≤ runtime
var users = connection.Query<User>(
    "SELECT * FROM users WHERE role = @Roe", // Typo!
    new { Role = "admin" } // –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∏–º—ë–Ω!
);
```

```go
// sqlc ‚Äî compile-time SQL, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞
users, err := queries.ListUsersByRole(ctx, "admin")

// –û—à–∏–±–∫–∏ —Ç–∏–ø–æ–≤ ‚Äî –ø—Ä–∏ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏
// –ï—Å–ª–∏ SQL –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π ‚Äî sqlc generate —É–ø–∞–¥—ë—Ç —Å –æ—à–∏–±–∫–æ–π
```

---

## Zero-Downtime Migrations

### –û–ø–∞—Å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏

–ü—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å production –ë–î –º–Ω–æ–≥–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –±–µ–∑–æ–±–∏–¥–Ω—ã –≤ development, –º–æ–≥—É—Ç –≤—ã–∑–≤–∞—Ç—å –¥–∞—É–Ω—Ç–∞–π–º.

#### –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –≤ PostgreSQL

| –û–ø–µ—Ä–∞—Ü–∏—è | –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ | –í–ª–∏—è–Ω–∏–µ |
|----------|-----------|---------|
| `ALTER TABLE ... ADD COLUMN` (nullable, –±–µ–∑ default) | `AccessExclusiveLock` (–º–≥–Ω–æ–≤–µ–Ω–Ω–æ) | –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ |
| `ALTER TABLE ... ADD COLUMN ... DEFAULT` (PG < 11) | `AccessExclusiveLock` + –ø–µ—Ä–µ–∑–∞–ø–∏—Å—å | **–î–æ–ª–≥–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞** |
| `ALTER TABLE ... ADD COLUMN ... DEFAULT` (PG >= 11) | `AccessExclusiveLock` (–º–≥–Ω–æ–≤–µ–Ω–Ω–æ) | –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ |
| `ALTER TABLE ... ALTER COLUMN SET NOT NULL` | `AccessExclusiveLock` (scan) | **–ë–ª–æ–∫–∏—Ä—É–µ—Ç —á—Ç–µ–Ω–∏–µ –∏ –∑–∞–ø–∏—Å—å** |
| `ALTER TABLE ... DROP COLUMN` | `AccessExclusiveLock` (–º–≥–Ω–æ–≤–µ–Ω–Ω–æ) | –õ–æ–º–∞–µ—Ç —Å—Ç–∞—Ä—ã–π –∫–æ–¥ |
| `CREATE INDEX` | `ShareLock` | **–ë–ª–æ–∫–∏—Ä—É–µ—Ç –∑–∞–ø–∏—Å—å** |
| `CREATE INDEX CONCURRENTLY` | –ë–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ | –ë–µ–∑–æ–ø–∞—Å–Ω–æ |
| `ALTER TABLE ... ADD CONSTRAINT` (CHECK, FK) | `AccessExclusiveLock` (scan) | **–î–æ–ª–≥–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞** |
| `DROP TABLE` | `AccessExclusiveLock` | –ú–≥–Ω–æ–≤–µ–Ω–Ω–æ, –Ω–æ –Ω–µ–æ–±—Ä–∞—Ç–∏–º–æ |

> ‚ö†Ô∏è **–ö—Ä–∏—Ç–∏—á–Ω–æ**: `AccessExclusiveLock` –±–ª–æ–∫–∏—Ä—É–µ—Ç **–≤—Å–µ** –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å —Ç–∞–±–ª–∏—Ü–µ–π ‚Äî –¥–∞–∂–µ `SELECT`. –ù–∞ —Ç–∞–±–ª–∏—Ü–µ —Å –º–∏–ª–ª–∏–æ–Ω–∞–º–∏ —Å—Ç—Ä–æ–∫ —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –º–∏–Ω—É—Ç—ã.

**C# –∞–Ω–∞–ª–æ–≥–∏—è**:
```csharp
// EF Core –º–∏–≥—Ä–∞—Ü–∏—è ‚Äî –º–æ–∂–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É
migrationBuilder.AddColumn<string>(
    name: "Phone",
    table: "Users",
    nullable: false,
    defaultValue: ""); // ‚ö†Ô∏è –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –≤ PG < 11!
```

### –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã

#### 1. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ nullable –∫–æ–ª–æ–Ω–∫–∏ (–±–µ–∑–æ–ø–∞—Å–Ω–æ)

```sql
-- ‚úÖ –ú–≥–Ω–æ–≤–µ–Ω–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è, –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ
ALTER TABLE users ADD COLUMN phone TEXT;
```

```go
// migrations/000010_add_users_phone.up.sql
ALTER TABLE users ADD COLUMN phone TEXT;

// migrations/000010_add_users_phone.down.sql
ALTER TABLE users DROP COLUMN phone;
```

#### 2. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ NOT NULL –∫–æ–ª–æ–Ω–∫–∏ (3-step pattern)

```sql
-- ‚ùå –û–ü–ê–°–ù–û: –±–ª–æ–∫–∏—Ä—É–µ—Ç —Ç–∞–±–ª–∏—Ü—É –Ω–∞ –±–æ–ª—å—à–æ–π —Ç–∞–±–ª–∏—Ü–µ
ALTER TABLE users ADD COLUMN status TEXT NOT NULL DEFAULT 'active';

-- ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û: 3 —à–∞–≥–∞
```

**–®–∞–≥ 1: –î–æ–±–∞–≤–∏—Ç—å nullable –∫–æ–ª–æ–Ω–∫—É**
```sql
-- migrations/000011_add_status_nullable.up.sql
ALTER TABLE users ADD COLUMN status TEXT;
```

**–®–∞–≥ 2: –ó–∞–ø–æ–ª–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –±–∞—Ç—á–∞–º–∏**
```go
// –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–∞–º–∏ (–Ω–µ –≤ –º–∏–≥—Ä–∞—Ü–∏–∏!)
func BackfillUserStatus(ctx context.Context, pool *pgxpool.Pool) error {
    const batchSize = 10000

    for {
        result, err := pool.Exec(ctx, `
            UPDATE users
            SET status = 'active'
            WHERE id IN (
                SELECT id FROM users
                WHERE status IS NULL
                LIMIT $1
                FOR UPDATE SKIP LOCKED
            )
        `, batchSize)
        if err != nil {
            return fmt.Errorf("backfill: %w", err)
        }

        rowsAffected := result.RowsAffected()
        slog.Info("backfill progress",
            slog.Int64("rows_updated", rowsAffected),
        )

        if rowsAffected == 0 {
            break // –í—Å–µ —Å—Ç—Ä–æ–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã
        }

        // –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å –ë–î
        time.Sleep(100 * time.Millisecond)
    }

    return nil
}
```

**–®–∞–≥ 3: –î–æ–±–∞–≤–∏—Ç—å NOT NULL constraint**
```sql
-- migrations/000012_add_status_not_null.up.sql
-- –ò—Å–ø–æ–ª—å–∑—É–µ–º CHECK constraint ‚Äî –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç—Å—è –±–µ–∑ –ø–æ–ª–Ω–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
ALTER TABLE users ADD CONSTRAINT users_status_not_null
    CHECK (status IS NOT NULL) NOT VALID;

-- –ó–∞—Ç–µ–º –≤–∞–ª–∏–¥–∏—Ä—É–µ–º (–±–µ—Ä—ë—Ç ShareUpdateExclusiveLock, –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç –∑–∞–ø–∏—Å–∏)
ALTER TABLE users VALIDATE CONSTRAINT users_status_not_null;

-- –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –∑–∞–º–µ–Ω—è–µ–º CHECK –Ω–∞ –Ω–∞—Å—Ç–æ—è—â–∏–π NOT NULL
-- (—Ç—Ä–µ–±—É–µ—Ç AccessExclusiveLock, –Ω–æ –º–≥–Ω–æ–≤–µ–Ω–Ω–æ –µ—Å–ª–∏ CHECK —É–∂–µ validated)
ALTER TABLE users ALTER COLUMN status SET NOT NULL;
ALTER TABLE users DROP CONSTRAINT users_status_not_null;
```

#### 3. –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏

```sql
-- ‚ùå –û–ü–ê–°–ù–û: ShareLock –±–ª–æ–∫–∏—Ä—É–µ—Ç INSERT/UPDATE/DELETE
CREATE INDEX idx_users_email ON users(email);

-- ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û: –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç DML
CREATE INDEX CONCURRENTLY idx_users_email ON users(email);
```

> ‚ö†Ô∏è **–í–∞–∂–Ω–æ**: `CREATE INDEX CONCURRENTLY` –Ω–µ–ª—å–∑—è –≤—ã–ø–æ–ª–Ω—è—Ç—å –≤–Ω—É—Ç—Ä–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏. –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ migration tools –≤—ã–ø–æ–ª–Ω—è—é—Ç –∫–∞–∂–¥—É—é –º–∏–≥—Ä–∞—Ü–∏—é –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏, –ø–æ—ç—Ç–æ–º—É –Ω—É–∂–Ω–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞.

```go
// golang-migrate: –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª –±–µ–∑ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
// migrations/000013_add_users_email_index.up.sql

-- +migrate StatementBegin
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_users_email ON users(email);
-- +migrate StatementEnd
```

```go
// goose: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
// migrations/000013_add_users_email_index.sql

-- +goose Up
-- +goose NO TRANSACTION
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_users_email ON users(email);

-- +goose Down
DROP INDEX IF EXISTS idx_users_email;
```

#### 4. –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ Foreign Key

```sql
-- ‚ùå –û–ü–ê–°–ù–û: AccessExclusiveLock + scan –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫
ALTER TABLE orders ADD CONSTRAINT fk_orders_user
    FOREIGN KEY (user_id) REFERENCES users(id);

-- ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û: –¥–≤–∞ —à–∞–≥–∞
-- –®–∞–≥ 1: –î–æ–±–∞–≤–∏—Ç—å constraint –±–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–º–≥–Ω–æ–≤–µ–Ω–Ω–æ)
ALTER TABLE orders ADD CONSTRAINT fk_orders_user
    FOREIGN KEY (user_id) REFERENCES users(id) NOT VALID;

-- –®–∞–≥ 2: –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å (ShareUpdateExclusiveLock ‚Äî –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç –∑–∞–ø–∏—Å–∏)
ALTER TABLE orders VALIDATE CONSTRAINT fk_orders_user;
```

#### 5. –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ (Expand/Contract)

```sql
-- ‚ùå –û–ü–ê–°–ù–û: –ª–æ–º–∞–µ—Ç —Ä–∞–±–æ—Ç–∞—é—â–µ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
ALTER TABLE users RENAME COLUMN name TO full_name;
```

### Expand/Contract Pattern

–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ö–µ–º—ã –≤ 4 —Ñ–∞–∑—ã:

```
Phase 1: Expand      ‚Äî –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
Phase 2: Migrate     ‚Äî –ü–µ—Ä–µ–Ω–µ—Å—Ç–∏ –¥–∞–Ω–Ω—ã–µ
Phase 3: Code Switch ‚Äî –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –∫–æ–¥
Phase 4: Contract    ‚Äî –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
```

**–ü—Ä–∏–º–µ—Ä: –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ `name` ‚Üí `full_name`**

```sql
-- Phase 1: Expand (Deploy 1)
ALTER TABLE users ADD COLUMN full_name TEXT;

-- –¢—Ä–∏–≥–≥–µ—Ä –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
CREATE OR REPLACE FUNCTION sync_user_name() RETURNS trigger AS $$
BEGIN
    IF TG_OP = 'INSERT' OR TG_OP = 'UPDATE' THEN
        IF NEW.full_name IS NULL AND NEW.name IS NOT NULL THEN
            NEW.full_name := NEW.name;
        ELSIF NEW.name IS NULL AND NEW.full_name IS NOT NULL THEN
            NEW.name := NEW.full_name;
        END IF;
    END IF;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_sync_user_name
    BEFORE INSERT OR UPDATE ON users
    FOR EACH ROW EXECUTE FUNCTION sync_user_name();
```

```sql
-- Phase 2: Migrate (–º–µ–∂–¥—É Deploy 1 –∏ Deploy 2)
UPDATE users SET full_name = name WHERE full_name IS NULL;
```

```go
// Phase 3: Code Switch (Deploy 2)
// –ö–æ–¥ –Ω–∞—á–∏–Ω–∞–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å full_name –≤–º–µ—Å—Ç–æ name
type User struct {
    ID       int64
    FullName string `db:"full_name"` // –ë—ã–ª–æ: Name string `db:"name"`
}
```

```sql
-- Phase 4: Contract (Deploy 3 ‚Äî —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π)
DROP TRIGGER trg_sync_user_name ON users;
DROP FUNCTION sync_user_name;
ALTER TABLE users DROP COLUMN name;
```

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: –≠—Ç–æ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω –∞–Ω–∞–ª–æ–≥–∏—á–µ–Ω —Ç–æ–º—É, —á—Ç–æ –¥–µ–ª–∞–µ—Ç EF Core —Å "Two-phase migration" ‚Äî —Ç–æ–ª—å–∫–æ –≤—Ä—É—á–Ω—É—é –∏ —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç—Ä–æ–ª–µ–º.

### Atlas: Declarative Migrations

Atlas ‚Äî —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è declarative (–∞ –Ω–µ imperative) –º–∏–≥—Ä–∞—Ü–∏–π.

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞
curl -sSf https://atlasgo.sh | sh
```

#### –î–µ–∫–ª–∞—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥

```hcl
# schema.hcl ‚Äî –æ–ø–∏—Å—ã–≤–∞–µ–º –∂–µ–ª–∞–µ–º–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
schema "public" {
  table "users" {
    column "id" {
      type = serial
    }
    column "email" {
      type = text
      null = false
    }
    column "name" {
      type = text
      null = false
    }
    column "status" {
      type = text
      null = false
      default = "active"
    }
    column "created_at" {
      type    = timestamptz
      null    = false
      default = sql("now()")
    }

    primary_key {
      columns = [column.id]
    }

    index "idx_users_email" {
      unique  = true
      columns = [column.email]
    }

    index "idx_users_status" {
      columns = [column.status]
    }
  }

  table "orders" {
    column "id" {
      type = serial
    }
    column "user_id" {
      type = integer
      null = false
    }
    column "total_amount" {
      type = numeric
      null = false
    }
    column "status" {
      type = text
      null = false
    }
    column "created_at" {
      type    = timestamptz
      null    = false
      default = sql("now()")
    }

    primary_key {
      columns = [column.id]
    }

    foreign_key "fk_orders_user" {
      columns     = [column.user_id]
      ref_columns = [table.users.column.id]
      on_delete   = CASCADE
    }
  }
}
```

```bash
# Atlas –≤—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞–∑–Ω–∏—Ü—É –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç SQL
atlas schema diff \
  --from "postgres://localhost:5432/mydb?sslmode=disable" \
  --to "file://schema.hcl" \
  --dev-url "docker://postgres/15"

# –ü—Ä–∏–º–µ–Ω—è–µ—Ç –º–∏–≥—Ä–∞—Ü–∏—é
atlas schema apply \
  --url "postgres://localhost:5432/mydb?sslmode=disable" \
  --to "file://schema.hcl" \
  --dev-url "docker://postgres/15"
```

#### Atlas —Å Go

```go
// atlas.hcl ‚Äî –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
variable "db_url" {
  type    = string
  default = getenv("DATABASE_URL")
}

env "production" {
  url = var.db_url
  migration {
    dir = "file://migrations"
  }
  lint {
    destructive {
      error = true
    }
    // –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞—Ç—å –æ–± –æ–ø–∞—Å–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏—è—Ö
    data_depend {
      error = true
    }
  }
}
```

```bash
# Lint –º–∏–≥—Ä–∞—Ü–∏–π –ø–µ—Ä–µ–¥ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º
atlas migrate lint --env production

# –ü—Ä–æ–≤–µ—Ä–∫–∞: –Ω–∞–π–¥—ë—Ç –æ–ø–∞—Å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
# Error: destructive change detected:
#   Dropping column "name" from table "users"
```

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –º–∏–≥—Ä–∞—Ü–∏–π

| –ê—Å–ø–µ–∫—Ç | golang-migrate | goose | Atlas |
|--------|---------------|-------|-------|
| **–ü–æ–¥—Ö–æ–¥** | Imperative | Imperative | Declarative |
| **SQL —Ñ–∞–π–ª—ã** | –û—Ç–¥–µ–ª—å–Ω—ã–µ up/down | –û–¥–∏–Ω —Ñ–∞–π–ª | HCL –∏–ª–∏ SQL |
| **Go –º–∏–≥—Ä–∞—Ü–∏–∏** | –ù–µ—Ç | –î–∞ | –î–∞ |
| **Lint** | –ù–µ—Ç | –ù–µ—Ç | –î–∞ (–æ–ø–∞—Å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏) |
| **Diff** | –ù–µ—Ç | –ù–µ—Ç | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π |
| **CONCURRENTLY** | –°–ª–æ–∂–Ω–æ | `NO TRANSACTION` | –í—Å—Ç—Ä–æ–µ–Ω–æ |
| **C# –∞–Ω–∞–ª–æ–≥** | DbUp | FluentMigrator | EF Core |

---

## Query Performance

### EXPLAIN ANALYZE –∏–∑ Go

–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ ‚Äî –∫–ª—é—á–µ–≤–æ–π –Ω–∞–≤—ã–∫ –¥–ª—è production.

```go
package pgutil

import (
    "context"
    "encoding/json"
    "fmt"
    "log/slog"
    "strings"

    "github.com/jackc/pgx/v5/pgxpool"
)

// QueryPlan –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –ø–ª–∞–Ω –∑–∞–ø—Ä–æ—Å–∞ PostgreSQL
type QueryPlan struct {
    Plan              PlanNode `json:"Plan"`
    PlanningTime      float64  `json:"Planning Time"`
    ExecutionTime     float64  `json:"Execution Time"`
    // Triggers
    Triggers          []any    `json:"Triggers"`
}

type PlanNode struct {
    NodeType          string     `json:"Node Type"`
    RelationName      string     `json:"Relation Name"`
    Alias             string     `json:"Alias"`
    StartupCost       float64    `json:"Startup Cost"`
    TotalCost         float64    `json:"Total Cost"`
    PlanRows          int64      `json:"Plan Rows"`
    PlanWidth         int        `json:"Plan Width"`
    ActualStartupTime float64    `json:"Actual Startup Time"`
    ActualTotalTime   float64    `json:"Actual Total Time"`
    ActualRows        int64      `json:"Actual Rows"`
    ActualLoops       int        `json:"Actual Loops"`
    SharedHitBlocks   int64      `json:"Shared Hit Blocks"`
    SharedReadBlocks  int64      `json:"Shared Read Blocks"`
    Plans             []PlanNode `json:"Plans"`
}

// ExplainAnalyze –≤—ã–ø–æ–ª–Ω—è–µ—Ç EXPLAIN ANALYZE –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–ª–∞–Ω
func ExplainAnalyze(ctx context.Context, pool *pgxpool.Pool, query string, args ...any) (*QueryPlan, error) {
    explainQuery := fmt.Sprintf(
        "EXPLAIN (ANALYZE, FORMAT JSON, BUFFERS, TIMING) %s",
        query,
    )

    var planJSON string
    err := pool.QueryRow(ctx, explainQuery, args...).Scan(&planJSON)
    if err != nil {
        return nil, fmt.Errorf("explain: %w", err)
    }

    var plans []QueryPlan
    if err := json.Unmarshal([]byte(planJSON), &plans); err != nil {
        return nil, fmt.Errorf("parse plan: %w", err)
    }

    if len(plans) == 0 {
        return nil, fmt.Errorf("empty plan")
    }

    return &plans[0], nil
}

// LogSlowQuery –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ –ª–æ–≥–∏—Ä—É–µ—Ç –º–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
func LogSlowQuery(ctx context.Context, pool *pgxpool.Pool, logger *slog.Logger,
    query string, threshold float64, args ...any) {

    plan, err := ExplainAnalyze(ctx, pool, query, args...)
    if err != nil {
        logger.Error("explain failed", slog.String("error", err.Error()))
        return
    }

    if plan.ExecutionTime > threshold {
        logger.Warn("slow query detected",
            slog.String("query", query),
            slog.Float64("execution_time_ms", plan.ExecutionTime),
            slog.Float64("planning_time_ms", plan.PlanningTime),
            slog.String("node_type", plan.Plan.NodeType),
            slog.Int64("actual_rows", plan.Plan.ActualRows),
            slog.Int64("planned_rows", plan.Plan.PlanRows),
        )

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        checkPlanIssues(logger, &plan.Plan, 0)
    }
}

func checkPlanIssues(logger *slog.Logger, node *PlanNode, depth int) {
    // Seq Scan –Ω–∞ –±–æ–ª—å—à–æ–π —Ç–∞–±–ª–∏—Ü–µ
    if node.NodeType == "Seq Scan" && node.ActualRows > 10000 {
        logger.Warn("sequential scan on large table",
            slog.String("table", node.RelationName),
            slog.Int64("rows", node.ActualRows),
            slog.String("suggestion", "consider adding an index"),
        )
    }

    // –ë–æ–ª—å—à–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É planned –∏ actual rows (–ø–ª–æ—Ö–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
    if node.PlanRows > 0 && node.ActualRows > 0 {
        ratio := float64(node.ActualRows) / float64(node.PlanRows)
        if ratio > 10 || ratio < 0.1 {
            logger.Warn("row estimate mismatch",
                slog.Int64("planned", node.PlanRows),
                slog.Int64("actual", node.ActualRows),
                slog.Float64("ratio", ratio),
                slog.String("suggestion", "run ANALYZE on the table"),
            )
        }
    }

    // –ú–Ω–æ–≥–æ disk reads (buffer cache miss)
    if node.SharedReadBlocks > 0 {
        hitRatio := float64(node.SharedHitBlocks) /
            float64(node.SharedHitBlocks+node.SharedReadBlocks)
        if hitRatio < 0.95 {
            logger.Warn("low buffer cache hit ratio",
                slog.Float64("hit_ratio", hitRatio),
                slog.Int64("read_blocks", node.SharedReadBlocks),
                slog.String("suggestion", "increase shared_buffers or check query"),
            )
        }
    }

    // –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—á–µ—Ä–Ω–∏–µ —É–∑–ª—ã
    for i := range node.Plans {
        checkPlanIssues(logger, &node.Plans[i], depth+1)
    }
}
```

### –ß—Ç–µ–Ω–∏–µ –ø–ª–∞–Ω–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤

```
-- –¢–∏–ø—ã —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è (–æ—Ç –ª—É—á—à–µ–≥–æ –∫ —Ö—É–¥—à–µ–º—É)
Index Only Scan  ‚Üí –î–∞–Ω–Ω—ã–µ —á–∏—Ç–∞—é—Ç—Å—è –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ (–ª—É—á—à–∏–π)
Index Scan       ‚Üí –ò–Ω–¥–µ–∫—Å + heap lookup
Bitmap Scan      ‚Üí –ò–Ω–¥–µ–∫—Å + bitmap + heap
Seq Scan         ‚Üí –ü–æ–ª–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ (—Ö—É–¥—à–∏–π –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü)

-- –¢–∏–ø—ã —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
Nested Loop      ‚Üí O(n*m) ‚Äî —Ö–æ—Ä–æ—à–æ –¥–ª—è –º–∞–ª—ã—Ö —Ç–∞–±–ª–∏—Ü / –∏–Ω–¥–µ–∫—Å–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
Hash Join        ‚Üí O(n+m) ‚Äî —Ö–æ—Ä–æ—à–æ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü
Merge Join       ‚Üí O(n+m) ‚Äî —Ö–æ—Ä–æ—à–æ –¥–ª—è –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
```

```sql
-- –ü—Ä–∏–º–µ—Ä: –ø–ª–æ—Ö–æ–π –ø–ª–∞–Ω
EXPLAIN ANALYZE
SELECT * FROM orders o
JOIN users u ON o.user_id = u.id
WHERE u.email = 'user@example.com';

-- –†–µ–∑—É–ª—å—Ç–∞—Ç:
-- Nested Loop (cost=0.56..16.61 rows=1 width=...)
--   -> Index Scan using idx_users_email on users u (cost=0.28..8.30 rows=1 width=...)
--        Index Cond: (email = 'user@example.com')
--   -> Index Scan using idx_orders_user_id on orders o (cost=0.28..8.30 rows=1 width=...)
--        Index Cond: (user_id = u.id)
-- Planning Time: 0.182 ms
-- Execution Time: 0.045 ms   ‚úÖ –ë—ã—Å—Ç—Ä–æ
```

```sql
-- –ü—Ä–∏–º–µ—Ä: –ø–ª–æ—Ö–æ–π –ø–ª–∞–Ω (–±–µ–∑ –∏–Ω–¥–µ–∫—Å–∞)
EXPLAIN ANALYZE
SELECT * FROM orders WHERE status = 'pending';

-- –†–µ–∑—É–ª—å—Ç–∞—Ç:
-- Seq Scan on orders (cost=0.00..25000.00 rows=50000 width=...)
--   Filter: (status = 'pending')
--   Rows Removed by Filter: 950000
-- Planning Time: 0.100 ms
-- Execution Time: 1250.000 ms   ‚ùå –ú–µ–¥–ª–µ–Ω–Ω–æ ‚Äî Seq Scan –Ω–∞ 1M —Å—Ç—Ä–æ–∫
```

### –¢–∏–ø—ã –∏–Ω–¥–µ–∫—Å–æ–≤

```sql
-- B-tree (default) ‚Äî –¥–ª—è –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤ =, <, >, <=, >=, BETWEEN, IN, LIKE 'prefix%'
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_orders_created ON orders(created_at DESC);

-- Composite index ‚Äî –ø–æ—Ä—è–¥–æ–∫ –≤–∞–∂–µ–Ω!
CREATE INDEX idx_orders_user_status ON orders(user_id, status);
-- ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è: WHERE user_id = 1
-- ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è: WHERE user_id = 1 AND status = 'pending'
-- ‚ùå –ù–ï —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è: WHERE status = 'pending' (–Ω—É–∂–µ–Ω –æ—Ç–¥–µ–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å)

-- Partial index ‚Äî –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ —á–∞—Å—Ç—å —Å—Ç—Ä–æ–∫
CREATE INDEX idx_orders_pending ON orders(created_at)
    WHERE status = 'pending';
-- –ú–µ–Ω—å—à–∏–π —Ä–∞–∑–º–µ—Ä, –±—ã—Å—Ç—Ä–µ–µ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è

-- Covering index (INCLUDE) ‚Äî PG 11+
CREATE INDEX idx_orders_user_covering ON orders(user_id)
    INCLUDE (status, total_amount);
-- Index Only Scan ‚Äî –Ω–µ –Ω—É–∂–Ω–æ –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ heap

-- GIN (Generalized Inverted Index) ‚Äî –¥–ª—è –º–∞—Å—Å–∏–≤–æ–≤, JSONB, full-text
CREATE INDEX idx_products_tags ON products USING GIN(tags);
CREATE INDEX idx_products_metadata ON products USING GIN(metadata jsonb_path_ops);

-- GiST ‚Äî –¥–ª—è –≥–µ–æ–¥–∞–Ω–Ω—ã—Ö, –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
CREATE INDEX idx_events_period ON events USING GiST(
    tstzrange(start_time, end_time)
);

-- BRIN (Block Range Index) ‚Äî –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü —Å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–æ–π
CREATE INDEX idx_logs_created ON logs USING BRIN(created_at);
-- –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–π –∏–Ω–¥–µ–∫—Å, —Ö–æ—Ä–æ—à –¥–ª—è append-only —Ç–∞–±–ª–∏—Ü
```

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ —Å SQL Server (C#)

| PostgreSQL | SQL Server | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ |
|-----------|------------|---------------|
| B-tree | Clustered/Non-clustered | –û—Å–Ω–æ–≤–Ω–æ–π —Ç–∏–ø |
| Partial Index | Filtered Index | WHERE condition |
| Covering (INCLUDE) | Covering Index (INCLUDE) | Index Only Scan |
| GIN | Full-Text Index | –ú–∞—Å—Å–∏–≤—ã, JSONB, FTS |
| GiST | Spatial Index | –ì–µ–æ–¥–∞–Ω–Ω—ã–µ |
| BRIN | ‚Äî (–Ω–µ—Ç –∞–Ω–∞–ª–æ–≥–∞) | Append-only —Ç–∞–±–ª–∏—Ü—ã |

### Query Tuning

#### Connection-level settings

```go
// –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –¥–ª—è —Ç—è–∂—ë–ª—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
func ExecuteHeavyQuery(ctx context.Context, pool *pgxpool.Pool) error {
    conn, err := pool.Acquire(ctx)
    if err != nil {
        return err
    }
    defer conn.Release()

    // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º work_mem –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    // (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–æ–∫ –∏ —Ö—ç—à-—Ç–∞–±–ª–∏—Ü)
    _, err = conn.Exec(ctx, "SET LOCAL work_mem = '256MB'")
    if err != nil {
        return err
    }

    // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç
    _, err = conn.Exec(ctx, "SET LOCAL statement_timeout = '120s'")
    if err != nil {
        return err
    }

    // –í—ã–ø–æ–ª–Ω—è–µ–º —Ç—è–∂—ë–ª—ã–π –∑–∞–ø—Ä–æ—Å
    rows, err := conn.Query(ctx, `
        SELECT ...
        FROM large_table
        ORDER BY complex_expression
    `)
    // ...

    return nil
}
```

#### –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã PostgreSQL

```go
// PostgreSQL –º–æ–∂–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å –∑–∞–ø—Ä–æ—Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ (PG 9.6+)
// –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É—é—Ç —ç—Ç–æ –ø–æ–≤–µ–¥–µ–Ω–∏–µ

func ConfigureParallelQueries(ctx context.Context, pool *pgxpool.Pool) {
    // Runtime params –¥–ª—è –≤—Å–µ—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
    poolConfig.ConnConfig.RuntimeParams = map[string]string{
        // –ú–∞–∫—Å–∏–º—É–º –≤–æ—Ä–∫–µ—Ä–æ–≤ –Ω–∞ –∑–∞–ø—Ä–æ—Å
        "max_parallel_workers_per_gather": "4",

        // –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        "min_parallel_table_scan_size": "8MB",

        // –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        "min_parallel_index_scan_size": "512kB",
    }
}
```

### pg_stat_statements

–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –ë–î.

```sql
-- –í–∫–ª—é—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
```

```go
// –ü–æ–ª—É—á–µ–Ω–∏–µ Top-N –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
type SlowQuery struct {
    Query          string
    Calls          int64
    TotalTimeMs    float64
    MeanTimeMs     float64
    MaxTimeMs      float64
    Rows           int64
    SharedBlksHit  int64
    SharedBlksRead int64
}

func GetSlowQueries(ctx context.Context, pool *pgxpool.Pool, limit int) ([]SlowQuery, error) {
    rows, err := pool.Query(ctx, `
        SELECT
            query,
            calls,
            total_exec_time as total_time_ms,
            mean_exec_time as mean_time_ms,
            max_exec_time as max_time_ms,
            rows,
            shared_blks_hit,
            shared_blks_read
        FROM pg_stat_statements
        WHERE query NOT LIKE '%pg_stat_statements%'
        ORDER BY total_exec_time DESC
        LIMIT $1
    `, limit)
    if err != nil {
        return nil, err
    }
    defer rows.Close()

    var queries []SlowQuery
    for rows.Next() {
        var q SlowQuery
        err := rows.Scan(
            &q.Query, &q.Calls, &q.TotalTimeMs,
            &q.MeanTimeMs, &q.MaxTimeMs, &q.Rows,
            &q.SharedBlksHit, &q.SharedBlksRead,
        )
        if err != nil {
            return nil, err
        }
        queries = append(queries, q)
    }

    return queries, rows.Err()
}

// –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
func AnalyzeSlowQueries(ctx context.Context, pool *pgxpool.Pool, logger *slog.Logger) {
    queries, err := GetSlowQueries(ctx, pool, 20)
    if err != nil {
        logger.Error("failed to get slow queries", slog.String("error", err.Error()))
        return
    }

    for _, q := range queries {
        // Buffer cache hit ratio
        totalBlocks := q.SharedBlksHit + q.SharedBlksRead
        var hitRatio float64
        if totalBlocks > 0 {
            hitRatio = float64(q.SharedBlksHit) / float64(totalBlocks) * 100
        }

        logger.Info("slow query",
            slog.String("query", truncate(q.Query, 100)),
            slog.Int64("calls", q.Calls),
            slog.Float64("total_time_ms", q.TotalTimeMs),
            slog.Float64("mean_time_ms", q.MeanTimeMs),
            slog.Float64("max_time_ms", q.MaxTimeMs),
            slog.Float64("cache_hit_ratio", hitRatio),
        )
    }
}

func truncate(s string, maxLen int) string {
    if len(s) <= maxLen {
        return s
    }
    return s[:maxLen] + "..."
}
```

### Auto EXPLAIN

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–ª–∞–Ω–æ–≤ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:

```sql
-- postgresql.conf
shared_preload_libraries = 'auto_explain'
auto_explain.log_min_duration = '100ms'  -- –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å—ã > 100ms
auto_explain.log_analyze = true          -- –í–∫–ª—é—á–∏—Ç—å ANALYZE
auto_explain.log_buffers = true          -- –í–∫–ª—é—á–∏—Ç—å buffer stats
auto_explain.log_format = 'json'         -- JSON —Ñ–æ—Ä–º–∞—Ç
auto_explain.log_nested_statements = true
```

```go
// –ü—Ä–æ–≥—Ä–∞–º–º–Ω–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
func EnableAutoExplain(ctx context.Context, conn *pgx.Conn) error {
    _, err := conn.Exec(ctx, `
        LOAD 'auto_explain';
        SET auto_explain.log_min_duration = '50ms';
        SET auto_explain.log_analyze = true;
    `)
    return err
}
```

---

## High Availability

### Read Replicas

–í production —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç read replicas –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è —á—Ç–µ–Ω–∏—è. –í Go —ç—Ç–æ —Ä–µ–∞–ª–∏–∑—É–µ—Ç—Å—è —á–µ—Ä–µ–∑ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é –∑–∞–ø—Ä–æ—Å–æ–≤.

```go
package postgres

import (
    "context"
    "fmt"
    "math/rand"
    "sync/atomic"

    "github.com/jackc/pgx/v5/pgxpool"
)

// DBCluster —É–ø—Ä–∞–≤–ª—è–µ—Ç primary –∏ replica —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è–º–∏
type DBCluster struct {
    primary  *pgxpool.Pool
    replicas []*pgxpool.Pool
    counter  atomic.Uint64 // –¥–ª—è round-robin
}

func NewDBCluster(ctx context.Context, primaryDSN string, replicaDSNs []string) (*DBCluster, error) {
    primary, err := pgxpool.New(ctx, primaryDSN)
    if err != nil {
        return nil, fmt.Errorf("connect primary: %w", err)
    }

    replicas := make([]*pgxpool.Pool, 0, len(replicaDSNs))
    for _, dsn := range replicaDSNs {
        replica, err := pgxpool.New(ctx, dsn)
        if err != nil {
            // –ó–∞–∫—Ä—ã–≤–∞–µ–º —É–∂–µ –æ—Ç–∫—Ä—ã—Ç—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
            primary.Close()
            for _, r := range replicas {
                r.Close()
            }
            return nil, fmt.Errorf("connect replica: %w", err)
        }
        replicas = append(replicas, replica)
    }

    return &DBCluster{
        primary:  primary,
        replicas: replicas,
    }, nil
}

// Primary –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É–ª –¥–ª—è –∑–∞–ø–∏—Å–∏
func (c *DBCluster) Primary() *pgxpool.Pool {
    return c.primary
}

// Replica –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É–ª –¥–ª—è —á—Ç–µ–Ω–∏—è (round-robin)
func (c *DBCluster) Replica() *pgxpool.Pool {
    if len(c.replicas) == 0 {
        return c.primary // Fallback –Ω–∞ primary
    }

    idx := c.counter.Add(1) % uint64(len(c.replicas))
    return c.replicas[idx]
}

// ReplicaRandom –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—É—é —Ä–µ–ø–ª–∏–∫—É
func (c *DBCluster) ReplicaRandom() *pgxpool.Pool {
    if len(c.replicas) == 0 {
        return c.primary
    }
    return c.replicas[rand.Intn(len(c.replicas))]
}

// Close –∑–∞–∫—Ä—ã–≤–∞–µ—Ç –≤—Å–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
func (c *DBCluster) Close() {
    c.primary.Close()
    for _, r := range c.replicas {
        r.Close()
    }
}
```

#### Context-based routing

```go
// –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ context
type ctxKey string

const readOnlyKey ctxKey = "read_only"

// WithReadOnly –ø–æ–º–µ—á–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –∫–∞–∫ read-only
func WithReadOnly(ctx context.Context) context.Context {
    return context.WithValue(ctx, readOnlyKey, true)
}

func IsReadOnly(ctx context.Context) bool {
    v, ok := ctx.Value(readOnlyKey).(bool)
    return ok && v
}

// Repository —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–µ–π
type UserRepository struct {
    cluster *DBCluster
}

func (r *UserRepository) pool(ctx context.Context) *pgxpool.Pool {
    if IsReadOnly(ctx) {
        return r.cluster.Replica()
    }
    return r.cluster.Primary()
}

func (r *UserRepository) GetByID(ctx context.Context, id int64) (*User, error) {
    // –ß—Ç–µ–Ω–∏–µ ‚Üí –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–ø–ª–∏–∫—É
    ctx = WithReadOnly(ctx)

    var u User
    err := r.pool(ctx).QueryRow(ctx,
        "SELECT id, email, name FROM users WHERE id = $1", id,
    ).Scan(&u.ID, &u.Email, &u.Name)

    return &u, err
}

func (r *UserRepository) Create(ctx context.Context, user *User) error {
    // –ó–∞–ø–∏—Å—å ‚Üí –∏—Å–ø–æ–ª—å–∑—É–µ–º primary (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    _, err := r.pool(ctx).Exec(ctx,
        "INSERT INTO users (email, name) VALUES ($1, $2)",
        user.Email, user.Name,
    )
    return err
}
```

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: –ê–Ω–∞–ª–æ–≥ –≤ EF Core ‚Äî —ç—Ç–æ `context.Database.UseTransaction()` —Å read-only connection, –∏–ª–∏ split read/write DbContext. –í Go –ø–æ–¥—Ö–æ–¥ –±–æ–ª–µ–µ —è–≤–Ω—ã–π.

### Connection String –¥–ª—è HA

PostgreSQL –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç multi-host connection strings:

```go
// Multi-host connection string ‚Äî pgx –ø–æ–ø—Ä–æ–±—É–µ—Ç –∫–∞–∂–¥—ã–π —Ö–æ—Å—Ç
primaryDSN := "postgres://user:pass@host1:5432,host2:5432/mydb?target_session_attrs=read-write"

// –î–ª—è —Ä–µ–ø–ª–∏–∫
replicaDSN := "postgres://user:pass@replica1:5432,replica2:5432/mydb?target_session_attrs=read-only"
```

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|----------|----------|
| `target_session_attrs` | `read-write` | Primary (–¥–ª—è –∑–∞–ø–∏—Å–∏) |
| `target_session_attrs` | `read-only` | Replica (–¥–ª—è —á—Ç–µ–Ω–∏—è) |
| `target_session_attrs` | `any` | –õ—é–±–æ–π –¥–æ—Å—Ç—É–ø–Ω—ã–π |
| `target_session_attrs` | `primary` | –¢–æ–ª—å–∫–æ primary |
| `target_session_attrs` | `standby` | –¢–æ–ª—å–∫–æ standby |

### Retry Strategies

–¢—Ä–∞–Ω–∑–∏–µ–Ω—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏ ‚Äî –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç—å production. –ù—É–∂–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫.

```go
package pgutil

import (
    "context"
    "errors"
    "math"
    "math/rand"
    "time"

    "github.com/jackc/pgx/v5/pgconn"
)

// RetryConfig –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
type RetryConfig struct {
    MaxRetries     int
    InitialBackoff time.Duration
    MaxBackoff     time.Duration
    Multiplier     float64
    Jitter         bool
}

func DefaultRetryConfig() RetryConfig {
    return RetryConfig{
        MaxRetries:     3,
        InitialBackoff: 100 * time.Millisecond,
        MaxBackoff:     5 * time.Second,
        Multiplier:     2.0,
        Jitter:         true,
    }
}

// WithRetry –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
func WithRetry[T any](
    ctx context.Context,
    cfg RetryConfig,
    fn func(ctx context.Context) (T, error),
) (T, error) {
    var result T
    var lastErr error

    for attempt := 0; attempt <= cfg.MaxRetries; attempt++ {
        result, lastErr = fn(ctx)
        if lastErr == nil {
            return result, nil
        }

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–Ω–æ –ª–∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å
        if !IsRetryable(lastErr) {
            return result, lastErr
        }

        // –ù–µ –∂–¥—ë–º –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–ø—ã—Ç–∫–∏
        if attempt == cfg.MaxRetries {
            break
        }

        // Exponential backoff
        backoff := cfg.InitialBackoff * time.Duration(math.Pow(cfg.Multiplier, float64(attempt)))
        if backoff > cfg.MaxBackoff {
            backoff = cfg.MaxBackoff
        }

        // Jitter (—Å–ª—É—á–∞–π–Ω—ã–π —Ä–∞–∑–±—Ä–æ—Å –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è thundering herd)
        if cfg.Jitter {
            backoff = time.Duration(rand.Int63n(int64(backoff)))
        }

        select {
        case <-ctx.Done():
            return result, ctx.Err()
        case <-time.After(backoff):
            // –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º
        }
    }

    return result, fmt.Errorf("max retries exceeded: %w", lastErr)
}

// IsRetryable –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –º–æ–∂–Ω–æ –ª–∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –æ—à–∏–±–∫—É
func IsRetryable(err error) bool {
    if err == nil {
        return false
    }

    // Context cancelled ‚Äî –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–µ–º
    if errors.Is(err, context.Canceled) || errors.Is(err, context.DeadlineExceeded) {
        return false
    }

    // PostgreSQL error codes
    var pgErr *pgconn.PgError
    if errors.As(err, &pgErr) {
        switch pgErr.Code {
        case "40001": // serialization_failure
            return true
        case "40P01": // deadlock_detected
            return true
        case "08000", "08003", "08006": // connection errors
            return true
        case "57P01": // admin_shutdown
            return true
        case "57P03": // cannot_connect_now
            return true
        default:
            return false
        }
    }

    // –û—à–∏–±–∫–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    if isConnectionError(err) {
        return true
    }

    return false
}

func isConnectionError(err error) bool {
    msg := err.Error()
    connectionErrors := []string{
        "connection refused",
        "connection reset",
        "broken pipe",
        "no such host",
        "connection timed out",
        "EOF",
    }
    for _, ce := range connectionErrors {
        if strings.Contains(msg, ce) {
            return true
        }
    }
    return false
}

// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
func (r *OrderRepository) GetByID(ctx context.Context, id int64) (*Order, error) {
    return WithRetry(ctx, DefaultRetryConfig(), func(ctx context.Context) (*Order, error) {
        var o Order
        err := r.pool.QueryRow(ctx,
            "SELECT id, user_id, total_amount FROM orders WHERE id = $1", id,
        ).Scan(&o.ID, &o.UserID, &o.TotalAmount)
        return &o, err
    })
}
```

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å Polly (C#)

| –ê—Å–ø–µ–∫—Ç | Go (—Ä—É—á–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è) | C# (Polly) |
|--------|----------------------|-------------|
| **API** | `WithRetry(ctx, cfg, fn)` | `Policy.Handle<>().WaitAndRetry()` |
| **Jitter** | –†—É—á–Ω–æ–π | `Backoff.DecorrelatedJitterBackoffV2` |
| **Circuit Breaker** | –†—É—á–Ω–æ–π –∏–ª–∏ go-circuitbreaker | `Policy.CircuitBreaker()` |
| **–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ** | –í–ª–æ–∂–µ–Ω–Ω—ã–µ –≤—ã–∑–æ–≤—ã | `Policy.Wrap()` |
| **Dependency** | –ù–µ—Ç | NuGet –ø–∞–∫–µ—Ç |

```csharp
// C# Polly
var retryPolicy = Policy
    .Handle<SqlException>(ex => ex.IsTransient)
    .WaitAndRetryAsync(3, attempt =>
        TimeSpan.FromMilliseconds(100 * Math.Pow(2, attempt)));

var result = await retryPolicy.ExecuteAsync(async () =>
    await connection.QueryFirstAsync<Order>(sql, new { Id = id })
);
```

### Circuit Breaker

Circuit Breaker –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–≥—Ä—É–∑–∫—É –ë–î –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö.

```go
package pgutil

import (
    "context"
    "errors"
    "sync"
    "time"
)

type CircuitState int

const (
    CircuitClosed   CircuitState = iota // –ù–æ—Ä–º–∞–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞
    CircuitOpen                          // –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –æ—Ç–∫–ª–æ–Ω—è—é—Ç—Å—è
    CircuitHalfOpen                      // –ü—Ä–æ–±–Ω—ã–π –∑–∞–ø—Ä–æ—Å
)

var ErrCircuitOpen = errors.New("circuit breaker is open")

type CircuitBreaker struct {
    mu              sync.RWMutex
    state           CircuitState
    failures        int
    successes       int
    threshold       int           // –ü–æ—Ä–æ–≥ –æ—à–∏–±–æ–∫ –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è
    halfOpenMax     int           // –ú–∞–∫—Å. –ø—Ä–æ–±–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    resetTimeout    time.Duration // –í—Ä–µ–º—è –¥–æ –ø–µ—Ä–µ—Ö–æ–¥–∞ –≤ half-open
    lastFailureTime time.Time
}

func NewCircuitBreaker(threshold int, resetTimeout time.Duration) *CircuitBreaker {
    return &CircuitBreaker{
        state:        CircuitClosed,
        threshold:    threshold,
        halfOpenMax:  3,
        resetTimeout: resetTimeout,
    }
}

func (cb *CircuitBreaker) Execute(ctx context.Context, fn func(ctx context.Context) error) error {
    if !cb.allowRequest() {
        return ErrCircuitOpen
    }

    err := fn(ctx)

    if err != nil {
        cb.recordFailure()
    } else {
        cb.recordSuccess()
    }

    return err
}

func (cb *CircuitBreaker) allowRequest() bool {
    cb.mu.RLock()
    defer cb.mu.RUnlock()

    switch cb.state {
    case CircuitClosed:
        return true
    case CircuitOpen:
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–æ—à–ª–æ –ª–∏ –≤—Ä–µ–º—è –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞ –≤ half-open
        if time.Since(cb.lastFailureTime) > cb.resetTimeout {
            cb.mu.RUnlock()
            cb.mu.Lock()
            cb.state = CircuitHalfOpen
            cb.successes = 0
            cb.mu.Unlock()
            cb.mu.RLock()
            return true
        }
        return false
    case CircuitHalfOpen:
        return cb.successes < cb.halfOpenMax
    }

    return false
}

func (cb *CircuitBreaker) recordFailure() {
    cb.mu.Lock()
    defer cb.mu.Unlock()

    cb.failures++
    cb.lastFailureTime = time.Now()

    if cb.failures >= cb.threshold {
        cb.state = CircuitOpen
    }
}

func (cb *CircuitBreaker) recordSuccess() {
    cb.mu.Lock()
    defer cb.mu.Unlock()

    if cb.state == CircuitHalfOpen {
        cb.successes++
        if cb.successes >= cb.halfOpenMax {
            cb.state = CircuitClosed
            cb.failures = 0
        }
    } else {
        cb.failures = 0
    }
}

func (cb *CircuitBreaker) State() CircuitState {
    cb.mu.RLock()
    defer cb.mu.RUnlock()
    return cb.state
}
```

```go
// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å –ø—É–ª–æ–º
type ResilientPool struct {
    pool    *pgxpool.Pool
    breaker *CircuitBreaker
    retry   RetryConfig
}

func (p *ResilientPool) QueryRow(ctx context.Context, sql string, args ...any) pgx.Row {
    // Circuit breaker + retry
    var row pgx.Row
    err := p.breaker.Execute(ctx, func(ctx context.Context) error {
        _, retryErr := WithRetry(ctx, p.retry, func(ctx context.Context) (struct{}, error) {
            row = p.pool.QueryRow(ctx, sql, args...)
            // QueryRow –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—à–∏–±–∫—É —Å—Ä–∞–∑—É ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏ Scan
            return struct{}{}, nil
        })
        return retryErr
    })
    if err != nil {
        // –í–æ–∑–≤—Ä–∞—â–∞–µ–º row, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–∏ Scan –≤–µ—Ä–Ω—ë—Ç –æ—à–∏–±–∫—É
        return &errorRow{err: err}
    }
    return row
}
```

---

## Security

### SSL/TLS Connections

–í production **–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ** –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ TLS –¥–ª—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å PostgreSQL.

```go
import (
    "crypto/tls"
    "crypto/x509"
    "os"

    "github.com/jackc/pgx/v5/pgxpool"
)

func NewSecurePool(ctx context.Context, cfg Config) (*pgxpool.Pool, error) {
    poolConfig, err := pgxpool.ParseConfig(cfg.ConnectionString())
    if err != nil {
        return nil, err
    }

    // –í–∞—Ä–∏–∞–Ω—Ç 1: Verify-full (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
    // –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç —Å–µ—Ä–≤–µ—Ä–∞ –∏ hostname
    certPool := x509.NewCertPool()
    caCert, err := os.ReadFile(cfg.CACertFile)
    if err != nil {
        return nil, fmt.Errorf("read CA cert: %w", err)
    }
    certPool.AppendCertsFromPEM(caCert)

    poolConfig.ConnConfig.TLSConfig = &tls.Config{
        ServerName: cfg.Host,
        RootCAs:    certPool,
        MinVersion: tls.VersionTLS12,
    }

    // –í–∞—Ä–∏–∞–Ω—Ç 2: Client certificate authentication (mTLS)
    if cfg.ClientCertFile != "" && cfg.ClientKeyFile != "" {
        clientCert, err := tls.LoadX509KeyPair(cfg.ClientCertFile, cfg.ClientKeyFile)
        if err != nil {
            return nil, fmt.Errorf("load client cert: %w", err)
        }
        poolConfig.ConnConfig.TLSConfig.Certificates = []tls.Certificate{clientCert}
    }

    return pgxpool.NewWithConfig(ctx, poolConfig)
}
```

### SSL Mode —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ

| sslmode | –ó–∞—â–∏—Ç–∞ | Production |
|---------|--------|------------|
| `disable` | –ù–µ—Ç —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è | ‚ùå –ù–∏–∫–æ–≥–¥–∞ |
| `allow` | –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ | ‚ùå –ù–µ–Ω–∞–¥—ë–∂–Ω–æ |
| `prefer` | –ü—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ–µ (default) | ‚ö†Ô∏è –ù–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç |
| `require` | –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ, –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ | ‚ö†Ô∏è Man-in-the-middle |
| `verify-ca` | –ü—Ä–æ–≤–µ—Ä–∫–∞ CA | ‚úÖ –•–æ—Ä–æ—à–æ |
| `verify-full` | –ü—Ä–æ–≤–µ—Ä–∫–∞ CA + hostname | ‚úÖ –õ—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç |

> ‚ö†Ô∏è **–ö—Ä–∏—Ç–∏—á–Ω–æ**: –í production –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `verify-ca` –∏–ª–∏ `verify-full`. `prefer` –∏ `require` –Ω–µ –∑–∞—â–∏—â–∞—é—Ç –æ—Ç man-in-the-middle –∞—Ç–∞–∫.

### Row-Level Security

RLS –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ —Å—Ç—Ä–æ–∫–∞–º –Ω–∞ —É—Ä–æ–≤–Ω–µ –ë–î ‚Äî –∏–¥–µ–∞–ª—å–Ω–æ –¥–ª—è multi-tenant –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π.

```sql
-- –í–∫–ª—é—á–∞–µ–º RLS –Ω–∞ —Ç–∞–±–ª–∏—Ü–µ
ALTER TABLE orders ENABLE ROW LEVEL SECURITY;

-- –ü–æ–ª–∏—Ç–∏–∫–∞: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –≤–∏–¥—è—Ç —Ç–æ–ª—å–∫–æ —Å–≤–æ–∏ –∑–∞–∫–∞–∑—ã
CREATE POLICY user_orders ON orders
    USING (user_id = current_setting('app.current_user_id')::int);

-- –ü–æ–ª–∏—Ç–∏–∫–∞: tenant isolation
CREATE POLICY tenant_isolation ON orders
    USING (tenant_id = current_setting('app.tenant_id')::int);

-- –ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –¥–∞–∂–µ –∫ owner (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é owner –æ–±—Ö–æ–¥–∏—Ç RLS)
ALTER TABLE orders FORCE ROW LEVEL SECURITY;
```

```go
// Middleware –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ tenant_id
type TenantMiddleware struct {
    pool *pgxpool.Pool
}

func (m *TenantMiddleware) WithTenant(ctx context.Context, tenantID int64) *pgxpool.Pool {
    // ‚ö†Ô∏è –ù–µ–ª—å–∑—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SET –¥–ª—è pool ‚Äî –æ–Ω shared!
    // –ò—Å–ø–æ–ª—å–∑—É–µ–º AfterConnect –∏–ª–∏ per-connection setup
    return m.pool
}

// –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥: —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º tenant_id –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
func (r *OrderRepository) ListForTenant(ctx context.Context, tenantID int64) ([]Order, error) {
    conn, err := r.pool.Acquire(ctx)
    if err != nil {
        return nil, err
    }
    defer conn.Release()

    // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º tenant_id –¥–ª—è —ç—Ç–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    _, err = conn.Exec(ctx,
        fmt.Sprintf("SET LOCAL app.tenant_id = '%d'", tenantID),
    )
    if err != nil {
        return nil, fmt.Errorf("set tenant: %w", err)
    }

    // –¢–µ–ø–µ—Ä—å RLS –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ
    rows, err := conn.Query(ctx, "SELECT * FROM orders ORDER BY created_at DESC")
    if err != nil {
        return nil, err
    }
    defer rows.Close()

    var orders []Order
    for rows.Next() {
        var o Order
        if err := rows.Scan(&o.ID, &o.TenantID, &o.UserID, &o.TotalAmount); err != nil {
            return nil, err
        }
        orders = append(orders, o)
    }
    return orders, rows.Err()
}

// –õ—É—á—à–∏–π –ø–æ–¥—Ö–æ–¥: —á–µ—Ä–µ–∑ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é
func (r *OrderRepository) WithTenant(ctx context.Context, tenantID int64,
    fn func(ctx context.Context, conn *pgxpool.Conn) error) error {

    conn, err := r.pool.Acquire(ctx)
    if err != nil {
        return err
    }
    defer conn.Release()

    tx, err := conn.Begin(ctx)
    if err != nil {
        return err
    }
    defer tx.Rollback(ctx)

    // SET LOCAL —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —Ä–∞–º–∫–∞—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
    _, err = tx.Exec(ctx,
        fmt.Sprintf("SET LOCAL app.tenant_id = '%d'", tenantID),
    )
    if err != nil {
        return fmt.Errorf("set tenant: %w", err)
    }

    if err := fn(ctx, conn); err != nil {
        return err
    }

    return tx.Commit(ctx)
}
```

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: RLS ‚Äî –∞–Ω–∞–ª–æ–≥ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ query filter –≤ EF Core (`HasQueryFilter`), –Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —É—Ä–æ–≤–Ω–µ –ë–î. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ–±–æ–π—Ç–∏ –∏–∑ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.

```csharp
// EF Core ‚Äî query filter (application-level)
modelBuilder.Entity<Order>()
    .HasQueryFilter(o => o.TenantId == _tenantService.TenantId);
// ‚ö†Ô∏è –ú–æ–∂–Ω–æ –æ–±–æ–π—Ç–∏ —Å IgnoreQueryFilters()

// PostgreSQL RLS ‚Äî database-level
// ‚úÖ –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ–±–æ–π—Ç–∏ –∏–∑ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
```

### Secrets Management

–ù–µ —Ö—Ä–∞–Ω–∏—Ç–µ –ø–∞—Ä–æ–ª–∏ –ë–î –≤ –∫–æ–¥–µ –∏–ª–∏ ENV –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤ –æ—Ç–∫—Ä—ã—Ç–æ–º –≤–∏–¥–µ.

```go
package config

import (
    "context"
    "encoding/json"
    "fmt"
    "os"
    "time"

    "github.com/aws/aws-sdk-go-v2/service/secretsmanager"
)

// DatabaseSecret ‚Äî —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–µ–∫—Ä–µ—Ç–∞ –∏–∑ AWS Secrets Manager / Vault
type DatabaseSecret struct {
    Host     string `json:"host"`
    Port     int    `json:"port"`
    Username string `json:"username"`
    Password string `json:"password"`
    Database string `json:"dbname"`
}

// –í–∞—Ä–∏–∞–Ω—Ç 1: AWS Secrets Manager
func GetDBSecretAWS(ctx context.Context, client *secretsmanager.Client, secretID string) (*DatabaseSecret, error) {
    result, err := client.GetSecretValue(ctx, &secretsmanager.GetSecretValueInput{
        SecretId: &secretID,
    })
    if err != nil {
        return nil, fmt.Errorf("get secret: %w", err)
    }

    var secret DatabaseSecret
    if err := json.Unmarshal([]byte(*result.SecretString), &secret); err != nil {
        return nil, fmt.Errorf("parse secret: %w", err)
    }

    return &secret, nil
}

// –í–∞—Ä–∏–∞–Ω—Ç 2: HashiCorp Vault
func GetDBSecretVault(ctx context.Context, vaultAddr, token, path string) (*DatabaseSecret, error) {
    // –ò—Å–ø–æ–ª—å–∑—É–µ–º vault API
    client, err := vault.New(
        vault.WithAddress(vaultAddr),
        vault.WithRequestTimeout(10*time.Second),
    )
    if err != nil {
        return nil, err
    }

    if err := client.SetToken(token); err != nil {
        return nil, err
    }

    s, err := client.Secrets.KvV2Read(ctx, path, vault.WithMountPath("secret"))
    if err != nil {
        return nil, err
    }

    return &DatabaseSecret{
        Host:     s.Data.Data["host"].(string),
        Port:     int(s.Data.Data["port"].(float64)),
        Username: s.Data.Data["username"].(string),
        Password: s.Data.Data["password"].(string),
        Database: s.Data.Data["dbname"].(string),
    }, nil
}

// –í–∞—Ä–∏–∞–Ω—Ç 3: Kubernetes Secrets (—Å–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π)
func GetDBSecretK8s() (*DatabaseSecret, error) {
    // K8s –º–æ–Ω—Ç–∏—Ä—É–µ—Ç —Å–µ–∫—Ä–µ—Ç—ã –∫–∞–∫ —Ñ–∞–π–ª—ã –∏–ª–∏ ENV
    return &DatabaseSecret{
        Host:     os.Getenv("DB_HOST"),
        Port:     5432,
        Username: os.Getenv("DB_USER"),
        Password: readFileOrEnv("/run/secrets/db-password", "DB_PASSWORD"),
        Database: os.Getenv("DB_NAME"),
    }, nil
}

func readFileOrEnv(filePath, envKey string) string {
    data, err := os.ReadFile(filePath)
    if err == nil {
        return strings.TrimSpace(string(data))
    }
    return os.Getenv(envKey)
}
```

### –†–æ—Ç–∞—Ü–∏—è —Å–µ–∫—Ä–µ—Ç–æ–≤

```go
// –ü—É–ª —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º credentials
type RotatingPool struct {
    mu          sync.RWMutex
    pool        *pgxpool.Pool
    secretFunc  func(ctx context.Context) (*DatabaseSecret, error)
    refreshEvery time.Duration
}

func NewRotatingPool(ctx context.Context,
    secretFunc func(ctx context.Context) (*DatabaseSecret, error),
    refreshEvery time.Duration,
) (*RotatingPool, error) {
    rp := &RotatingPool{
        secretFunc:   secretFunc,
        refreshEvery: refreshEvery,
    }

    // –°–æ–∑–¥–∞—ë–º –Ω–∞—á–∞–ª—å–Ω—ã–π –ø—É–ª
    if err := rp.refresh(ctx); err != nil {
        return nil, err
    }

    // –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
    go rp.rotateLoop(ctx)

    return rp, nil
}

func (rp *RotatingPool) Pool() *pgxpool.Pool {
    rp.mu.RLock()
    defer rp.mu.RUnlock()
    return rp.pool
}

func (rp *RotatingPool) refresh(ctx context.Context) error {
    secret, err := rp.secretFunc(ctx)
    if err != nil {
        return err
    }

    dsn := fmt.Sprintf("postgres://%s:%s@%s:%d/%s?sslmode=verify-ca",
        secret.Username, secret.Password, secret.Host, secret.Port, secret.Database)

    newPool, err := pgxpool.New(ctx, dsn)
    if err != nil {
        return err
    }

    rp.mu.Lock()
    oldPool := rp.pool
    rp.pool = newPool
    rp.mu.Unlock()

    // –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å—Ç–∞—Ä—ã–π –ø—É–ª –ø–æ—Å–ª–µ –ø–µ—Ä–µ—Ö–æ–¥–∞
    if oldPool != nil {
        go func() {
            time.Sleep(30 * time.Second) // –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            oldPool.Close()
        }()
    }

    return nil
}

func (rp *RotatingPool) rotateLoop(ctx context.Context) {
    ticker := time.NewTicker(rp.refreshEvery)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            if err := rp.refresh(ctx); err != nil {
                slog.Error("failed to rotate DB credentials",
                    slog.String("error", err.Error()),
                )
            }
        }
    }
}
```

---

## Observability –¥–ª—è PostgreSQL

### –ú–µ—Ç—Ä–∏–∫–∏ pg_stat_*

PostgreSQL –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞.

```go
package pgmetrics

import (
    "context"

    "github.com/jackc/pgx/v5/pgxpool"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    dbSize = promauto.NewGauge(prometheus.GaugeOpts{
        Name: "postgresql_database_size_bytes",
        Help: "Database size in bytes",
    })

    tableRows = promauto.NewGaugeVec(prometheus.GaugeOpts{
        Name: "postgresql_table_rows_estimate",
        Help: "Estimated number of rows in table",
    }, []string{"table"})

    cacheHitRatio = promauto.NewGauge(prometheus.GaugeOpts{
        Name: "postgresql_cache_hit_ratio",
        Help: "Buffer cache hit ratio",
    })

    activeConnections = promauto.NewGauge(prometheus.GaugeOpts{
        Name: "postgresql_active_connections",
        Help: "Number of active connections",
    })

    deadTuples = promauto.NewGaugeVec(prometheus.GaugeOpts{
        Name: "postgresql_dead_tuples",
        Help: "Number of dead tuples (need VACUUM)",
    }, []string{"table"})

    replicationLag = promauto.NewGauge(prometheus.GaugeOpts{
        Name: "postgresql_replication_lag_seconds",
        Help: "Replication lag in seconds",
    })

    longRunningQueries = promauto.NewGauge(prometheus.GaugeOpts{
        Name: "postgresql_long_running_queries",
        Help: "Number of queries running longer than 30 seconds",
    })
)

// PGCollector —Å–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ PostgreSQL
type PGCollector struct {
    pool *pgxpool.Pool
}

func NewPGCollector(pool *pgxpool.Pool) *PGCollector {
    return &PGCollector{pool: pool}
}

func (c *PGCollector) Collect(ctx context.Context) error {
    // Database size
    var size int64
    if err := c.pool.QueryRow(ctx,
        "SELECT pg_database_size(current_database())").Scan(&size); err != nil {
        return err
    }
    dbSize.Set(float64(size))

    // Cache hit ratio
    var ratio float64
    if err := c.pool.QueryRow(ctx, `
        SELECT
            CASE WHEN (blks_hit + blks_read) = 0 THEN 0
            ELSE blks_hit::float / (blks_hit + blks_read)
            END
        FROM pg_stat_database
        WHERE datname = current_database()
    `).Scan(&ratio); err != nil {
        return err
    }
    cacheHitRatio.Set(ratio)

    // Active connections
    var active int
    if err := c.pool.QueryRow(ctx, `
        SELECT count(*) FROM pg_stat_activity
        WHERE state = 'active' AND pid != pg_backend_pid()
    `).Scan(&active); err != nil {
        return err
    }
    activeConnections.Set(float64(active))

    // Table stats
    rows, err := c.pool.Query(ctx, `
        SELECT
            schemaname || '.' || relname as table_name,
            n_live_tup,
            n_dead_tup
        FROM pg_stat_user_tables
        ORDER BY n_dead_tup DESC
        LIMIT 50
    `)
    if err != nil {
        return err
    }
    defer rows.Close()

    for rows.Next() {
        var tableName string
        var liveTup, deadTup int64
        if err := rows.Scan(&tableName, &liveTup, &deadTup); err != nil {
            return err
        }
        tableRows.WithLabelValues(tableName).Set(float64(liveTup))
        deadTuples.WithLabelValues(tableName).Set(float64(deadTup))
    }

    // Long running queries
    var longQueries int
    if err := c.pool.QueryRow(ctx, `
        SELECT count(*) FROM pg_stat_activity
        WHERE state = 'active'
          AND now() - query_start > interval '30 seconds'
          AND pid != pg_backend_pid()
    `).Scan(&longQueries); err != nil {
        return err
    }
    longRunningQueries.Set(float64(longQueries))

    // Replication lag (–µ—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–ø–ª–∏–∫–∏)
    var lag *float64
    _ = c.pool.QueryRow(ctx, `
        SELECT EXTRACT(EPOCH FROM replay_lag)
        FROM pg_stat_replication
        LIMIT 1
    `).Scan(&lag)
    if lag != nil {
        replicationLag.Set(*lag)
    }

    return nil
}

// StartCollector –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π —Å–±–æ—Ä –º–µ—Ç—Ä–∏–∫
func StartCollector(ctx context.Context, pool *pgxpool.Pool, interval time.Duration) {
    collector := NewPGCollector(pool)
    ticker := time.NewTicker(interval)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            if err := collector.Collect(ctx); err != nil {
                slog.Error("metrics collection failed",
                    slog.String("error", err.Error()),
                )
            }
        }
    }
}
```

### Prometheus Integration

```go
// –ü–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä —Å HTTP endpoint
package main

import (
    "net/http"

    "github.com/prometheus/client_golang/prometheus/promhttp"
)

func main() {
    pool, _ := NewPool(ctx, cfg)

    // –ó–∞–ø—É—Å–∫ —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫
    go StartCollector(ctx, pool, 15*time.Second)

    // –ó–∞–ø—É—Å–∫ pool monitor
    monitor := NewPoolMonitor(pool, slog.Default())
    go monitor.Start(ctx)

    // Prometheus endpoint
    http.Handle("/metrics", promhttp.Handler())
    http.ListenAndServe(":9090", nil)
}
```

### –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∞–ª–µ—Ä—Ç–æ–≤

```yaml
# Prometheus alerting rules
groups:
  - name: postgresql
    rules:
      # –ù–∏–∑–∫–∏–π cache hit ratio
      - alert: PostgreSQLLowCacheHitRatio
        expr: postgresql_cache_hit_ratio < 0.95
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low buffer cache hit ratio"

      # –ú–Ω–æ–≥–æ dead tuples (–Ω—É–∂–µ–Ω VACUUM)
      - alert: PostgreSQLHighDeadTuples
        expr: postgresql_dead_tuples > 100000
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Table {{ $labels.table }} needs VACUUM"

      # –î–æ–ª–≥–∏–µ –∑–∞–ø—Ä–æ—Å—ã
      - alert: PostgreSQLLongRunningQueries
        expr: postgresql_long_running_queries > 0
        for: 1m
        labels:
          severity: critical

      # –í—ã—Å–æ–∫–∞—è —É—Ç–∏–ª–∏–∑–∞—Ü–∏—è –ø—É–ª–∞
      - alert: PostgreSQLPoolNearCapacity
        expr: db_pool_connections_total{state="acquired"} / db_pool_connections_total{state="max"} > 0.8
        for: 5m
        labels:
          severity: warning

      # Replication lag
      - alert: PostgreSQLReplicationLag
        expr: postgresql_replication_lag_seconds > 10
        for: 2m
        labels:
          severity: critical
```

### OpenTelemetry Instrumentation

–ü–æ–ª–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è pgx —Å OpenTelemetry –¥–ª—è distributed tracing.

```go
package otel

import (
    "context"

    "github.com/jackc/pgx/v5"
    "github.com/jackc/pgx/v5/pgxpool"
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/codes"
    semconv "go.opentelemetry.io/otel/semconv/v1.21.0"
    "go.opentelemetry.io/otel/trace"
)

// PgxTracer —Ä–µ–∞–ª–∏–∑—É–µ—Ç –ø–æ–ª–Ω—ã–π OpenTelemetry instrumentation –¥–ª—è pgx
type PgxTracer struct {
    tracer trace.Tracer
    dbName string
}

func NewPgxTracer(dbName string) *PgxTracer {
    return &PgxTracer{
        tracer: otel.Tracer("github.com/myapp/pgx"),
        dbName: dbName,
    }
}

// TraceQueryStart ‚Äî –Ω–∞—á–∞–ª–æ –∑–∞–ø—Ä–æ—Å–∞
func (t *PgxTracer) TraceQueryStart(
    ctx context.Context,
    conn *pgx.Conn,
    data pgx.TraceQueryStartData,
) context.Context {
    attrs := []attribute.KeyValue{
        semconv.DBSystemPostgreSQL,
        semconv.DBName(t.dbName),
        semconv.DBStatement(data.SQL),
        semconv.DBUser(conn.Config().User),
        attribute.String("db.postgresql.host", conn.Config().Host),
        attribute.Int("db.postgresql.port", int(conn.Config().Port)),
    }

    ctx, _ = t.tracer.Start(ctx, "postgresql.query",
        trace.WithSpanKind(trace.SpanKindClient),
        trace.WithAttributes(attrs...),
    )

    return ctx
}

// TraceQueryEnd ‚Äî –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
func (t *PgxTracer) TraceQueryEnd(
    ctx context.Context,
    conn *pgx.Conn,
    data pgx.TraceQueryEndData,
) {
    span := trace.SpanFromContext(ctx)
    defer span.End()

    span.SetAttributes(
        attribute.Int64("db.rows_affected", data.CommandTag.RowsAffected()),
        attribute.String("db.command_tag", data.CommandTag.String()),
    )

    if data.Err != nil {
        span.RecordError(data.Err)
        span.SetStatus(codes.Error, data.Err.Error())
    } else {
        span.SetStatus(codes.Ok, "")
    }
}

// TraceBatchStart ‚Äî –Ω–∞—á–∞–ª–æ batch
func (t *PgxTracer) TraceBatchStart(
    ctx context.Context,
    conn *pgx.Conn,
    data pgx.TraceBatchStartData,
) context.Context {
    ctx, _ = t.tracer.Start(ctx, "postgresql.batch",
        trace.WithSpanKind(trace.SpanKindClient),
        trace.WithAttributes(
            semconv.DBSystemPostgreSQL,
            attribute.Int("db.batch.size", data.Batch.Len()),
        ),
    )
    return ctx
}

// TraceBatchEnd ‚Äî –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ batch
func (t *PgxTracer) TraceBatchEnd(
    ctx context.Context,
    conn *pgx.Conn,
    data pgx.TraceBatchEndData,
) {
    span := trace.SpanFromContext(ctx)
    defer span.End()

    if data.Err != nil {
        span.RecordError(data.Err)
        span.SetStatus(codes.Error, data.Err.Error())
    }
}

// –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ –ø—É–ª—É
func NewInstrumentedPool(ctx context.Context, dsn, dbName string) (*pgxpool.Pool, error) {
    poolConfig, err := pgxpool.ParseConfig(dsn)
    if err != nil {
        return nil, err
    }

    poolConfig.ConnConfig.Tracer = NewPgxTracer(dbName)

    return pgxpool.NewWithConfig(ctx, poolConfig)
}
```

> üí° **–î–ª—è C# —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤**: –í .NET –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `DiagnosticSource` –∏ `Activity` (System.Diagnostics) –¥–ª—è —Ç—Ä–µ–π—Å–∏–Ω–≥–∞ SQL. –í Go ‚Äî —è–≤–Ω—ã–π tracer interface, —á—Ç–æ –¥–∞—ë—Ç –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ —Ç–µ–º, –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–±–∏—Ä–∞—é—Ç—Å—è.

---

## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã

### –ü—Ä–∏–º–µ—Ä 1: Production-Ready Connection Setup

–ü–æ–ª–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ PostgreSQL –¥–ª—è production —Å–µ—Ä–≤–∏—Å–∞.

```go
package main

import (
    "context"
    "crypto/tls"
    "crypto/x509"
    "fmt"
    "log/slog"
    "os"
    "strconv"
    "time"

    "github.com/jackc/pgx/v5"
    "github.com/jackc/pgx/v5/pgxpool"
)

// AppConfig ‚Äî –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
type AppConfig struct {
    DB DBConfig
}

type DBConfig struct {
    Host     string
    Port     int
    User     string
    Password string
    Database string

    // Pool
    MaxConns        int32
    MinConns        int32
    MaxConnLifetime time.Duration
    MaxConnIdleTime time.Duration

    // SSL
    SSLMode    string
    CACertPath string

    // Timeouts
    ConnectTimeout   time.Duration
    StatementTimeout time.Duration
}

func LoadDBConfig() DBConfig {
    return DBConfig{
        Host:     getEnv("DB_HOST", "localhost"),
        Port:     getEnvInt("DB_PORT", 5432),
        User:     getEnv("DB_USER", "app"),
        Password: getEnv("DB_PASSWORD", ""),
        Database: getEnv("DB_NAME", "myapp"),

        MaxConns:        int32(getEnvInt("DB_MAX_CONNS", 50)),
        MinConns:        int32(getEnvInt("DB_MIN_CONNS", 10)),
        MaxConnLifetime: time.Hour,
        MaxConnIdleTime: 30 * time.Minute,

        SSLMode:    getEnv("DB_SSL_MODE", "verify-ca"),
        CACertPath: getEnv("DB_CA_CERT", ""),

        ConnectTimeout:   10 * time.Second,
        StatementTimeout: 30 * time.Second,
    }
}

func NewProductionPool(ctx context.Context, cfg DBConfig, logger *slog.Logger) (*pgxpool.Pool, error) {
    dsn := fmt.Sprintf(
        "postgres://%s:%s@%s:%d/%s?sslmode=%s",
        cfg.User, cfg.Password, cfg.Host, cfg.Port, cfg.Database, cfg.SSLMode,
    )

    poolConfig, err := pgxpool.ParseConfig(dsn)
    if err != nil {
        return nil, fmt.Errorf("parse config: %w", err)
    }

    // --- Pool settings ---
    poolConfig.MaxConns = cfg.MaxConns
    poolConfig.MinConns = cfg.MinConns
    poolConfig.MaxConnLifetime = cfg.MaxConnLifetime
    poolConfig.MaxConnIdleTime = cfg.MaxConnIdleTime
    poolConfig.HealthCheckPeriod = time.Minute

    // --- Connection settings ---
    poolConfig.ConnConfig.ConnectTimeout = cfg.ConnectTimeout
    poolConfig.ConnConfig.RuntimeParams = map[string]string{
        "application_name":  "myapp",
        "statement_timeout": fmt.Sprintf("%dms", cfg.StatementTimeout.Milliseconds()),
        "lock_timeout":      "10s",
        "idle_in_transaction_session_timeout": "60s",
        "timezone": "UTC",
    }

    // --- TLS ---
    if cfg.CACertPath != "" {
        certPool := x509.NewCertPool()
        caCert, err := os.ReadFile(cfg.CACertPath)
        if err != nil {
            return nil, fmt.Errorf("read CA cert: %w", err)
        }
        certPool.AppendCertsFromPEM(caCert)

        poolConfig.ConnConfig.TLSConfig = &tls.Config{
            ServerName: cfg.Host,
            RootCAs:    certPool,
            MinVersion: tls.VersionTLS12,
        }
    }

    // --- Tracing ---
    poolConfig.ConnConfig.Tracer = &LoggingTracer{logger: logger}

    // --- Hooks ---
    poolConfig.AfterConnect = func(ctx context.Context, conn *pgx.Conn) error {
        logger.Info("new db connection established")
        return nil
    }

    poolConfig.BeforeAcquire = func(ctx context.Context, conn *pgx.Conn) bool {
        return !conn.IsClosed()
    }

    // --- Create pool ---
    pool, err := pgxpool.NewWithConfig(ctx, poolConfig)
    if err != nil {
        return nil, fmt.Errorf("create pool: %w", err)
    }

    // --- Verify ---
    if err := pool.Ping(ctx); err != nil {
        pool.Close()
        return nil, fmt.Errorf("ping: %w", err)
    }

    // --- Warm pool ---
    warmConns := min(5, int(cfg.MinConns))
    conns := make([]*pgxpool.Conn, 0, warmConns)
    for i := 0; i < warmConns; i++ {
        c, err := pool.Acquire(ctx)
        if err != nil {
            break
        }
        conns = append(conns, c)
    }
    for _, c := range conns {
        c.Release()
    }

    logger.Info("database pool ready",
        slog.Int("warm_connections", len(conns)),
        slog.Int32("max_connections", cfg.MaxConns),
    )

    return pool, nil
}

func getEnv(key, fallback string) string {
    if v := os.Getenv(key); v != "" {
        return v
    }
    return fallback
}

func getEnvInt(key string, fallback int) int {
    if v := os.Getenv(key); v != "" {
        if i, err := strconv.Atoi(v); err == nil {
            return i
        }
    }
    return fallback
}
```

### –ü—Ä–∏–º–µ—Ä 2: Zero-Downtime Migration

–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø–æ–ª—è –∫ —Ç–∞–±–ª–∏—Ü–µ —Å –º–∏–ª–ª–∏–æ–Ω–∞–º–∏ –∑–∞–ø–∏—Å–µ–π –±–µ–∑ –¥–∞—É–Ω—Ç–∞–π–º–∞.

```go
// cmd/migrate/add_user_preferences.go
//
// –ó–∞–¥–∞—á–∞: –¥–æ–±–∞–≤–∏—Ç—å –∫–æ–ª–æ–Ω–∫—É preferences JSONB NOT NULL —Å default –∑–Ω–∞—á–µ–Ω–∏–µ–º
// –∫ —Ç–∞–±–ª–∏—Ü–µ users (5 –º–ª–Ω –∑–∞–ø–∏—Å–µ–π)
//
// –°—Ç—Ä–∞—Ç–µ–≥–∏—è: 3-step migration

package main

import (
    "context"
    "fmt"
    "log/slog"
    "time"

    "github.com/jackc/pgx/v5/pgxpool"
)

func main() {
    ctx := context.Background()
    pool, _ := pgxpool.New(ctx, os.Getenv("DATABASE_URL"))
    defer pool.Close()

    logger := slog.Default()

    // –®–∞–≥ 1: –î–æ–±–∞–≤–∏—Ç—å nullable –∫–æ–ª–æ–Ω–∫—É (–º–≥–Ω–æ–≤–µ–Ω–Ω–æ)
    logger.Info("Step 1: Adding nullable column")
    _, err := pool.Exec(ctx, `
        ALTER TABLE users ADD COLUMN IF NOT EXISTS preferences JSONB;
    `)
    if err != nil {
        logger.Error("step 1 failed", slog.String("error", err.Error()))
        return
    }
    logger.Info("Step 1 complete")

    // –®–∞–≥ 2: Backfill –¥–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–∞–º–∏
    logger.Info("Step 2: Backfilling data")
    defaultPrefs := `{"theme": "light", "notifications": true, "locale": "en"}`

    totalUpdated := int64(0)
    batchSize := 5000

    for {
        result, err := pool.Exec(ctx, `
            UPDATE users
            SET preferences = $1::jsonb
            WHERE id IN (
                SELECT id FROM users
                WHERE preferences IS NULL
                LIMIT $2
                FOR UPDATE SKIP LOCKED
            )
        `, defaultPrefs, batchSize)
        if err != nil {
            logger.Error("backfill batch failed", slog.String("error", err.Error()))
            return
        }

        rowsAffected := result.RowsAffected()
        totalUpdated += rowsAffected

        logger.Info("backfill progress",
            slog.Int64("batch_rows", rowsAffected),
            slog.Int64("total_updated", totalUpdated),
        )

        if rowsAffected == 0 {
            break
        }

        // –ü–∞—É–∑–∞, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å –ë–î
        time.Sleep(50 * time.Millisecond)
    }
    logger.Info("Step 2 complete", slog.Int64("total_rows", totalUpdated))

    // –®–∞–≥ 3: –î–æ–±–∞–≤–∏—Ç—å NOT NULL constraint
    logger.Info("Step 3: Adding NOT NULL constraint")

    // 3a. –î–æ–±–∞–≤–ª—è–µ–º CHECK constraint (NOT VALID ‚Äî –±–µ–∑ —Å–∫–∞–Ω–∞)
    _, err = pool.Exec(ctx, `
        ALTER TABLE users ADD CONSTRAINT users_preferences_not_null
            CHECK (preferences IS NOT NULL) NOT VALID;
    `)
    if err != nil {
        logger.Error("step 3a failed", slog.String("error", err.Error()))
        return
    }

    // 3b. –í–∞–ª–∏–¥–∏—Ä—É–µ–º constraint (ShareUpdateExclusiveLock ‚Äî –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç –∑–∞–ø–∏—Å—å)
    _, err = pool.Exec(ctx, `
        ALTER TABLE users VALIDATE CONSTRAINT users_preferences_not_null;
    `)
    if err != nil {
        logger.Error("step 3b failed", slog.String("error", err.Error()))
        return
    }

    // 3c. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π NOT NULL –∏ —É–¥–∞–ª—è–µ–º CHECK
    _, err = pool.Exec(ctx, `
        ALTER TABLE users ALTER COLUMN preferences SET NOT NULL;
        ALTER TABLE users DROP CONSTRAINT users_preferences_not_null;
    `)
    if err != nil {
        logger.Error("step 3c failed", slog.String("error", err.Error()))
        return
    }

    // 3d. –î–æ–±–∞–≤–ª—è–µ–º DEFAULT –¥–ª—è –Ω–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫
    _, err = pool.Exec(ctx, fmt.Sprintf(`
        ALTER TABLE users ALTER COLUMN preferences SET DEFAULT '%s'::jsonb;
    `, defaultPrefs))
    if err != nil {
        logger.Error("step 3d failed", slog.String("error", err.Error()))
        return
    }

    logger.Info("Migration complete! Column 'preferences' is now NOT NULL with default")
}
```

### –ü—Ä–∏–º–µ—Ä 3: Read Replica Routing

–ü–æ–ª–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –º–µ–∂–¥—É primary –∏ replicas.

```go
package postgres

import (
    "context"
    "fmt"
    "log/slog"
    "sync/atomic"
    "time"

    "github.com/jackc/pgx/v5/pgxpool"
)

// ClusterConfig ‚Äî –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–∞
type ClusterConfig struct {
    PrimaryDSN   string
    ReplicaDSNs  []string
    MaxConns     int32
    MinConns     int32
    HealthCheck  time.Duration
}

// Cluster —É–ø—Ä–∞–≤–ª—è–µ—Ç primary –∏ replica –ø—É–ª–∞–º–∏
type Cluster struct {
    primary  *pgxpool.Pool
    replicas []*pgxpool.Pool
    healthy  []atomic.Bool
    counter  atomic.Uint64
    logger   *slog.Logger
}

func NewCluster(ctx context.Context, cfg ClusterConfig, logger *slog.Logger) (*Cluster, error) {
    // Primary
    primaryCfg, err := pgxpool.ParseConfig(cfg.PrimaryDSN)
    if err != nil {
        return nil, fmt.Errorf("parse primary config: %w", err)
    }
    primaryCfg.MaxConns = cfg.MaxConns
    primaryCfg.MinConns = cfg.MinConns

    primary, err := pgxpool.NewWithConfig(ctx, primaryCfg)
    if err != nil {
        return nil, fmt.Errorf("connect primary: %w", err)
    }

    // Replicas
    replicas := make([]*pgxpool.Pool, 0, len(cfg.ReplicaDSNs))
    healthy := make([]atomic.Bool, len(cfg.ReplicaDSNs))

    for i, dsn := range cfg.ReplicaDSNs {
        repCfg, err := pgxpool.ParseConfig(dsn)
        if err != nil {
            closeAll(primary, replicas)
            return nil, fmt.Errorf("parse replica config: %w", err)
        }
        repCfg.MaxConns = cfg.MaxConns / 2 // –†–µ–ø–ª–∏–∫–∏ ‚Äî –º–µ–Ω—å—à–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
        repCfg.MinConns = cfg.MinConns / 2

        replica, err := pgxpool.NewWithConfig(ctx, repCfg)
        if err != nil {
            closeAll(primary, replicas)
            return nil, fmt.Errorf("connect replica %d: %w", i, err)
        }
        replicas = append(replicas, replica)
        healthy[i].Store(true)
    }

    c := &Cluster{
        primary:  primary,
        replicas: replicas,
        healthy:  healthy,
        logger:   logger,
    }

    // –ó–∞–ø—É—Å–∫–∞–µ–º health checks –¥–ª—è —Ä–µ–ø–ª–∏–∫
    if cfg.HealthCheck > 0 {
        go c.healthCheckLoop(ctx, cfg.HealthCheck)
    }

    return c, nil
}

// Writer –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç primary pool (–¥–ª—è INSERT/UPDATE/DELETE)
func (c *Cluster) Writer() *pgxpool.Pool {
    return c.primary
}

// Reader –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–¥–æ—Ä–æ–≤—É—é —Ä–µ–ø–ª–∏–∫—É (round-robin) –∏–ª–∏ primary –∫–∞–∫ fallback
func (c *Cluster) Reader() *pgxpool.Pool {
    if len(c.replicas) == 0 {
        return c.primary
    }

    // Round-robin –ø–æ –∑–¥–æ—Ä–æ–≤—ã–º —Ä–µ–ø–ª–∏–∫–∞–º
    attempts := len(c.replicas)
    for i := 0; i < attempts; i++ {
        idx := c.counter.Add(1) % uint64(len(c.replicas))
        if c.healthy[idx].Load() {
            return c.replicas[idx]
        }
    }

    // –í—Å–µ —Ä–µ–ø–ª–∏–∫–∏ –Ω–µ–∑–¥–æ—Ä–æ–≤—ã ‚Äî fallback –Ω–∞ primary
    c.logger.Warn("all replicas unhealthy, falling back to primary")
    return c.primary
}

func (c *Cluster) healthCheckLoop(ctx context.Context, interval time.Duration) {
    ticker := time.NewTicker(interval)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            c.checkReplicas(ctx)
        }
    }
}

func (c *Cluster) checkReplicas(ctx context.Context) {
    for i, replica := range c.replicas {
        checkCtx, cancel := context.WithTimeout(ctx, 5*time.Second)

        err := replica.Ping(checkCtx)
        cancel()

        wasHealthy := c.healthy[i].Load()
        isHealthy := err == nil

        c.healthy[i].Store(isHealthy)

        // –õ–æ–≥–∏—Ä—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
        if wasHealthy && !isHealthy {
            c.logger.Warn("replica became unhealthy",
                slog.Int("replica", i),
                slog.String("error", err.Error()),
            )
        } else if !wasHealthy && isHealthy {
            c.logger.Info("replica recovered", slog.Int("replica", i))
        }
    }
}

func (c *Cluster) Close() {
    c.primary.Close()
    for _, r := range c.replicas {
        r.Close()
    }
}

func closeAll(primary *pgxpool.Pool, replicas []*pgxpool.Pool) {
    if primary != nil {
        primary.Close()
    }
    for _, r := range replicas {
        r.Close()
    }
}

// --- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ —Å–µ—Ä–≤–∏—Å–µ ---

type OrderService struct {
    cluster *Cluster
}

func NewOrderService(cluster *Cluster) *OrderService {
    return &OrderService{cluster: cluster}
}

func (s *OrderService) Create(ctx context.Context, order Order) (int64, error) {
    // –ó–∞–ø–∏—Å—å ‚Üí primary
    var id int64
    err := s.cluster.Writer().QueryRow(ctx,
        "INSERT INTO orders (user_id, total_amount, status) VALUES ($1, $2, $3) RETURNING id",
        order.UserID, order.TotalAmount, "pending",
    ).Scan(&id)
    return id, err
}

func (s *OrderService) GetByID(ctx context.Context, id int64) (*Order, error) {
    // –ß—Ç–µ–Ω–∏–µ ‚Üí replica (—Å –≤–æ–∑–º–æ–∂–Ω—ã–º –æ—Ç—Å—Ç–∞–≤–∞–Ω–∏–µ–º)
    var o Order
    err := s.cluster.Reader().QueryRow(ctx,
        "SELECT id, user_id, total_amount, status, created_at FROM orders WHERE id = $1",
        id,
    ).Scan(&o.ID, &o.UserID, &o.TotalAmount, &o.Status, &o.CreatedAt)
    if err != nil {
        return nil, err
    }
    return &o, nil
}

func (s *OrderService) GetByIDConsistent(ctx context.Context, id int64) (*Order, error) {
    // –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–µ —á—Ç–µ–Ω–∏–µ ‚Üí primary (–∫–æ–≥–¥–∞ –Ω—É–∂–Ω—ã —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ)
    var o Order
    err := s.cluster.Writer().QueryRow(ctx,
        "SELECT id, user_id, total_amount, status, created_at FROM orders WHERE id = $1",
        id,
    ).Scan(&o.ID, &o.UserID, &o.TotalAmount, &o.Status, &o.CreatedAt)
    if err != nil {
        return nil, err
    }
    return &o, nil
}

func (s *OrderService) List(ctx context.Context, limit, offset int) ([]Order, error) {
    // –°–ø–∏—Å–æ–∫ ‚Üí replica
    rows, err := s.cluster.Reader().Query(ctx,
        "SELECT id, user_id, total_amount, status, created_at FROM orders ORDER BY created_at DESC LIMIT $1 OFFSET $2",
        limit, offset,
    )
    if err != nil {
        return nil, err
    }
    defer rows.Close()

    var orders []Order
    for rows.Next() {
        var o Order
        if err := rows.Scan(&o.ID, &o.UserID, &o.TotalAmount, &o.Status, &o.CreatedAt); err != nil {
            return nil, err
        }
        orders = append(orders, o)
    }
    return orders, rows.Err()
}
```

---

## –ß–µ–∫-–ª–∏—Å—Ç

–ü–æ—Å–ª–µ –∏–∑—É—á–µ–Ω–∏—è —ç—Ç–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ –≤—ã –¥–æ–ª–∂–Ω—ã:

### Connection & Configuration
- [ ] –£–º–µ—Ç—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å pgxpool —Å production-–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (timeouts, pool size, health checks)
- [ ] –ó–Ω–∞—Ç—å Runtime Parameters –∏ –∫–æ–≥–¥–∞ –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
- [ ] –ü–æ–Ω–∏–º–∞—Ç—å —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É pgxpool –∏ PgBouncer
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å connection warming –∏ graceful shutdown
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—É–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π

### pgx Advanced
- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pgtype –¥–ª—è PostgreSQL-specific —Ç–∏–ø–æ–≤
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å QueryTracer –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Ç—Ä–µ–π—Å–∏–Ω–≥–∞
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å AfterConnect, BeforeAcquire, AfterRelease hooks
- [ ] –ü–æ–Ω–∏–º–∞—Ç—å —Ä–µ–∂–∏–º—ã prepared statement cache –∏ –∏—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å PgBouncer

### sqlc Advanced
- [ ] –ü–∏—Å–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ SQL –∑–∞–ø—Ä–æ—Å—ã (CTE, window functions, recursive CTE)
- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å sqlc.narg() –¥–ª—è optional filters
- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å sqlc.slice() –¥–ª—è array –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ —á–µ—Ä–µ–∑ WithTx –∏ TxManager
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å custom types –∏ overrides –≤ sqlc.yaml

### Migrations
- [ ] –ü–æ–Ω–∏–º–∞—Ç—å, –∫–∞–∫–∏–µ ALTER TABLE –æ–ø–µ—Ä–∞—Ü–∏–∏ –±–ª–æ–∫–∏—Ä—É—é—Ç —Ç–∞–±–ª–∏—Ü—É
- [ ] –ü—Ä–∏–º–µ–Ω—è—Ç—å 3-step pattern –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è NOT NULL –∫–æ–ª–æ–Ω–æ–∫
- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CREATE INDEX CONCURRENTLY
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Expand/Contract pattern –¥–ª—è –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π
- [ ] –ó–Ω–∞—Ç—å atlas –¥–ª—è declarative –º–∏–≥—Ä–∞—Ü–∏–π

### Performance
- [ ] –ó–∞–ø—É—Å–∫–∞—Ç—å –∏ —á–∏—Ç–∞—Ç—å EXPLAIN ANALYZE –∏–∑ Go –∫–æ–¥–∞
- [ ] –ü–æ–Ω–∏–º–∞—Ç—å —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É Seq Scan, Index Scan, Index Only Scan
- [ ] –í—ã–±–∏—Ä–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø –∏–Ω–¥–µ–∫—Å–∞ (B-tree, GIN, GiST, BRIN)
- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pg_stat_statements –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
- [ ] –ù–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å connection-level –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (work_mem, statement_timeout)

### High Availability
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å routing –º–µ–∂–¥—É primary –∏ replicas
- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å multi-host connection strings
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å retry —Å exponential backoff –∏ jitter
- [ ] –ü–æ–Ω–∏–º–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω Circuit Breaker –¥–ª—è –ë–î

### Security
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å SSL/TLS —Å verify-ca –∏–ª–∏ verify-full
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Row-Level Security –¥–ª—è multi-tenant
- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å secrets management (AWS SM, Vault, K8s Secrets)
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ä–æ—Ç–∞—Ü–∏—é credentials

### Observability
- [ ] –°–æ–±–∏—Ä–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ pg_stat_* –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π
- [ ] –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ Prometheus
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å OpenTelemetry instrumentation –¥–ª—è pgx
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–ª–µ—Ä—Ç—ã –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫

---

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

–ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ [4.2 –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ](./02_caching.md) ‚Äî Redis, in-memory cache, distributed caching patterns.

---

**–í–æ–ø—Ä–æ—Å—ã?** –û—Ç–∫—Ä–æ–π issue –Ω–∞ [GitHub](https://github.com/AlexandrTolstuhin/csharp-to-go/issues)

[‚Üê –ù–∞–∑–∞–¥: 3.5 –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è API](../part3-web-api/05_api_documentation.md) | [–í–ø–µ—Ä—ë–¥: 4.2 –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Üí](./02_caching.md)

